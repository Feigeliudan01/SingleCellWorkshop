{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A81Q6Am1y_Ud"
   },
   "source": [
    "# Classifying cell types with neural networks\n",
    "\n",
    "In this notebook, we will build a neural network that classifies cell types in the retinal bipolar dataset for Shekhar et al., 2016. These cells have been manually annotated, and here we will show that a neural network can recapitulate these cell type labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EXFYoXoTy_Ue"
   },
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8178,
     "status": "ok",
     "timestamp": 1589305632112,
     "user": {
      "displayName": "Egbert Castro",
      "photoUrl": "",
      "userId": "05225301495169195138"
     },
     "user_tz": 420
    },
    "id": "JdWUNmk2y_Uf",
    "outputId": "c66fd4af-526e-4919-91f2-d3909f6242d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scprep in /home/scottgigante/.local/lib/python3.8/site-packages (1.0.5.post2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/scottgigante/.local/lib/python3.8/site-packages (from scprep) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /usr/lib/python3.8/site-packages (from scprep) (0.25.3)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/lib/python3.8/site-packages (from scprep) (0.22)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/lib/python3.8/site-packages (from scprep) (4.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/lib/python3.8/site-packages (from scprep) (1.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/lib/python3.8/site-packages (from pandas>=0.25->scprep) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3.8/site-packages (from pandas>=0.25->scprep) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas>=0.25->scprep) (1.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FO8aUJszy_Uk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import scprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxD1LoiOy_Uo"
   },
   "source": [
    "## 2. Loading the retinal bipolar data\n",
    "\n",
    "We'll use the same retinal bipolar data you saw in preprocessing and visualization.\n",
    "\n",
    "Alternatively, you may load your own data by replacing the Google Drive file ids with your own file ids.\n",
    "\n",
    "Note that if you do, you will likely not have annotated celltype labels yet. Replace all references to `metadata['CELLTYPE']` with an entry from `metadata`, or your favorite gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndWmQm0ay_Up"
   },
   "outputs": [],
   "source": [
    "scprep.io.download.download_google_drive(\"1GYqmGgv-QY6mRTJhOCE1sHWszRGMFpnf\", \"data.pickle.gz\")\n",
    "scprep.io.download.download_google_drive(\"1q1N1s044FGWzYnQEoYMDJOjdWPm_Uone\", \"metadata.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uft9tH4Hy_Ut"
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_pickle(\"data.pickle.gz\")\n",
    "metadata = pd.read_pickle(\"metadata.pickle.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ow4_EgqBy_Uw"
   },
   "source": [
    "#### Converting data to `numpy` format\n",
    "\n",
    "PyTorch expects data to be stored as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5XD8-4J9y_Ux"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -2.86639095,  16.11995588,   4.36943178, ...,  -1.92352617,\n",
       "         -1.23398076,  -0.18499969],\n",
       "       [ -0.66863206,  13.21553129,  -4.8926386 , ...,   2.2129324 ,\n",
       "         -0.30849364,   2.33503532],\n",
       "       [  0.29665496,   6.85551504,  18.19106778, ...,  -2.82630926,\n",
       "          1.67045571,  -0.06871964],\n",
       "       ...,\n",
       "       [ 39.5113115 ,  -8.20886489, -10.16420678, ...,  -0.89208505,\n",
       "         -0.14628051,   2.41269496],\n",
       "       [  3.13934964,  15.10619606,   3.69472732, ...,  -2.45809468,\n",
       "         -2.331806  ,  -0.44193557],\n",
       "       [ 42.90597659,  -9.79281524, -13.25214996, ...,  -0.15642158,\n",
       "         -0.52714465,  -1.58145625]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = scprep.reduce.pca(data_raw, n_components=100, method='dense').to_numpy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2, ..., 20, 20, 20])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, cluster_names = pd.factorize(metadata['CELLTYPE'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60198,
     "status": "ok",
     "timestamp": 1589305695604,
     "user": {
      "displayName": "Egbert Castro",
      "photoUrl": "",
      "userId": "05225301495169195138"
     },
     "user_tz": 420
    },
    "id": "BhUTttDgy_U2",
    "outputId": "654e14cd-bd94-4e43-f9c7-f25f5534076a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(labels))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DR163lNCy_U8"
   },
   "source": [
    "#### Splitting the data into training and validation sets\n",
    "\n",
    "We'll allocate 80\\% of our data for training and 20\\% for testing. You can also do this with scikit-learn:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_training, data_validation, labels_training, labels_validation = train_test_split(\n",
    "    data, labels, test_size=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59972,
     "status": "ok",
     "timestamp": 1589305695605,
     "user": {
      "displayName": "Egbert Castro",
      "photoUrl": "",
      "userId": "05225301495169195138"
     },
     "user_tz": 420
    },
    "id": "58UuUKv1y_U9",
    "outputId": "bd127f36-6498-47ae-f07b-5a2dd51aafe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17241, 100), (4311, 100))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first let's split our data into training and validation sets\n",
    "train_test_split = int(.8 * data.shape[0])\n",
    "\n",
    "data_training = data[:train_test_split, :]\n",
    "labels_training = labels[:train_test_split]\n",
    "data_validation = data[train_test_split:, :]\n",
    "labels_validation = labels[train_test_split:]\n",
    "data_training.shape, data_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCP4K9QGy_VB"
   },
   "source": [
    "## 3. Moving Our Data to PyTorch Tensors \n",
    "\n",
    "By moving our data from numpy arrays to PyTorch Tensors, we can take advantage of the variety of tensor operations available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SmEz1AoxaHzs"
   },
   "outputs": [],
   "source": [
    "train_tensor = torch.from_numpy(data_training)\n",
    "train_labels = torch.from_numpy(labels_training)\n",
    "\n",
    "valid_tensor = torch.from_numpy(data_validation)\n",
    "valid_labels = torch.from_numpy(labels_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TCSh3dDcZ7U"
   },
   "source": [
    "Let's go ahead and check that our tensors are the expected sizes. We can do this identically to how we've previously done it with numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58849,
     "status": "ok",
     "timestamp": 1589305695606,
     "user": {
      "displayName": "Egbert Castro",
      "photoUrl": "",
      "userId": "05225301495169195138"
     },
     "user_tz": 420
    },
    "id": "9i_UlXj_cSeN",
    "outputId": "6d6a0810-457d-40b3-f3b1-7525635ab813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train tensor shape: torch.Size([17241, 100])\n",
      "train labels shape: torch.Size([17241])\n",
      "valid tensor shape: torch.Size([4311, 100])\n",
      "valid labels shape: torch.Size([4311])\n"
     ]
    }
   ],
   "source": [
    "# check shapes\n",
    "print(\"train tensor shape: {}\".format(train_tensor.shape))\n",
    "print(\"train labels shape: {}\".format(train_labels.shape))\n",
    "\n",
    "print(\"valid tensor shape: {}\".format(valid_tensor.shape))\n",
    "print(\"valid labels shape: {}\".format(valid_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nep06YFNdh4i"
   },
   "source": [
    "## Exercise 1 - Tensor Operations 1\n",
    "\n",
    "1. Create a tensor called x of values (1,20) using torch.arange(). Check the PyTorch documentation for [help](https://pytorch.org/docs/master/generated/torch.arange.html)\n",
    "\n",
    "2. Reshape this tensor to shape (4,5)\n",
    "\n",
    "2. Add the constant 5 to x and save this tensor as y\n",
    "\n",
    "3. Power the values of y to 3rd power and save this tensor as z\n",
    "\n",
    "4. Print the first row of z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58434,
     "status": "error",
     "timestamp": 1589305695607,
     "user": {
      "displayName": "Egbert Castro",
      "photoUrl": "",
      "userId": "05225301495169195138"
     },
     "user_tz": 420
    },
    "id": "Hu3qBrTwehu_",
    "outputId": "1b846634-3f82-4fba-ff3d-e21ea20b6e6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([125, 216, 343, 512, 729])\n"
     ]
    }
   ],
   "source": [
    "# create x using torch.arange()\n",
    "x = torch.arange(20)\n",
    "\n",
    "# reshape to (4,5)\n",
    "x = x.reshape(4,5)\n",
    "\n",
    "# add 5\n",
    "y = x + 5\n",
    "\n",
    "# power y to the 3rd power\n",
    "z = y ** 3\n",
    "\n",
    "# print the first row of z\n",
    "print(z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7yyq0BFieh1l"
   },
   "source": [
    "## Exercise 2 - Tensor Operations 2\n",
    "\n",
    "1. Subset the training tensor by taking the last 5 rows\n",
    "\n",
    "2. Double the values and print the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B8QoSscEc8Rc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5.7328,  32.2399,   8.7389,  ...,  -3.8471,  -2.4680,  -0.3700],\n",
       "        [ -1.3373,  26.4311,  -9.7853,  ...,   4.4259,  -0.6170,   4.6701],\n",
       "        [  0.5933,  13.7110,  36.3821,  ...,  -5.6526,   3.3409,  -0.1374],\n",
       "        ...,\n",
       "        [-28.5883, -13.0283,  -4.1683,  ...,   3.1040,  -1.4847,  -1.4837],\n",
       "        [ -1.0126,  31.4739,  -1.5407,  ...,   0.1357,   1.7186,  -5.8128],\n",
       "        [-27.1728, -18.9764,   3.0928,  ...,   0.4251,   1.5037,  -4.0879]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the last five rows of `data_training`\n",
    "data_last5 = train_tensor[-5:]\n",
    "\n",
    "# Multiply by two\n",
    "last5_double = train_tensor * 2\n",
    "\n",
    "# Print the result\n",
    "last5_double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZnXNkmMgbQG"
   },
   "source": [
    "## 4. Building a one-layer neural network\n",
    "\n",
    "Now we know how to write simple recipes in PyTorch, we can create a more complex instruction set defining a simple neural network with a single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQQbxUl3k951"
   },
   "outputs": [],
   "source": [
    "class layer(nn.Module):\n",
    "    def __init__(self, input_size, output_size, activation=None):\n",
    "        super(layer, self).__init__()\n",
    "\n",
    "        self.weight = torch.randn(input_size, output_size).double().requires_grad_()\n",
    "        self.bias = torch.randn(output_size).double().requires_grad_()\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = torch.matmul(x, self.weight) + self.bias\n",
    "        output = self.activation(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can make two copies of this layer and stack them together to make a simple neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1589306878346,
     "user": {
      "displayName": "Egbert Castro",
      "photoUrl": "",
      "userId": "05225301495169195138"
     },
     "user_tz": 420
    },
    "id": "5KNIbIWld4W9",
    "outputId": "f75960cf-36b2-408b-c290-c3edbe12aec4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.9228e-72, 2.4956e-115,  2.6830e-45,  ...,  1.4393e-22,\n",
       "          4.1317e-49,  1.1881e-87],\n",
       "        [ 6.3094e-93, 9.0371e-143, 7.8264e-142,  ...,  3.3343e-74,\n",
       "          1.0387e-40, 1.0014e-181],\n",
       "        [ 1.5437e-37,  1.6377e-40,  8.0126e-59,  ...,  8.0852e-45,\n",
       "          6.4936e-22,  2.6568e-89],\n",
       "        ...,\n",
       "        [ 1.9545e-36,  2.1544e-53,  4.9683e-29,  ...,  1.4466e-01,\n",
       "          4.8434e-32,  5.3621e-31],\n",
       "        [6.7169e-123, 2.6999e-169, 3.6800e-142,  ...,  6.3275e-63,\n",
       "         1.6753e-116, 1.5895e-192],\n",
       "        [ 8.9144e-40,  1.0835e-92,  5.5660e-25,  ...,  1.3610e-06,\n",
       "          1.1614e-45,  1.4110e-58]], dtype=torch.float64,\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = data_training.shape[1]\n",
    "num_hidden = 10\n",
    "\n",
    "layer_1 = layer(input_size, num_hidden, activation=nn.ReLU())\n",
    "layer_2 = layer(num_hidden, num_classes, activation=nn.Softmax(dim=-1))\n",
    "\n",
    "# create a hidden (middle) layer\n",
    "hidden_layer = layer_1(train_tensor)\n",
    "\n",
    "# create the output layer used to classify\n",
    "output = layer_2(hidden_layer)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UfrPOTZGhuOg"
   },
   "source": [
    "#### Build the loss function\n",
    "\n",
    "In order to train our neural network, we need to define a loss function which tells us how well (or how poorly) our classifier performed.\n",
    "\n",
    "Here, we'll use the cross-entropy loss which we discussed in lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSAT1diwiJbX"
   },
   "outputs": [],
   "source": [
    "def to_one_hot(y_tensor, c_dims):\n",
    "    \"\"\"converts a N-dimensional input to a NxC dimnensional one-hot encoding\n",
    "    \"\"\"\n",
    "    y_tensor = torch.LongTensor(y_tensor)\n",
    "    y_tensor = y_tensor.type(torch.LongTensor).view(-1, 1)\n",
    "    c_dims = c_dims if c_dims is not None else int(torch.max(y_tensor)) + 1\n",
    "    y_one_hot = torch.zeros(y_tensor.size()[0], c_dims).scatter_(1, y_tensor, 1)\n",
    "    y_one_hot = y_one_hot.view(*y_tensor.shape, -1)\n",
    "    return y_one_hot.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SjJxo01g-eY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert our integer class labels to a binary \"one-hot\" matrix\n",
    "labels_one_hot = to_one_hot(train_labels, num_classes)\n",
    "labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SjJxo01g-eY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(400516.5197, dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute cross entropy\n",
    "loss = labels_one_hot * torch.log(output+ 1e-6) + (1 - labels_one_hot) * torch.log(1 - output + 1e-6)\n",
    "loss = -1 * loss.sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Px6sHlWirB3"
   },
   "source": [
    "#### Create the optimizer\n",
    "\n",
    "PyTorch does all of the heavy lifting for us. The optimizer takes the loss value and calculates how we should change the network weights to improve our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yF0I1uEviNuc"
   },
   "outputs": [],
   "source": [
    "# now we need an optimizer that we'll give this loss, and it'll take responsibility\n",
    "# for updating the network to make this score go down\n",
    "learning_rate = 0.00001\n",
    "\n",
    "optimizer = optim.SGD([layer_1.weight, layer_1.bias,\n",
    "                       layer_2.weight, layer_2.bias],\n",
    "                       lr=learning_rate)\n",
    "\n",
    "\n",
    "# how many data points do we want to calculate at once?\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMX8M0Pl_TmR"
   },
   "source": [
    "#### Train the network\n",
    "\n",
    "Let's train the network for 100 _epochs_. An epoch is defined as having optimized our weights over all of our data points exactly once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 147956,
     "status": "error",
     "timestamp": 1589307256803,
     "user": {
      "displayName": "Egbert Castro",
      "photoUrl": "",
      "userId": "05225301495169195138"
     },
     "user_tz": 420
    },
    "id": "wIy3I485nlJN",
    "outputId": "211e7f85-b661-4172-c845-45e7340d5879",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50 loss: 205.678 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 100 loss: 264.961 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150 loss: 250.261 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 200 loss: 185.985 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 250 loss: 234.498 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 300 loss: 198.654 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 350 loss: 222.733 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 400 loss: 229.582 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 450 loss: 245.975 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 500 loss: 230.577 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 550 loss: 238.413 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 600 loss: 256.378 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 650 loss: 224.726 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 700 loss: 228.099 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 750 loss: 244.960 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 800 loss: 219.933 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 850 loss: 224.934 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 900 loss: 221.357 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 950 loss: 250.755 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1000 loss: 255.058 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1050 loss: 235.751 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1100 loss: 247.684 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1150 loss: 194.548 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 1200 loss: 240.717 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1250 loss: 212.068 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 1300 loss: 245.514 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 1350 loss: 227.077 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1400 loss: 185.790 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 1450 loss: 252.438 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1500 loss: 208.985 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1550 loss: 201.088 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1600 loss: 253.282 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 1650 loss: 198.529 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1700 loss: 218.938 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 1750 loss: 231.439 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 1800 loss: 227.629 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1850 loss: 210.359 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1900 loss: 168.223 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 1950 loss: 268.801 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2000 loss: 225.673 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 2050 loss: 233.737 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2100 loss: 192.212 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 2150 loss: 229.953 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 2200 loss: 226.101 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2250 loss: 222.477 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2300 loss: 244.103 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2350 loss: 199.450 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 2400 loss: 224.257 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2450 loss: 221.539 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2500 loss: 257.300 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 2550 loss: 193.043 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 2600 loss: 196.113 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 2650 loss: 164.060 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 2700 loss: 180.643 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 2750 loss: 255.025 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2800 loss: 237.470 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2850 loss: 248.407 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2900 loss: 168.432 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 2950 loss: 110.854 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 3000 loss: 231.600 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 3050 loss: 200.912 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 3100 loss: 217.997 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 3150 loss: 214.877 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 3200 loss: 208.954 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 3250 loss: 224.850 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3300 loss: 264.872 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3350 loss: 233.646 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 3400 loss: 237.097 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3450 loss: 247.896 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3500 loss: 217.196 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 3550 loss: 223.528 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 3600 loss: 197.240 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3650 loss: 204.987 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 3700 loss: 206.862 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 3750 loss: 213.610 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 3800 loss: 223.102 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 3850 loss: 208.145 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3900 loss: 206.462 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 3950 loss: 179.453 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 4000 loss: 203.368 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4050 loss: 190.628 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 4100 loss: 225.013 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4150 loss: 227.827 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 4200 loss: 195.258 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 4250 loss: 218.425 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 4300 loss: 195.654 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4350 loss: 203.872 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 4400 loss: 206.239 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 4450 loss: 259.780 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4500 loss: 185.072 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 4550 loss: 209.042 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4600 loss: 220.050 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 4650 loss: 221.812 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4700 loss: 165.471 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 4750 loss: 199.342 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 4800 loss: 164.034 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 4850 loss: 219.317 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 4900 loss: 243.162 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4950 loss: 216.074 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5000 loss: 198.433 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 5050 loss: 219.861 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5100 loss: 153.088 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 5150 loss: 220.827 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 5200 loss: 160.372 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 5250 loss: 166.354 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 5300 loss: 192.117 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 5350 loss: 227.285 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 5400 loss: 225.954 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5450 loss: 207.248 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 5500 loss: 248.336 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5550 loss: 160.579 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 5600 loss: 192.799 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 5650 loss: 204.210 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 5700 loss: 233.586 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 5750 loss: 168.838 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 5800 loss: 199.416 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5850 loss: 166.934 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 5900 loss: 254.490 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 5950 loss: 206.046 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 6000 loss: 157.774 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 6050 loss: 178.978 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 6100 loss: 227.327 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 6150 loss: 219.927 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 6200 loss: 182.050 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 6250 loss: 213.084 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6300 loss: 190.689 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 6350 loss: 200.288 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 6400 loss: 239.895 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 6450 loss: 224.293 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6500 loss: 151.672 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 6550 loss: 190.380 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 6600 loss: 214.560 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 6650 loss: 216.546 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 6700 loss: 215.590 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 6750 loss: 186.839 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 6800 loss: 207.459 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 6850 loss: 227.980 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6900 loss: 207.385 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 6950 loss: 223.549 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7000 loss: 178.129 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 7050 loss: 186.157 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 7100 loss: 211.351 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7150 loss: 213.739 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 7200 loss: 242.646 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 7250 loss: 237.507 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7300 loss: 191.410 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 7350 loss: 242.573 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7400 loss: 208.421 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7450 loss: 235.270 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 7500 loss: 118.499 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 7550 loss: 186.054 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 7600 loss: 140.702 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 7650 loss: 191.352 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 7700 loss: 241.080 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 7750 loss: 255.371 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7800 loss: 174.735 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 7850 loss: 190.449 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 7900 loss: 248.223 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 7950 loss: 194.602 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8000 loss: 231.647 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 8050 loss: 246.670 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8100 loss: 216.830 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 8150 loss: 184.605 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 8200 loss: 201.852 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 8250 loss: 159.014 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 8300 loss: 244.173 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 8350 loss: 218.455 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8400 loss: 156.714 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 8450 loss: 221.401 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 8500 loss: 204.275 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 8550 loss: 191.690 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 8600 loss: 242.608 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8650 loss: 169.237 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 8700 loss: 161.739 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 8750 loss: 166.187 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 8800 loss: 236.092 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 8850 loss: 226.488 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8900 loss: 168.676 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 8950 loss: 223.181 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 9000 loss: 166.719 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 9050 loss: 180.852 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 9100 loss: 203.903 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 9150 loss: 158.748 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 9200 loss: 264.476 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 9250 loss: 217.103 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 9300 loss: 184.481 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 9350 loss: 254.591 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 9400 loss: 162.853 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 9450 loss: 241.425 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 9500 loss: 171.609 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 9550 loss: 194.541 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 9600 loss: 191.280 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 9650 loss: 213.224 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 9700 loss: 215.699 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 9750 loss: 202.177 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 9800 loss: 168.827 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 9850 loss: 231.655 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 9900 loss: 175.156 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 9950 loss: 182.304 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 10000 loss: 179.062 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 10050 loss: 177.750 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 10100 loss: 218.790 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 10150 loss: 189.953 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 10200 loss: 171.339 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 10250 loss: 182.212 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 10300 loss: 221.993 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10350 loss: 200.091 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 10400 loss: 197.574 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 10450 loss: 227.024 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 10500 loss: 211.341 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 10550 loss: 117.194 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 10600 loss: 171.876 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 10650 loss: 215.759 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 10700 loss: 156.023 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 10750 loss: 230.708 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 10800 loss: 203.492 training accuracy: 0.000 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10850 loss: 213.400 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 10900 loss: 200.191 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 10950 loss: 144.062 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 11000 loss: 205.563 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 11050 loss: 154.955 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 11100 loss: 228.372 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 11150 loss: 210.897 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 11200 loss: 249.984 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 11250 loss: 164.515 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 11300 loss: 145.344 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 11350 loss: 175.694 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 11400 loss: 193.875 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 11450 loss: 215.421 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 11500 loss: 193.287 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 11550 loss: 199.203 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 11600 loss: 155.961 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 11650 loss: 210.747 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 11700 loss: 171.426 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 11750 loss: 200.960 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11800 loss: 235.752 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 11850 loss: 174.936 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 11900 loss: 180.121 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 11950 loss: 238.768 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 12000 loss: 199.903 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 12050 loss: 196.682 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 12100 loss: 157.896 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 12150 loss: 204.015 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 12200 loss: 195.174 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 12250 loss: 190.857 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12300 loss: 218.647 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12350 loss: 206.064 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 12400 loss: 197.637 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 12450 loss: 203.030 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 12500 loss: 188.248 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12550 loss: 230.375 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 12600 loss: 143.859 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 12650 loss: 236.148 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 12700 loss: 247.700 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 12750 loss: 174.369 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 12800 loss: 207.813 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12850 loss: 193.412 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 12900 loss: 255.838 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12950 loss: 237.314 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13000 loss: 160.088 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 13050 loss: 206.784 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 13100 loss: 153.036 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 13150 loss: 204.973 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 13200 loss: 210.554 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 13250 loss: 246.813 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13300 loss: 232.006 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 13350 loss: 191.936 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 13400 loss: 211.432 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 13450 loss: 222.559 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13500 loss: 164.409 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 13550 loss: 161.485 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 13600 loss: 143.765 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 13650 loss: 221.887 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 13700 loss: 234.522 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 13750 loss: 180.820 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 13800 loss: 199.254 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 13850 loss: 151.824 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 13900 loss: 219.221 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13950 loss: 178.984 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 14000 loss: 173.189 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 14050 loss: 221.652 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 14100 loss: 217.542 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 14150 loss: 202.103 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 14200 loss: 201.904 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 14250 loss: 226.240 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 14300 loss: 163.337 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 14350 loss: 236.314 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14400 loss: 193.365 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 14450 loss: 184.154 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 14500 loss: 200.984 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 14550 loss: 209.984 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 14600 loss: 125.950 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 14650 loss: 194.629 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 14700 loss: 172.078 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 14750 loss: 150.670 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 14800 loss: 239.497 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 14850 loss: 195.807 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14900 loss: 223.164 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 14950 loss: 203.613 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 15000 loss: 213.293 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 15050 loss: 220.442 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 15100 loss: 240.875 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 15150 loss: 225.570 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 15200 loss: 205.092 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 15250 loss: 206.607 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 15300 loss: 162.534 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 15350 loss: 221.434 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 15400 loss: 191.802 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 15450 loss: 215.596 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 15500 loss: 138.376 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 15550 loss: 227.224 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 15600 loss: 192.088 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 15650 loss: 237.932 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15700 loss: 170.556 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 15750 loss: 223.739 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 15800 loss: 153.909 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 15850 loss: 233.597 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 15900 loss: 212.680 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 15950 loss: 215.940 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 16000 loss: 229.906 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16050 loss: 177.416 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 16100 loss: 172.539 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 16150 loss: 188.039 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 16200 loss: 219.910 training accuracy: 0.100 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16250 loss: 204.019 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 16300 loss: 159.880 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 16350 loss: 224.673 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 16400 loss: 175.672 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 16450 loss: 230.643 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16500 loss: 187.117 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 16550 loss: 205.314 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 16600 loss: 137.476 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 16650 loss: 212.733 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 16700 loss: 247.148 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16750 loss: 181.910 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 16800 loss: 210.402 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 16850 loss: 200.178 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 16900 loss: 180.657 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 16950 loss: 179.604 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 17000 loss: 229.940 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 17050 loss: 190.007 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 17100 loss: 167.870 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 17150 loss: 157.990 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 17200 loss: 150.507 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 17250 loss: 224.174 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 17300 loss: 173.242 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 17350 loss: 191.670 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 17400 loss: 183.290 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 17450 loss: 218.389 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 17500 loss: 185.173 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 17550 loss: 221.497 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 17600 loss: 228.450 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 17650 loss: 215.959 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 17700 loss: 206.259 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 17750 loss: 193.024 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 17800 loss: 186.309 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 17850 loss: 191.009 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 17900 loss: 216.726 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 17950 loss: 171.605 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 18000 loss: 164.168 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 18050 loss: 227.348 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18100 loss: 178.255 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18150 loss: 219.200 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18200 loss: 187.841 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 18250 loss: 215.499 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 18300 loss: 188.311 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 18350 loss: 196.668 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18400 loss: 141.904 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 18450 loss: 237.136 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 18500 loss: 223.538 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 18550 loss: 177.200 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 18600 loss: 183.110 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 18650 loss: 182.872 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 18700 loss: 224.994 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 18750 loss: 200.371 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 18800 loss: 204.316 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18850 loss: 183.535 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 18900 loss: 180.617 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18950 loss: 208.562 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 19000 loss: 209.245 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 19050 loss: 201.758 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 19100 loss: 217.780 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 19150 loss: 255.237 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 19200 loss: 226.264 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 19250 loss: 175.994 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 19300 loss: 237.030 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19350 loss: 189.500 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 19400 loss: 171.986 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 19450 loss: 106.654 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 19500 loss: 210.381 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 19550 loss: 193.195 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 19600 loss: 193.159 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 19650 loss: 169.731 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 19700 loss: 227.398 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 19750 loss: 158.994 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 19800 loss: 209.886 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 19850 loss: 187.164 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 19900 loss: 216.712 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 19950 loss: 202.264 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 20000 loss: 256.272 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20050 loss: 215.495 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 20100 loss: 175.550 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 20150 loss: 196.844 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 20200 loss: 242.307 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20250 loss: 182.089 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 20300 loss: 194.784 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 20350 loss: 190.368 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 20400 loss: 228.435 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 20450 loss: 204.293 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 20500 loss: 220.993 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 20550 loss: 229.336 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20600 loss: 194.601 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 20650 loss: 181.014 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 20700 loss: 226.348 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20750 loss: 205.814 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 20800 loss: 191.276 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 20850 loss: 198.941 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 20900 loss: 179.870 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 20950 loss: 186.583 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 21000 loss: 137.159 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 21050 loss: 210.367 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 21100 loss: 215.844 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 21150 loss: 170.052 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 21200 loss: 195.753 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 21250 loss: 193.551 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 21300 loss: 176.935 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 21350 loss: 230.067 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 21400 loss: 187.012 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 21450 loss: 138.677 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 21500 loss: 178.431 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 21550 loss: 227.960 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21600 loss: 201.561 training accuracy: 0.200 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21650 loss: 169.262 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 21700 loss: 170.151 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 21750 loss: 182.487 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 21800 loss: 203.678 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 21850 loss: 225.449 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21900 loss: 195.168 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 21950 loss: 159.502 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 22000 loss: 145.133 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 22050 loss: 201.482 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 22100 loss: 232.714 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22150 loss: 214.595 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 22200 loss: 210.552 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 22250 loss: 172.174 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 22300 loss: 219.490 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 22350 loss: 189.964 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 22400 loss: 173.695 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 22450 loss: 205.400 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 22500 loss: 194.964 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 22550 loss: 178.677 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 22600 loss: 197.327 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 22650 loss: 122.691 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 22700 loss: 223.206 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 22750 loss: 180.060 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 22800 loss: 199.302 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 22850 loss: 210.128 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 22900 loss: 194.200 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 22950 loss: 179.823 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 23000 loss: 203.838 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 23050 loss: 167.302 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 23100 loss: 158.516 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 23150 loss: 211.870 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 23200 loss: 182.466 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 23250 loss: 192.504 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 23300 loss: 214.385 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23350 loss: 211.343 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 23400 loss: 206.192 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 23450 loss: 221.413 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23500 loss: 224.561 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 23550 loss: 170.234 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 23600 loss: 182.754 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 23650 loss: 127.548 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 23700 loss: 209.231 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 23750 loss: 202.528 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 23800 loss: 244.096 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 23850 loss: 157.085 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 23900 loss: 197.707 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 23950 loss: 168.663 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 24000 loss: 195.397 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 24050 loss: 209.653 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 24100 loss: 220.664 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 24150 loss: 198.847 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 24200 loss: 211.246 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24250 loss: 217.234 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 24300 loss: 160.413 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 24350 loss: 140.566 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 24400 loss: 216.737 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24450 loss: 193.429 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 24500 loss: 220.734 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 24550 loss: 190.599 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 24600 loss: 197.734 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 24650 loss: 174.410 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 24700 loss: 142.797 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 24750 loss: 180.553 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 24800 loss: 138.822 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 24850 loss: 184.807 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 24900 loss: 173.412 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 24950 loss: 214.155 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 25000 loss: 140.740 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 25050 loss: 195.080 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 25100 loss: 131.659 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 25150 loss: 143.761 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 25200 loss: 207.946 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 25250 loss: 187.639 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 25300 loss: 189.284 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 25350 loss: 207.863 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 25400 loss: 145.313 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 25450 loss: 245.610 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 25500 loss: 194.059 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 25550 loss: 179.452 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 25600 loss: 166.056 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 25650 loss: 208.151 training accuracy: 0.000 validation accuracy: 0.500 \n",
      "Step 25700 loss: 187.510 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 25750 loss: 195.081 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 25800 loss: 207.565 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 25850 loss: 191.167 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 25900 loss: 204.788 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 25950 loss: 169.996 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 26000 loss: 212.135 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 26050 loss: 158.242 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 26100 loss: 222.549 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 26150 loss: 209.302 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 26200 loss: 185.216 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 26250 loss: 200.552 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 26300 loss: 185.460 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 26350 loss: 207.318 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 26400 loss: 179.395 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 26450 loss: 181.007 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 26500 loss: 207.837 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 26550 loss: 231.754 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26600 loss: 175.582 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 26650 loss: 185.267 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 26700 loss: 240.511 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26750 loss: 192.684 training accuracy: 0.000 validation accuracy: 0.500 \n",
      "Step 26800 loss: 194.719 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 26850 loss: 188.410 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 26900 loss: 185.770 training accuracy: 0.200 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26950 loss: 216.184 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27000 loss: 176.124 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 27050 loss: 199.561 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 27100 loss: 196.155 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 27150 loss: 128.088 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 27200 loss: 123.548 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 27250 loss: 193.022 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 27300 loss: 193.798 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 27350 loss: 194.044 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27400 loss: 154.148 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 27450 loss: 212.985 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 27500 loss: 203.479 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 27550 loss: 195.491 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 27600 loss: 180.576 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 27650 loss: 215.670 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 27700 loss: 156.017 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 27750 loss: 207.157 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27800 loss: 199.642 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 27850 loss: 217.309 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 27900 loss: 185.408 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 27950 loss: 172.559 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 28000 loss: 184.518 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 28050 loss: 175.000 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 28100 loss: 214.250 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28150 loss: 166.994 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 28200 loss: 169.593 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 28250 loss: 170.059 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 28300 loss: 224.868 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28350 loss: 205.472 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28400 loss: 176.873 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 28450 loss: 202.869 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 28500 loss: 203.384 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 28550 loss: 169.847 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 28600 loss: 205.431 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28650 loss: 163.257 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 28700 loss: 165.654 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 28750 loss: 179.818 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 28800 loss: 171.402 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 28850 loss: 192.447 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 28900 loss: 232.447 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28950 loss: 148.442 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 29000 loss: 183.541 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 29050 loss: 173.716 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29100 loss: 187.068 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 29150 loss: 203.357 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29200 loss: 191.068 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 29250 loss: 235.873 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29300 loss: 141.966 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 29350 loss: 177.321 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 29400 loss: 159.779 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 29450 loss: 159.868 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 29500 loss: 183.830 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29550 loss: 208.830 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 29600 loss: 212.338 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 29650 loss: 192.233 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29700 loss: 191.375 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29750 loss: 159.428 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 29800 loss: 151.317 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 29850 loss: 180.466 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 29900 loss: 156.199 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 29950 loss: 198.940 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 30000 loss: 148.848 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 30050 loss: 179.193 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 30100 loss: 181.947 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 30150 loss: 206.888 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 30200 loss: 232.450 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30250 loss: 150.859 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 30300 loss: 179.111 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 30350 loss: 164.128 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 30400 loss: 216.961 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 30450 loss: 178.318 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 30500 loss: 231.831 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30550 loss: 177.112 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 30600 loss: 153.266 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 30650 loss: 183.632 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 30700 loss: 150.027 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 30750 loss: 160.849 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 30800 loss: 179.265 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 30850 loss: 178.978 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 30900 loss: 225.935 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 30950 loss: 223.779 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 31000 loss: 206.896 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 31050 loss: 198.953 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 31100 loss: 214.256 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31150 loss: 210.722 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 31200 loss: 196.139 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 31250 loss: 213.568 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 31300 loss: 182.122 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 31350 loss: 193.515 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 31400 loss: 143.957 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 31450 loss: 185.433 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 31500 loss: 152.952 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 31550 loss: 159.429 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 31600 loss: 203.057 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 31650 loss: 237.108 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 31700 loss: 227.930 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 31750 loss: 196.738 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 31800 loss: 150.396 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 31850 loss: 151.968 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 31900 loss: 207.618 training accuracy: 0.000 validation accuracy: 0.500 \n",
      "Step 31950 loss: 175.094 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 32000 loss: 198.654 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32050 loss: 157.953 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 32100 loss: 170.607 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 32150 loss: 194.735 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 32200 loss: 175.317 training accuracy: 0.200 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 32250 loss: 138.230 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 32300 loss: 171.001 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 32350 loss: 182.184 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 32400 loss: 182.853 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 32450 loss: 216.225 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 32500 loss: 210.885 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 32550 loss: 185.022 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 32600 loss: 207.471 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32650 loss: 191.670 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 32700 loss: 190.050 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 32750 loss: 186.456 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 32800 loss: 186.992 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 32850 loss: 209.496 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 32900 loss: 187.796 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 32950 loss: 176.463 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 33000 loss: 164.420 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 33050 loss: 182.486 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 33100 loss: 213.155 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33150 loss: 234.710 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33200 loss: 175.375 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 33250 loss: 172.141 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 33300 loss: 168.234 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 33350 loss: 190.088 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 33400 loss: 162.750 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 33450 loss: 170.675 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 33500 loss: 205.471 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 33550 loss: 213.689 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 33600 loss: 178.462 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 33650 loss: 180.893 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 33700 loss: 214.669 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33750 loss: 176.447 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 33800 loss: 260.794 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 33850 loss: 240.794 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33900 loss: 212.108 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 33950 loss: 193.036 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 34000 loss: 194.430 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 34050 loss: 234.175 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 34100 loss: 180.749 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34150 loss: 199.589 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 34200 loss: 209.056 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 34250 loss: 192.376 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 34300 loss: 165.021 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 34350 loss: 168.672 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 34400 loss: 150.274 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 34450 loss: 210.824 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34500 loss: 171.891 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 34550 loss: 187.760 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 34600 loss: 199.862 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 34650 loss: 228.774 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 34700 loss: 222.088 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 34750 loss: 172.604 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 34800 loss: 206.640 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 34850 loss: 203.651 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 34900 loss: 143.736 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 34950 loss: 231.149 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 35000 loss: 190.631 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 35050 loss: 193.765 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 35100 loss: 235.903 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35150 loss: 183.923 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 35200 loss: 214.457 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 35250 loss: 211.357 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 35300 loss: 174.757 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 35350 loss: 169.229 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 35400 loss: 184.739 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 35450 loss: 191.791 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 35500 loss: 218.111 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 35550 loss: 148.216 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 35600 loss: 212.309 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 35650 loss: 131.354 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 35700 loss: 179.260 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 35750 loss: 178.973 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 35800 loss: 142.698 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 35850 loss: 151.850 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 35900 loss: 174.672 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 35950 loss: 207.926 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 36000 loss: 174.876 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 36050 loss: 173.681 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 36100 loss: 176.639 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 36150 loss: 175.932 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 36200 loss: 181.185 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 36250 loss: 165.809 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 36300 loss: 188.792 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 36350 loss: 227.420 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 36400 loss: 142.631 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 36450 loss: 169.588 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 36500 loss: 160.968 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 36550 loss: 183.021 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36600 loss: 217.705 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 36650 loss: 179.191 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 36700 loss: 189.227 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 36750 loss: 157.736 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 36800 loss: 207.417 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 36850 loss: 192.704 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 36900 loss: 217.786 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 36950 loss: 156.827 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 37000 loss: 186.467 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 37050 loss: 153.362 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 37100 loss: 183.220 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 37150 loss: 191.575 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 37200 loss: 191.025 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 37250 loss: 153.834 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 37300 loss: 215.535 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 37350 loss: 163.420 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 37400 loss: 206.373 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 37450 loss: 218.142 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 37500 loss: 189.170 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 37550 loss: 235.911 training accuracy: 0.000 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 37600 loss: 140.924 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 37650 loss: 171.102 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 37700 loss: 235.260 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 37750 loss: 193.355 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 37800 loss: 175.783 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 37850 loss: 188.552 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 37900 loss: 149.172 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 37950 loss: 201.884 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 38000 loss: 203.417 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 38050 loss: 193.881 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 38100 loss: 142.269 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 38150 loss: 192.411 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 38200 loss: 196.821 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 38250 loss: 131.885 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 38300 loss: 166.043 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 38350 loss: 191.222 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 38400 loss: 181.998 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 38450 loss: 173.061 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 38500 loss: 125.685 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 38550 loss: 229.320 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 38600 loss: 124.619 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 38650 loss: 138.615 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 38700 loss: 151.299 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 38750 loss: 184.427 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 38800 loss: 212.714 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 38850 loss: 172.105 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 38900 loss: 183.320 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 38950 loss: 161.069 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39000 loss: 217.449 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 39050 loss: 184.246 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 39100 loss: 170.161 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 39150 loss: 181.263 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 39200 loss: 176.040 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 39250 loss: 180.327 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 39300 loss: 204.140 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 39350 loss: 189.969 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 39400 loss: 200.585 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 39450 loss: 183.948 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 39500 loss: 152.656 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 39550 loss: 221.187 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 39600 loss: 147.346 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 39650 loss: 164.312 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 39700 loss: 140.981 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 39750 loss: 195.144 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 39800 loss: 231.061 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39850 loss: 212.400 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39900 loss: 151.076 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 39950 loss: 174.785 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 40000 loss: 161.893 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 40050 loss: 165.178 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 40100 loss: 159.728 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 40150 loss: 168.691 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 40200 loss: 218.660 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 40250 loss: 197.974 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 40300 loss: 194.337 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 40350 loss: 177.611 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 40400 loss: 189.295 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 40450 loss: 159.894 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 40500 loss: 103.447 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 40550 loss: 188.373 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 40600 loss: 176.745 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 40650 loss: 106.013 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 40700 loss: 187.320 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 40750 loss: 160.813 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 40800 loss: 189.135 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 40850 loss: 175.146 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 40900 loss: 200.622 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 40950 loss: 134.008 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 41000 loss: 203.970 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 41050 loss: 156.678 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 41100 loss: 164.308 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 41150 loss: 213.243 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 41200 loss: 177.111 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 41250 loss: 182.520 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 41300 loss: 116.950 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 41350 loss: 185.652 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 41400 loss: 146.474 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 41450 loss: 203.022 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 41500 loss: 195.045 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 41550 loss: 164.783 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 41600 loss: 159.136 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 41650 loss: 201.176 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 41700 loss: 149.928 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 41750 loss: 194.631 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41800 loss: 140.895 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 41850 loss: 164.234 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 41900 loss: 243.068 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 41950 loss: 126.462 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 42000 loss: 182.670 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 42050 loss: 188.050 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 42100 loss: 221.632 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 42150 loss: 158.635 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 42200 loss: 185.933 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 42250 loss: 182.041 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 42300 loss: 147.775 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 42350 loss: 179.811 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 42400 loss: 123.008 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 42450 loss: 169.255 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 42500 loss: 171.471 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 42550 loss: 157.597 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 42600 loss: 140.877 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 42650 loss: 196.853 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 42700 loss: 169.396 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 42750 loss: 173.615 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 42800 loss: 196.127 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 42850 loss: 151.620 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 42900 loss: 155.360 training accuracy: 0.200 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 42950 loss: 210.673 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43000 loss: 158.512 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 43050 loss: 167.561 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 43100 loss: 231.093 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43150 loss: 161.164 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 43200 loss: 189.800 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 43250 loss: 197.221 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43300 loss: 164.365 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 43350 loss: 123.915 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 43400 loss: 135.782 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 43450 loss: 201.906 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43500 loss: 212.595 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43550 loss: 216.537 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43600 loss: 204.586 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 43650 loss: 200.280 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43700 loss: 149.403 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 43750 loss: 142.391 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 43800 loss: 187.223 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 43850 loss: 190.347 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 43900 loss: 149.115 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 43950 loss: 148.763 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 44000 loss: 143.973 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 44050 loss: 158.779 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44100 loss: 172.542 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 44150 loss: 193.002 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44200 loss: 233.518 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44250 loss: 180.628 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44300 loss: 132.317 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 44350 loss: 206.722 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 44400 loss: 200.972 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 44450 loss: 229.312 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 44500 loss: 209.626 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44550 loss: 221.757 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 44600 loss: 178.634 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 44650 loss: 192.245 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 44700 loss: 131.737 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 44750 loss: 193.105 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 44800 loss: 206.452 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 44850 loss: 184.559 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 44900 loss: 145.713 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 44950 loss: 178.389 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45000 loss: 209.026 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 45050 loss: 155.123 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 45100 loss: 183.284 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 45150 loss: 153.777 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 45200 loss: 173.730 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45250 loss: 191.154 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 45300 loss: 175.335 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 45350 loss: 198.898 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 45400 loss: 195.550 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 45450 loss: 224.581 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45500 loss: 228.734 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 45550 loss: 195.177 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45600 loss: 144.590 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 45650 loss: 162.521 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 45700 loss: 213.353 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45750 loss: 157.582 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 45800 loss: 191.764 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45850 loss: 192.480 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 45900 loss: 198.620 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45950 loss: 219.511 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 46000 loss: 178.496 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 46050 loss: 183.137 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 46100 loss: 157.831 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 46150 loss: 188.541 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 46200 loss: 197.066 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 46250 loss: 180.429 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46300 loss: 146.938 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 46350 loss: 209.743 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 46400 loss: 178.488 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 46450 loss: 181.603 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 46500 loss: 175.385 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 46550 loss: 194.373 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 46600 loss: 162.283 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 46650 loss: 79.310 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 46700 loss: 146.074 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 46750 loss: 168.909 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 46800 loss: 142.839 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 46850 loss: 194.652 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 46900 loss: 175.935 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 46950 loss: 164.059 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 47000 loss: 133.127 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 47050 loss: 176.482 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 47100 loss: 216.956 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 47150 loss: 205.924 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 47200 loss: 185.718 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 47250 loss: 188.225 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 47300 loss: 141.330 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 47350 loss: 204.221 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 47400 loss: 175.006 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 47450 loss: 197.430 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 47500 loss: 170.782 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 47550 loss: 119.811 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 47600 loss: 203.785 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 47650 loss: 194.613 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 47700 loss: 179.779 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 47750 loss: 184.156 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 47800 loss: 179.774 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 47850 loss: 159.195 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 47900 loss: 150.906 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 47950 loss: 177.457 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 48000 loss: 180.571 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 48050 loss: 141.677 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 48100 loss: 192.155 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 48150 loss: 164.834 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 48200 loss: 178.573 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48250 loss: 223.609 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 48300 loss: 202.996 training accuracy: 0.100 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 48350 loss: 112.675 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 48400 loss: 158.751 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 48450 loss: 201.640 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 48500 loss: 162.452 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 48550 loss: 229.019 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48600 loss: 178.061 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 48650 loss: 188.083 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 48700 loss: 165.459 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 48750 loss: 213.677 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 48800 loss: 101.173 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 48850 loss: 168.645 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 48900 loss: 172.302 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 48950 loss: 208.370 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49000 loss: 182.594 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 49050 loss: 185.856 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 49100 loss: 174.043 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 49150 loss: 218.285 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 49200 loss: 164.332 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 49250 loss: 169.162 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 49300 loss: 179.457 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 49350 loss: 187.519 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 49400 loss: 160.473 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 49450 loss: 176.138 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 49500 loss: 201.048 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 49550 loss: 191.510 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 49600 loss: 192.967 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 49650 loss: 149.773 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 49700 loss: 186.953 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 49750 loss: 165.880 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 49800 loss: 201.710 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49850 loss: 137.281 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 49900 loss: 188.369 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 49950 loss: 104.572 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 50000 loss: 170.382 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 50050 loss: 106.461 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 50100 loss: 194.581 training accuracy: 0.000 validation accuracy: 0.500 \n",
      "Step 50150 loss: 101.708 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 50200 loss: 123.535 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 50250 loss: 161.932 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 50300 loss: 161.847 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 50350 loss: 210.390 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 50400 loss: 220.731 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 50450 loss: 155.474 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 50500 loss: 131.761 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 50550 loss: 205.502 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 50600 loss: 167.326 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 50650 loss: 179.885 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 50700 loss: 196.686 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 50750 loss: 180.636 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 50800 loss: 178.016 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 50850 loss: 184.764 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 50900 loss: 145.848 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 50950 loss: 173.577 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 51000 loss: 128.430 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 51050 loss: 170.836 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 51100 loss: 174.171 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 51150 loss: 171.903 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 51200 loss: 217.008 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 51250 loss: 180.319 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 51300 loss: 191.249 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 51350 loss: 193.232 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 51400 loss: 194.289 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 51450 loss: 194.712 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 51500 loss: 175.722 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 51550 loss: 190.590 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 51600 loss: 191.866 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 51650 loss: 196.800 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 51700 loss: 186.444 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 51750 loss: 172.842 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 51800 loss: 137.040 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 51850 loss: 204.337 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 51900 loss: 188.136 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 51950 loss: 126.568 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 52000 loss: 177.425 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 52050 loss: 170.964 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 52100 loss: 192.667 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 52150 loss: 193.427 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 52200 loss: 120.960 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 52250 loss: 166.594 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 52300 loss: 168.123 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 52350 loss: 170.374 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 52400 loss: 166.391 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 52450 loss: 141.880 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 52500 loss: 164.443 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 52550 loss: 218.584 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 52600 loss: 167.542 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 52650 loss: 147.588 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 52700 loss: 159.827 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 52750 loss: 170.475 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 52800 loss: 153.743 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 52850 loss: 156.828 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 52900 loss: 135.497 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 52950 loss: 203.397 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 53000 loss: 197.765 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 53050 loss: 187.872 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 53100 loss: 193.098 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53150 loss: 157.641 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 53200 loss: 168.476 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 53250 loss: 167.760 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 53300 loss: 142.145 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 53350 loss: 164.797 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 53400 loss: 202.340 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53450 loss: 138.614 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 53500 loss: 142.902 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 53550 loss: 175.188 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 53600 loss: 149.562 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 53650 loss: 159.501 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 53700 loss: 187.891 training accuracy: 0.100 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 53750 loss: 180.753 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 53800 loss: 184.999 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 53850 loss: 163.162 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 53900 loss: 123.528 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 53950 loss: 153.601 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 54000 loss: 189.767 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 54050 loss: 147.822 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 54100 loss: 131.527 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 54150 loss: 152.789 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 54200 loss: 215.153 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 54250 loss: 184.762 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 54300 loss: 177.008 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54350 loss: 169.384 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 54400 loss: 162.069 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 54450 loss: 196.016 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 54500 loss: 159.467 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 54550 loss: 173.784 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 54600 loss: 144.826 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 54650 loss: 181.813 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 54700 loss: 191.814 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 54750 loss: 138.341 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 54800 loss: 189.703 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 54850 loss: 180.602 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 54900 loss: 185.715 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 54950 loss: 172.685 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 55000 loss: 124.047 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 55050 loss: 168.413 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 55100 loss: 213.708 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 55150 loss: 152.845 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 55200 loss: 135.487 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 55250 loss: 211.989 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 55300 loss: 207.816 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 55350 loss: 202.575 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 55400 loss: 181.250 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 55450 loss: 204.640 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 55500 loss: 160.797 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 55550 loss: 107.539 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 55600 loss: 217.680 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 55650 loss: 206.704 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55700 loss: 145.096 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 55750 loss: 171.781 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 55800 loss: 202.255 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 55850 loss: 188.398 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 55900 loss: 178.160 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 55950 loss: 198.022 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 56000 loss: 172.630 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 56050 loss: 155.645 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 56100 loss: 182.012 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 56150 loss: 175.014 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56200 loss: 161.149 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 56250 loss: 139.080 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 56300 loss: 166.757 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 56350 loss: 174.675 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56400 loss: 166.847 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 56450 loss: 179.372 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 56500 loss: 168.815 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 56550 loss: 107.417 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 56600 loss: 166.532 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 56650 loss: 148.255 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 56700 loss: 183.748 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 56750 loss: 178.243 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 56800 loss: 131.809 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 56850 loss: 185.346 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56900 loss: 150.340 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 56950 loss: 176.220 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 57000 loss: 153.841 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 57050 loss: 157.947 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 57100 loss: 184.751 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 57150 loss: 153.686 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 57200 loss: 106.955 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 57250 loss: 95.913 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 57300 loss: 221.811 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 57350 loss: 181.011 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 57400 loss: 187.573 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 57450 loss: 161.290 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 57500 loss: 180.581 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 57550 loss: 123.140 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 57600 loss: 204.072 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 57650 loss: 161.038 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 57700 loss: 203.590 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 57750 loss: 206.786 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 57800 loss: 152.952 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 57850 loss: 183.450 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57900 loss: 194.510 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 57950 loss: 201.828 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 58000 loss: 193.650 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 58050 loss: 138.975 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 58100 loss: 191.992 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 58150 loss: 113.845 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 58200 loss: 193.691 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 58250 loss: 152.238 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 58300 loss: 134.148 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 58350 loss: 157.200 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 58400 loss: 176.602 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 58450 loss: 187.818 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58500 loss: 140.654 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 58550 loss: 175.739 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 58600 loss: 157.805 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 58650 loss: 169.307 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 58700 loss: 156.317 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 58750 loss: 147.422 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 58800 loss: 139.924 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 58850 loss: 135.378 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 58900 loss: 179.870 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 58950 loss: 166.187 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 59000 loss: 155.614 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59050 loss: 149.789 training accuracy: 0.100 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 59100 loss: 193.729 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 59150 loss: 197.579 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 59200 loss: 123.469 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 59250 loss: 198.958 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 59300 loss: 141.995 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 59350 loss: 174.344 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 59400 loss: 154.322 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 59450 loss: 108.732 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 59500 loss: 175.186 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 59550 loss: 192.817 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 59600 loss: 170.401 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59650 loss: 176.876 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 59700 loss: 139.923 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 59750 loss: 147.699 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 59800 loss: 140.420 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 59850 loss: 174.868 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 59900 loss: 124.490 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 59950 loss: 169.988 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 60000 loss: 139.696 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 60050 loss: 196.974 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 60100 loss: 161.739 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 60150 loss: 102.553 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 60200 loss: 142.245 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 60250 loss: 189.481 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 60300 loss: 125.673 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 60350 loss: 176.447 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 60400 loss: 176.552 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60450 loss: 138.003 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 60500 loss: 154.372 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 60550 loss: 164.507 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 60600 loss: 149.697 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 60650 loss: 192.180 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 60700 loss: 125.399 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 60750 loss: 154.281 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 60800 loss: 180.320 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60850 loss: 176.558 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 60900 loss: 157.732 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 60950 loss: 95.059 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 61000 loss: 169.513 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 61050 loss: 148.785 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 61100 loss: 155.383 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 61150 loss: 153.208 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 61200 loss: 118.552 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 61250 loss: 188.217 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 61300 loss: 207.635 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 61350 loss: 130.177 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 61400 loss: 164.075 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 61450 loss: 148.006 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 61500 loss: 145.833 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 61550 loss: 135.412 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 61600 loss: 142.427 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 61650 loss: 214.500 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 61700 loss: 166.004 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 61750 loss: 180.381 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 61800 loss: 179.808 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 61850 loss: 144.204 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 61900 loss: 168.718 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 61950 loss: 172.355 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 62000 loss: 144.616 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62050 loss: 149.171 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 62100 loss: 126.350 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 62150 loss: 186.997 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62200 loss: 140.471 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 62250 loss: 203.198 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62300 loss: 168.374 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 62350 loss: 171.670 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 62400 loss: 163.984 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 62450 loss: 149.318 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 62500 loss: 131.711 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 62550 loss: 129.448 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 62600 loss: 189.678 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 62650 loss: 185.094 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62700 loss: 167.007 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 62750 loss: 129.267 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 62800 loss: 161.427 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 62850 loss: 123.970 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 62900 loss: 173.285 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 62950 loss: 188.306 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63000 loss: 184.847 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 63050 loss: 192.085 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 63100 loss: 174.709 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 63150 loss: 192.288 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 63200 loss: 169.240 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 63250 loss: 139.735 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 63300 loss: 171.132 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 63350 loss: 176.750 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 63400 loss: 204.723 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 63450 loss: 146.982 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 63500 loss: 200.091 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63550 loss: 118.949 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 63600 loss: 165.876 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 63650 loss: 154.100 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 63700 loss: 140.743 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 63750 loss: 173.427 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 63800 loss: 158.652 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 63850 loss: 166.014 training accuracy: 0.000 validation accuracy: 0.500 \n",
      "Step 63900 loss: 130.629 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 63950 loss: 179.506 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 64000 loss: 151.831 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 64050 loss: 146.622 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 64100 loss: 133.447 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 64150 loss: 163.885 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 64200 loss: 102.804 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 64250 loss: 143.474 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 64300 loss: 127.278 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 64350 loss: 163.979 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 64400 loss: 167.519 training accuracy: 0.000 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 64450 loss: 96.646 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 64500 loss: 173.007 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 64550 loss: 94.654 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 64600 loss: 167.581 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 64650 loss: 202.118 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 64700 loss: 177.065 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 64750 loss: 151.346 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 64800 loss: 100.884 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 64850 loss: 189.329 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64900 loss: 154.446 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 64950 loss: 137.928 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 65000 loss: 146.262 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65050 loss: 179.968 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65100 loss: 123.323 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 65150 loss: 160.207 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 65200 loss: 140.777 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 65250 loss: 165.659 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 65300 loss: 115.168 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 65350 loss: 118.280 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 65400 loss: 150.396 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 65450 loss: 149.816 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 65500 loss: 158.540 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 65550 loss: 175.970 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 65600 loss: 145.105 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 65650 loss: 139.672 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 65700 loss: 149.916 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 65750 loss: 171.628 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 65800 loss: 165.082 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 65850 loss: 152.823 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 65900 loss: 140.509 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 65950 loss: 187.013 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 66000 loss: 154.917 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 66050 loss: 145.706 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 66100 loss: 157.680 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 66150 loss: 166.382 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 66200 loss: 168.251 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 66250 loss: 170.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 66300 loss: 174.898 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 66350 loss: 199.967 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 66400 loss: 147.617 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 66450 loss: 151.492 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 66500 loss: 141.956 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 66550 loss: 132.214 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 66600 loss: 148.530 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 66650 loss: 132.548 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 66700 loss: 178.834 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 66750 loss: 128.207 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 66800 loss: 176.380 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 66850 loss: 159.958 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 66900 loss: 143.951 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 66950 loss: 166.668 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 67000 loss: 166.317 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 67050 loss: 161.187 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 67100 loss: 115.127 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 67150 loss: 158.171 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 67200 loss: 199.997 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 67250 loss: 180.049 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 67300 loss: 191.399 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 67350 loss: 167.057 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 67400 loss: 166.963 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 67450 loss: 112.304 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 67500 loss: 142.791 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 67550 loss: 153.109 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 67600 loss: 178.940 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 67650 loss: 125.888 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 67700 loss: 149.166 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 67750 loss: 175.366 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 67800 loss: 114.663 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 67850 loss: 151.765 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 67900 loss: 145.174 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 67950 loss: 124.916 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 68000 loss: 165.393 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 68050 loss: 127.653 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 68100 loss: 146.040 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 68150 loss: 171.817 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 68200 loss: 70.159 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 68250 loss: 119.682 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 68300 loss: 151.907 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68350 loss: 100.167 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 68400 loss: 132.969 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 68450 loss: 141.457 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 68500 loss: 161.190 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 68550 loss: 175.824 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 68600 loss: 176.328 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 68650 loss: 162.500 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 68700 loss: 115.895 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 68750 loss: 170.666 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 68800 loss: 142.520 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 68850 loss: 173.512 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 68900 loss: 181.445 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68950 loss: 117.346 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 69000 loss: 145.227 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 69050 loss: 132.490 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 69100 loss: 140.764 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 69150 loss: 153.832 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 69200 loss: 134.412 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 69250 loss: 149.956 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 69300 loss: 157.845 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 69350 loss: 170.465 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 69400 loss: 170.492 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 69450 loss: 132.115 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 69500 loss: 123.344 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 69550 loss: 137.699 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 69600 loss: 138.814 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 69650 loss: 143.923 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 69700 loss: 131.743 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 69750 loss: 105.552 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 69800 loss: 170.527 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 69850 loss: 140.149 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 69900 loss: 133.560 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 69950 loss: 126.963 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 70000 loss: 120.148 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 70050 loss: 145.380 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 70100 loss: 172.497 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 70150 loss: 166.137 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 70200 loss: 129.996 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 70250 loss: 164.522 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 70300 loss: 89.559 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 70350 loss: 147.614 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 70400 loss: 100.720 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 70450 loss: 116.434 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 70500 loss: 110.051 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 70550 loss: 139.087 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 70600 loss: 194.856 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 70650 loss: 150.914 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 70700 loss: 155.130 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 70750 loss: 137.154 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 70800 loss: 142.077 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 70850 loss: 141.118 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 70900 loss: 115.717 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 70950 loss: 189.512 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 71000 loss: 156.574 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 71050 loss: 136.065 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 71100 loss: 126.305 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 71150 loss: 87.703 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 71200 loss: 199.844 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 71250 loss: 125.215 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 71300 loss: 141.754 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 71350 loss: 100.889 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 71400 loss: 137.983 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 71450 loss: 154.521 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71500 loss: 171.086 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 71550 loss: 123.270 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 71600 loss: 137.741 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 71650 loss: 100.624 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 71700 loss: 193.700 training accuracy: 0.000 validation accuracy: 0.500 \n",
      "Step 71750 loss: 142.857 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 71800 loss: 164.810 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 71850 loss: 130.326 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 71900 loss: 112.265 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 71950 loss: 151.477 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72000 loss: 152.179 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 72050 loss: 135.588 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 72100 loss: 126.954 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 72150 loss: 131.155 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 72200 loss: 140.700 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 72250 loss: 140.949 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 72300 loss: 108.644 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 72350 loss: 148.218 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 72400 loss: 105.399 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 72450 loss: 141.229 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 72500 loss: 121.406 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 72550 loss: 166.788 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 72600 loss: 107.043 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 72650 loss: 103.793 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 72700 loss: 119.487 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 72750 loss: 157.915 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 72800 loss: 144.499 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 72850 loss: 152.648 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 72900 loss: 144.380 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 72950 loss: 131.473 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 73000 loss: 147.376 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 73050 loss: 151.902 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 73100 loss: 167.632 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73150 loss: 157.327 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 73200 loss: 146.409 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 73250 loss: 124.711 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 73300 loss: 163.560 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 73350 loss: 161.850 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 73400 loss: 129.936 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 73450 loss: 130.483 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 73500 loss: 107.056 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 73550 loss: 134.257 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 73600 loss: 108.005 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 73650 loss: 135.708 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 73700 loss: 102.758 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 73750 loss: 136.532 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 73800 loss: 150.939 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 73850 loss: 164.183 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 73900 loss: 134.741 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 73950 loss: 145.473 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 74000 loss: 138.264 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 74050 loss: 147.082 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 74100 loss: 156.662 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 74150 loss: 160.019 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 74200 loss: 136.527 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 74250 loss: 153.804 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 74300 loss: 159.379 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 74350 loss: 152.313 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74400 loss: 115.103 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 74450 loss: 83.016 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 74500 loss: 108.264 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 74550 loss: 122.146 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 74600 loss: 141.271 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 74650 loss: 138.160 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 74700 loss: 90.650 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 74750 loss: 144.422 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 74800 loss: 95.030 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 74850 loss: 151.095 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 74900 loss: 134.120 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 74950 loss: 145.252 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 75000 loss: 136.526 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 75050 loss: 138.972 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 75100 loss: 109.435 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 75150 loss: 170.770 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 75200 loss: 101.321 training accuracy: 0.100 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 75250 loss: 137.198 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 75300 loss: 142.045 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 75350 loss: 165.678 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 75400 loss: 119.247 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 75450 loss: 123.103 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 75500 loss: 117.162 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 75550 loss: 159.274 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 75600 loss: 166.880 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75650 loss: 85.052 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 75700 loss: 149.480 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 75750 loss: 149.331 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 75800 loss: 163.265 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 75850 loss: 121.438 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 75900 loss: 91.066 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 75950 loss: 109.474 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 76000 loss: 124.467 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 76050 loss: 170.406 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 76100 loss: 142.123 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 76150 loss: 180.564 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76200 loss: 156.151 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 76250 loss: 137.311 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 76300 loss: 132.083 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 76350 loss: 146.290 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 76400 loss: 120.478 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 76450 loss: 131.800 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 76500 loss: 150.297 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 76550 loss: 163.721 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 76600 loss: 122.968 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76650 loss: 135.623 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 76700 loss: 142.029 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 76750 loss: 161.622 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76800 loss: 150.764 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 76850 loss: 135.178 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 76900 loss: 146.842 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 76950 loss: 105.038 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 77000 loss: 148.824 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77050 loss: 130.853 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 77100 loss: 99.172 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 77150 loss: 125.056 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 77200 loss: 137.624 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 77250 loss: 107.436 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 77300 loss: 138.300 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 77350 loss: 115.680 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 77400 loss: 87.620 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 77450 loss: 156.382 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 77500 loss: 174.494 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77550 loss: 122.684 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 77600 loss: 105.688 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 77650 loss: 122.891 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 77700 loss: 129.866 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 77750 loss: 107.201 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 77800 loss: 141.178 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 77850 loss: 114.912 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 77900 loss: 106.710 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 77950 loss: 91.533 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 78000 loss: 135.606 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 78050 loss: 116.038 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 78100 loss: 130.182 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 78150 loss: 133.317 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 78200 loss: 107.940 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 78250 loss: 150.192 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 78300 loss: 135.697 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 78350 loss: 164.607 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 78400 loss: 149.788 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 78450 loss: 109.202 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 78500 loss: 107.458 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 78550 loss: 136.610 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 78600 loss: 110.940 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 78650 loss: 94.260 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 78700 loss: 135.632 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 78750 loss: 172.058 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 78800 loss: 144.886 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 78850 loss: 122.356 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 78900 loss: 90.656 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 78950 loss: 127.528 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 79000 loss: 166.889 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 79050 loss: 91.037 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 79100 loss: 120.996 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 79150 loss: 113.664 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 79200 loss: 149.781 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 79250 loss: 117.323 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 79300 loss: 118.375 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 79350 loss: 151.531 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 79400 loss: 151.514 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 79450 loss: 136.567 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 79500 loss: 155.056 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 79550 loss: 89.926 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 79600 loss: 147.123 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 79650 loss: 122.928 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 79700 loss: 91.117 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 79750 loss: 152.010 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 79800 loss: 113.834 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 79850 loss: 136.440 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 79900 loss: 159.167 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 79950 loss: 115.230 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 80000 loss: 119.214 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80050 loss: 83.560 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 80100 loss: 135.981 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 80150 loss: 114.277 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 80200 loss: 112.462 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 80250 loss: 141.232 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 80300 loss: 129.870 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 80350 loss: 111.011 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 80400 loss: 150.045 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 80450 loss: 121.119 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 80500 loss: 163.043 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80550 loss: 136.183 training accuracy: 0.200 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 80600 loss: 121.708 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 80650 loss: 92.267 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 80700 loss: 130.181 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 80750 loss: 181.617 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 80800 loss: 133.584 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 80850 loss: 128.447 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 80900 loss: 160.365 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 80950 loss: 150.614 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 81000 loss: 116.765 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 81050 loss: 96.028 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 81100 loss: 117.668 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 81150 loss: 137.881 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 81200 loss: 137.740 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 81250 loss: 116.906 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 81300 loss: 137.283 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 81350 loss: 98.876 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 81400 loss: 118.798 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 81450 loss: 137.176 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 81500 loss: 126.774 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 81550 loss: 157.429 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 81600 loss: 96.690 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 81650 loss: 160.905 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 81700 loss: 104.168 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 81750 loss: 129.009 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 81800 loss: 122.244 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 81850 loss: 114.505 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 81900 loss: 99.505 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 81950 loss: 104.065 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 82000 loss: 97.989 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 82050 loss: 92.385 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 82100 loss: 143.615 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 82150 loss: 122.137 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 82200 loss: 124.982 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 82250 loss: 108.104 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 82300 loss: 105.285 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 82350 loss: 88.278 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 82400 loss: 130.263 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 82450 loss: 126.450 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 82500 loss: 60.914 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 82550 loss: 135.313 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 82600 loss: 101.294 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 82650 loss: 140.300 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 82700 loss: 150.776 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 82750 loss: 90.459 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 82800 loss: 139.706 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 82850 loss: 116.514 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 82900 loss: 116.337 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 82950 loss: 137.865 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 83000 loss: 127.282 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 83050 loss: 138.487 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 83100 loss: 120.917 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 83150 loss: 124.773 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 83200 loss: 123.383 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 83250 loss: 72.290 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 83300 loss: 116.727 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 83350 loss: 117.856 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 83400 loss: 108.466 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 83450 loss: 91.170 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 83500 loss: 134.382 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 83550 loss: 108.341 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 83600 loss: 121.887 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 83650 loss: 154.095 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83700 loss: 125.780 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 83750 loss: 104.450 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 83800 loss: 88.498 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 83850 loss: 120.330 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 83900 loss: 137.168 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 83950 loss: 85.542 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 84000 loss: 102.713 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 84050 loss: 78.873 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 84100 loss: 145.190 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 84150 loss: 124.149 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 84200 loss: 120.533 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 84250 loss: 78.487 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 84300 loss: 86.582 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 84350 loss: 114.660 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 84400 loss: 122.683 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 84450 loss: 119.288 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 84500 loss: 103.575 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 84550 loss: 122.260 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 84600 loss: 99.190 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 84650 loss: 131.037 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 84700 loss: 125.351 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 84750 loss: 108.503 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 84800 loss: 108.312 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 84850 loss: 140.952 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 84900 loss: 128.389 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 84950 loss: 99.040 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 85000 loss: 141.365 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 85050 loss: 69.020 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 85100 loss: 37.546 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 85150 loss: 108.718 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 85200 loss: 133.830 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 85250 loss: 122.051 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 85300 loss: 76.521 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 85350 loss: 122.409 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 85400 loss: 100.507 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 85450 loss: 110.914 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 85500 loss: 101.420 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 85550 loss: 100.940 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 85600 loss: 83.500 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 85650 loss: 137.618 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 85700 loss: 88.353 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 85750 loss: 114.251 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 85800 loss: 98.558 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 85850 loss: 144.116 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 85900 loss: 115.697 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 85950 loss: 130.677 training accuracy: 0.200 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 86000 loss: 98.003 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 86050 loss: 103.729 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 86100 loss: 116.225 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 86150 loss: 122.703 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 86200 loss: 108.453 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 86250 loss: 71.823 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 86300 loss: 113.627 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 86350 loss: 107.276 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 86400 loss: 77.426 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 86450 loss: 168.496 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 86500 loss: 151.050 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 86550 loss: 108.690 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 86600 loss: 62.307 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 86650 loss: 75.762 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 86700 loss: 148.400 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 86750 loss: 137.499 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 86800 loss: 85.454 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 86850 loss: 87.322 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 86900 loss: 103.855 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 86950 loss: 103.087 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 87000 loss: 124.355 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 87050 loss: 119.897 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 87100 loss: 114.364 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 87150 loss: 106.344 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 87200 loss: 89.792 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 87250 loss: 118.052 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 87300 loss: 89.732 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 87350 loss: 91.444 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 87400 loss: 116.555 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 87450 loss: 119.588 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 87500 loss: 126.620 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 87550 loss: 150.245 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 87600 loss: 76.319 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 87650 loss: 137.566 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 87700 loss: 127.808 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 87750 loss: 97.234 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 87800 loss: 68.986 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 87850 loss: 108.301 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 87900 loss: 111.291 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 87950 loss: 105.033 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 88000 loss: 130.166 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 88050 loss: 83.590 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 88100 loss: 96.761 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 88150 loss: 111.148 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 88200 loss: 121.629 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 88250 loss: 67.181 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 88300 loss: 121.081 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 88350 loss: 106.886 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 88400 loss: 62.785 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 88450 loss: 122.480 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 88500 loss: 103.755 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 88550 loss: 97.384 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 88600 loss: 90.522 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 88650 loss: 115.591 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 88700 loss: 68.250 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 88750 loss: 103.846 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 88800 loss: 75.456 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 88850 loss: 92.702 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 88900 loss: 76.695 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 88950 loss: 67.258 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 89000 loss: 71.085 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 89050 loss: 97.206 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 89100 loss: 92.096 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 89150 loss: 78.289 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 89200 loss: 84.726 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 89250 loss: 64.488 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 89300 loss: 123.963 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 89350 loss: 67.661 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 89400 loss: 82.552 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 89450 loss: 91.814 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 89500 loss: 101.204 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 89550 loss: 100.468 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 89600 loss: 79.655 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 89650 loss: 88.853 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 89700 loss: 118.615 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 89750 loss: 50.659 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 89800 loss: 131.821 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 89850 loss: 71.046 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 89900 loss: 82.777 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 89950 loss: 130.941 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 90000 loss: 109.004 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 90050 loss: 106.219 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 90100 loss: 60.725 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 90150 loss: 80.514 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 90200 loss: 163.513 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 90250 loss: 98.240 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 90300 loss: 108.356 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 90350 loss: 90.963 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 90400 loss: 63.640 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 90450 loss: 66.210 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 90500 loss: 124.007 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 90550 loss: 51.589 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 90600 loss: 73.191 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 90650 loss: 74.776 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 90700 loss: 33.522 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 90750 loss: 93.696 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 90800 loss: 49.591 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 90850 loss: 59.789 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 90900 loss: 123.434 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 90950 loss: 82.834 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 91000 loss: 92.753 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 91050 loss: 104.717 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 91100 loss: 140.504 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 91150 loss: 118.937 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 91200 loss: 107.122 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 91250 loss: 131.023 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 91300 loss: 76.946 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 91350 loss: 125.200 training accuracy: 0.300 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 91400 loss: 60.835 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 91450 loss: 109.718 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 91500 loss: 116.552 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 91550 loss: 86.682 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 91600 loss: 73.496 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 91650 loss: 77.282 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 91700 loss: 81.182 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 91750 loss: 94.117 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 91800 loss: 60.237 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 91850 loss: 100.165 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 91900 loss: 84.943 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 91950 loss: 29.131 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 92000 loss: 109.674 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 92050 loss: 62.252 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 92100 loss: 92.961 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 92150 loss: 73.694 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 92200 loss: 106.592 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 92250 loss: 133.133 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 92300 loss: 53.925 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 92350 loss: 105.000 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 92400 loss: 38.402 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 92450 loss: 105.142 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 92500 loss: 89.487 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 92550 loss: 83.294 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 92600 loss: 59.382 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 92650 loss: 119.456 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 92700 loss: 111.368 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 92750 loss: 62.477 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 92800 loss: 73.408 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 92850 loss: 134.264 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 92900 loss: 61.871 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 92950 loss: 95.019 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 93000 loss: 98.145 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 93050 loss: 99.719 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 93100 loss: 56.433 training accuracy: 0.700 validation accuracy: 0.000 \n",
      "Step 93150 loss: 78.427 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 93200 loss: 92.298 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 93250 loss: 106.772 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 93300 loss: 111.939 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 93350 loss: 55.357 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 93400 loss: 95.681 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 93450 loss: 63.206 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 93500 loss: 96.300 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 93550 loss: 74.483 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 93600 loss: 76.859 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 93650 loss: 119.549 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 93700 loss: 117.514 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 93750 loss: 82.125 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 93800 loss: 17.113 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 93850 loss: 83.990 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 93900 loss: 128.543 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 93950 loss: 109.637 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 94000 loss: 114.051 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 94050 loss: 95.743 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 94100 loss: 155.358 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 94150 loss: 87.886 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 94200 loss: 77.829 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 94250 loss: 79.740 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 94300 loss: 139.444 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 94350 loss: 37.994 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 94400 loss: 45.881 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 94450 loss: 92.014 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 94500 loss: 101.319 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 94550 loss: 84.661 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 94600 loss: 77.382 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 94650 loss: 48.003 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 94700 loss: 77.938 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 94750 loss: 136.907 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 94800 loss: 66.844 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 94850 loss: 57.674 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 94900 loss: 176.237 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 94950 loss: 88.491 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 95000 loss: 32.677 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 95050 loss: 80.529 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 95100 loss: 132.501 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 95150 loss: 107.419 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 95200 loss: 64.687 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 95250 loss: 96.636 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 95300 loss: 82.771 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 95350 loss: 65.109 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 95400 loss: 82.850 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 95450 loss: 91.663 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 95500 loss: 150.988 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 95550 loss: 98.161 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 95600 loss: 112.043 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 95650 loss: 96.712 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 95700 loss: 96.549 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 95750 loss: 57.933 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 95800 loss: 103.729 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 95850 loss: 102.069 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 95900 loss: 79.213 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 95950 loss: 135.642 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 96000 loss: 82.093 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 96050 loss: 130.607 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 96100 loss: 107.567 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 96150 loss: 76.038 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 96200 loss: 52.465 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 96250 loss: 103.718 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 96300 loss: 91.742 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 96350 loss: 124.200 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 96400 loss: 71.432 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 96450 loss: 88.584 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 96500 loss: 92.390 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 96550 loss: 96.900 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 96600 loss: 81.198 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 96650 loss: 76.893 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 96700 loss: 63.342 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 96750 loss: 107.014 training accuracy: 0.300 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 96800 loss: 88.700 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 96850 loss: 87.811 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 96900 loss: 92.589 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 96950 loss: 116.224 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 97000 loss: 93.166 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 97050 loss: 147.660 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 97100 loss: 78.540 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 97150 loss: 76.203 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 97200 loss: 88.476 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 97250 loss: 79.677 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 97300 loss: 79.598 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 97350 loss: 128.391 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 97400 loss: 73.544 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 97450 loss: 117.074 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 97500 loss: 131.116 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 97550 loss: 109.838 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 97600 loss: 76.577 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 97650 loss: 61.799 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 97700 loss: 83.292 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 97750 loss: 61.476 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 97800 loss: 93.048 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 97850 loss: 93.208 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 97900 loss: 92.508 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 97950 loss: 111.777 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 98000 loss: 108.993 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 98050 loss: 102.773 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 98100 loss: 121.905 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 98150 loss: 99.783 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 98200 loss: 83.846 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 98250 loss: 55.864 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 98300 loss: 35.545 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 98350 loss: 83.738 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 98400 loss: 61.568 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 98450 loss: 34.866 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 98500 loss: 95.438 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 98550 loss: 76.045 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 98600 loss: 107.197 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 98650 loss: 63.713 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 98700 loss: 53.383 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 98750 loss: 96.882 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 98800 loss: 48.219 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 98850 loss: 121.098 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 98900 loss: 77.815 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 98950 loss: 46.804 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 99000 loss: 46.279 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 99050 loss: 90.302 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 99100 loss: 44.404 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 99150 loss: 76.795 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 99200 loss: 86.826 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 99250 loss: 76.286 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 99300 loss: 60.327 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 99350 loss: 78.654 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 99400 loss: 62.514 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 99450 loss: 131.755 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 99500 loss: 102.241 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 99550 loss: 93.343 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 99600 loss: 96.759 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 99650 loss: 97.878 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 99700 loss: 62.497 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 99750 loss: 106.759 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 99800 loss: 139.087 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 99850 loss: 105.754 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 99900 loss: 64.193 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 99950 loss: 66.332 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 100000 loss: 76.635 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 100050 loss: 85.295 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 100100 loss: 119.762 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 100150 loss: 73.507 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 100200 loss: 77.799 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 100250 loss: 66.889 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 100300 loss: 69.896 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 100350 loss: 65.034 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 100400 loss: 115.486 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 100450 loss: 78.509 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 100500 loss: 113.517 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 100550 loss: 5.202 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 100600 loss: 64.082 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 100650 loss: 135.572 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 100700 loss: 86.258 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 100750 loss: 61.238 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 100800 loss: 76.864 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 100850 loss: 65.874 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 100900 loss: 85.061 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 100950 loss: 53.579 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 101000 loss: 75.090 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 101050 loss: 87.708 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 101100 loss: 95.068 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 101150 loss: 44.017 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 101200 loss: 70.715 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 101250 loss: 46.162 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 101300 loss: 127.155 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 101350 loss: 92.625 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 101400 loss: 83.666 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 101450 loss: 31.402 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 101500 loss: 73.545 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 101550 loss: 56.243 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 101600 loss: 61.451 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 101650 loss: 48.492 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 101700 loss: 61.186 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 101750 loss: 57.902 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 101800 loss: 70.499 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 101850 loss: 61.065 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 101900 loss: 71.726 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 101950 loss: 78.093 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 102000 loss: 47.231 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 102050 loss: 114.680 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 102100 loss: 54.216 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 102150 loss: 134.526 training accuracy: 0.200 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 102200 loss: 80.876 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 102250 loss: 62.346 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 102300 loss: 137.028 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 102350 loss: 138.875 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 102400 loss: 93.672 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 102450 loss: 97.312 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 102500 loss: 73.944 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 102550 loss: 90.758 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 102600 loss: 45.566 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 102650 loss: 91.403 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 102700 loss: 122.464 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 102750 loss: 187.190 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 102800 loss: 45.482 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 102850 loss: 92.493 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 102900 loss: 80.716 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 102950 loss: 65.094 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 103000 loss: 48.057 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 103050 loss: 82.993 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 103100 loss: 101.735 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 103150 loss: 119.222 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 103200 loss: 76.198 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 103250 loss: 58.636 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 103300 loss: 92.321 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 103350 loss: 90.125 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 103400 loss: 37.906 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 103450 loss: 129.507 training accuracy: 0.100 validation accuracy: 0.700 \n",
      "Step 103500 loss: 63.112 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 103550 loss: 70.745 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 103600 loss: 67.763 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 103650 loss: 67.596 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 103700 loss: 29.293 training accuracy: 0.900 validation accuracy: 0.200 \n",
      "Step 103750 loss: 61.897 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 103800 loss: 98.737 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 103850 loss: 139.071 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 103900 loss: 63.967 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 103950 loss: 55.895 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 104000 loss: 45.949 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 104050 loss: 81.637 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 104100 loss: 33.163 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 104150 loss: 31.760 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 104200 loss: 89.144 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 104250 loss: 84.632 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 104300 loss: 40.656 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 104350 loss: 46.709 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 104400 loss: 112.106 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 104450 loss: 106.900 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 104500 loss: 78.214 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 104550 loss: 92.228 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 104600 loss: 63.499 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 104650 loss: 92.146 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 104700 loss: 94.118 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 104750 loss: 109.003 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 104800 loss: 77.128 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 104850 loss: 78.232 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 104900 loss: 47.254 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 104950 loss: 60.069 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 105000 loss: 82.152 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 105050 loss: 63.204 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 105100 loss: 72.978 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 105150 loss: 61.266 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 105200 loss: 45.902 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 105250 loss: 69.935 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 105300 loss: 76.176 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 105350 loss: 87.112 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 105400 loss: 118.221 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 105450 loss: 68.806 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 105500 loss: 44.729 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 105550 loss: 103.894 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 105600 loss: 77.695 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 105650 loss: 103.163 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 105700 loss: 78.776 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 105750 loss: 50.287 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 105800 loss: 91.931 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 105850 loss: 77.654 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 105900 loss: 95.943 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 105950 loss: 45.705 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 106000 loss: 90.209 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 106050 loss: 65.195 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 106100 loss: 91.540 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 106150 loss: 61.931 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 106200 loss: 94.519 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 106250 loss: 92.715 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 106300 loss: 89.043 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 106350 loss: 64.660 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 106400 loss: 80.914 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 106450 loss: 108.139 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 106500 loss: 58.633 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 106550 loss: 61.729 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 106600 loss: 77.800 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 106650 loss: 46.826 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 106700 loss: 75.525 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 106750 loss: 51.078 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 106800 loss: 139.047 training accuracy: 0.000 validation accuracy: 0.800 \n",
      "Step 106850 loss: 104.244 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 106900 loss: 77.322 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 106950 loss: 65.096 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 107000 loss: 91.574 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 107050 loss: 61.727 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 107100 loss: 136.500 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 107150 loss: 61.710 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 107200 loss: 51.415 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 107250 loss: 36.830 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 107300 loss: 92.961 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 107350 loss: 83.429 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 107400 loss: 68.318 training accuracy: 0.500 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 107450 loss: 51.573 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 107500 loss: 111.455 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 107550 loss: 100.612 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 107600 loss: 47.304 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 107650 loss: 33.800 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 107700 loss: 32.544 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 107750 loss: 47.164 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 107800 loss: 92.683 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 107850 loss: 62.140 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 107900 loss: 91.176 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 107950 loss: 31.862 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 108000 loss: 77.216 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 108050 loss: 27.991 training accuracy: 0.900 validation accuracy: 0.200 \n",
      "Step 108100 loss: 112.210 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 108150 loss: 66.824 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 108200 loss: 75.097 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 108250 loss: 101.704 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 108300 loss: 58.629 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 108350 loss: 71.482 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 108400 loss: 92.788 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 108450 loss: 169.974 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 108500 loss: 70.722 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 108550 loss: 92.811 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 108600 loss: 62.889 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 108650 loss: 58.931 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 108700 loss: 33.830 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 108750 loss: 81.679 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 108800 loss: 60.626 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 108850 loss: 85.408 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 108900 loss: 46.613 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 108950 loss: 78.876 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 109000 loss: 24.561 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 109050 loss: 71.443 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 109100 loss: 117.708 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 109150 loss: 64.361 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 109200 loss: 63.630 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 109250 loss: 106.750 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 109300 loss: 83.564 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 109350 loss: 109.866 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 109400 loss: 81.108 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 109450 loss: 32.814 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 109500 loss: 88.133 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 109550 loss: 121.271 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 109600 loss: 57.806 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 109650 loss: 62.477 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 109700 loss: 73.020 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 109750 loss: 96.436 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 109800 loss: 61.998 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 109850 loss: 47.029 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 109900 loss: 76.776 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 109950 loss: 45.019 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 110000 loss: 35.848 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 110050 loss: 98.783 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 110100 loss: 74.374 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 110150 loss: 143.140 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 110200 loss: 63.948 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 110250 loss: 132.908 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 110300 loss: 76.272 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 110350 loss: 76.376 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 110400 loss: 88.676 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 110450 loss: 39.664 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 110500 loss: 119.633 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 110550 loss: 86.138 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 110600 loss: 48.783 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 110650 loss: 87.486 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 110700 loss: 50.022 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 110750 loss: 98.842 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 110800 loss: 83.952 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 110850 loss: 70.684 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 110900 loss: 64.861 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 110950 loss: 32.430 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 111000 loss: 94.158 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 111050 loss: 73.868 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 111100 loss: 99.081 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 111150 loss: 73.356 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 111200 loss: 47.496 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 111250 loss: 73.042 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 111300 loss: 51.214 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 111350 loss: 100.365 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 111400 loss: 84.043 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 111450 loss: 91.216 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 111500 loss: 103.405 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 111550 loss: 127.508 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 111600 loss: 74.009 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 111650 loss: 92.195 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 111700 loss: 85.170 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 111750 loss: 85.618 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 111800 loss: 43.284 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 111850 loss: 80.938 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 111900 loss: 59.737 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 111950 loss: 86.576 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 112000 loss: 55.741 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 112050 loss: 78.875 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 112100 loss: 71.080 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 112150 loss: 63.545 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 112200 loss: 97.499 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 112250 loss: 104.750 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 112300 loss: 74.866 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 112350 loss: 57.263 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 112400 loss: 76.264 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 112450 loss: 78.605 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 112500 loss: 76.364 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 112550 loss: 60.759 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 112600 loss: 101.997 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 112650 loss: 68.737 training accuracy: 0.500 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 112700 loss: 106.494 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 112750 loss: 134.182 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 112800 loss: 53.114 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 112850 loss: 82.454 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 112900 loss: 50.596 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 112950 loss: 101.618 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 113000 loss: 61.937 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 113050 loss: 71.175 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 113100 loss: 105.410 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 113150 loss: 31.310 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 113200 loss: 126.121 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 113250 loss: 78.042 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 113300 loss: 69.102 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 113350 loss: 62.653 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 113400 loss: 130.226 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 113450 loss: 90.504 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 113500 loss: 79.183 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 113550 loss: 48.698 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 113600 loss: 77.499 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 113650 loss: 64.142 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 113700 loss: 76.498 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 113750 loss: 63.805 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 113800 loss: 92.226 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 113850 loss: 91.472 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 113900 loss: 62.751 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 113950 loss: 46.674 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 114000 loss: 95.366 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 114050 loss: 89.963 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 114100 loss: 81.654 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 114150 loss: 92.803 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 114200 loss: 66.541 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 114250 loss: 76.614 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 114300 loss: 85.981 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 114350 loss: 49.611 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 114400 loss: 66.283 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 114450 loss: 51.158 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 114500 loss: 82.904 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 114550 loss: 94.725 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 114600 loss: 79.249 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 114650 loss: 93.074 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 114700 loss: 62.246 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 114750 loss: 78.464 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 114800 loss: 102.452 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 114850 loss: 91.220 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 114900 loss: 90.055 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 114950 loss: 136.796 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 115000 loss: 94.381 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 115050 loss: 100.430 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 115100 loss: 103.859 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 115150 loss: 89.061 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 115200 loss: 54.706 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 115250 loss: 134.906 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 115300 loss: 129.486 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 115350 loss: 67.847 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 115400 loss: 49.027 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 115450 loss: 79.457 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 115500 loss: 78.407 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 115550 loss: 93.890 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 115600 loss: 67.458 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 115650 loss: 46.344 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 115700 loss: 46.086 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 115750 loss: 62.433 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 115800 loss: 61.765 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 115850 loss: 80.846 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 115900 loss: 77.852 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 115950 loss: 52.152 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 116000 loss: 47.413 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 116050 loss: 47.909 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 116100 loss: 62.163 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 116150 loss: 76.831 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 116200 loss: 68.233 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 116250 loss: 94.454 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 116300 loss: 92.800 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 116350 loss: 90.283 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 116400 loss: 106.431 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 116450 loss: 66.970 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 116500 loss: 58.299 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 116550 loss: 102.778 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 116600 loss: 63.878 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 116650 loss: 90.336 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 116700 loss: 54.345 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 116750 loss: 112.915 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 116800 loss: 91.693 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 116850 loss: 46.350 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 116900 loss: 108.873 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 116950 loss: 89.371 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 117000 loss: 117.351 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 117050 loss: 70.933 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 117100 loss: 78.806 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 117150 loss: 144.323 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 117200 loss: 60.784 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 117250 loss: 62.389 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 117300 loss: 77.781 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 117350 loss: 61.021 training accuracy: 0.700 validation accuracy: 0.000 \n",
      "Step 117400 loss: 106.419 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 117450 loss: 20.544 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 117500 loss: 108.218 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 117550 loss: 68.076 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 117600 loss: 68.040 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 117650 loss: 78.695 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 117700 loss: 61.752 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 117750 loss: 93.127 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 117800 loss: 56.887 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 117850 loss: 93.297 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 117900 loss: 74.742 training accuracy: 0.600 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 117950 loss: 77.899 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 118000 loss: 47.334 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 118050 loss: 110.114 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 118100 loss: 40.958 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 118150 loss: 77.105 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 118200 loss: 90.513 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 118250 loss: 30.823 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 118300 loss: 49.643 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 118350 loss: 33.228 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 118400 loss: 119.082 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 118450 loss: 30.826 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 118500 loss: 78.832 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 118550 loss: 105.086 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 118600 loss: 84.505 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 118650 loss: 18.045 training accuracy: 0.900 validation accuracy: 0.000 \n",
      "Step 118700 loss: 32.787 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 118750 loss: 66.097 training accuracy: 0.600 validation accuracy: 0.900 \n",
      "Step 118800 loss: 76.165 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 118850 loss: 79.688 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 118900 loss: 25.463 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 118950 loss: 58.836 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 119000 loss: 95.259 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 119050 loss: 129.686 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 119100 loss: 70.689 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 119150 loss: 32.219 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 119200 loss: 116.562 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 119250 loss: 110.087 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 119300 loss: 93.266 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 119350 loss: 16.193 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 119400 loss: 86.816 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 119450 loss: 36.838 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 119500 loss: 77.526 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 119550 loss: 96.068 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 119600 loss: 60.842 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 119650 loss: 16.129 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 119700 loss: 52.592 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 119750 loss: 65.005 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 119800 loss: 160.403 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 119850 loss: 59.822 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 119900 loss: 99.364 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 119950 loss: 78.550 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 120000 loss: 114.374 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 120050 loss: 49.845 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 120100 loss: 77.489 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 120150 loss: 62.742 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 120200 loss: 70.776 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 120250 loss: 74.672 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 120300 loss: 107.143 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 120350 loss: 43.935 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 120400 loss: 74.386 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 120450 loss: 88.663 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 120500 loss: 61.677 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 120550 loss: 91.474 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 120600 loss: 78.665 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 120650 loss: 60.760 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 120700 loss: 125.532 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 120750 loss: 89.900 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 120800 loss: 92.881 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 120850 loss: 82.495 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 120900 loss: 76.836 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 120950 loss: 42.376 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 121000 loss: 92.797 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 121050 loss: 79.435 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 121100 loss: 58.855 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 121150 loss: 105.548 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 121200 loss: 43.549 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 121250 loss: 86.862 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 121300 loss: 76.187 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 121350 loss: 112.397 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 121400 loss: 47.530 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 121450 loss: 92.284 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 121500 loss: 45.774 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 121550 loss: 64.450 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 121600 loss: 109.194 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 121650 loss: 73.174 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 121700 loss: 57.303 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 121750 loss: 69.806 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 121800 loss: 76.889 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 121850 loss: 77.330 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 121900 loss: 77.017 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 121950 loss: 46.530 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 122000 loss: 105.389 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 122050 loss: 107.221 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 122100 loss: 86.500 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 122150 loss: 63.694 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 122200 loss: 46.888 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 122250 loss: 121.456 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 122300 loss: 122.545 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 122350 loss: 60.672 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 122400 loss: 150.629 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 122450 loss: 108.131 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 122500 loss: 65.499 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 122550 loss: 62.190 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 122600 loss: 101.796 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 122650 loss: 37.331 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 122700 loss: 49.166 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 122750 loss: 66.447 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 122800 loss: 46.918 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 122850 loss: 63.802 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 122900 loss: 44.836 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 122950 loss: 52.911 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 123000 loss: 61.961 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 123050 loss: 67.430 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 123100 loss: 66.072 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 123150 loss: 74.874 training accuracy: 0.600 validation accuracy: 0.700 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 123200 loss: 64.156 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 123250 loss: 104.958 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 123300 loss: 44.760 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 123350 loss: 93.015 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 123400 loss: 32.778 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 123450 loss: 32.841 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 123500 loss: 90.539 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 123550 loss: 141.613 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 123600 loss: 94.945 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 123650 loss: 41.444 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 123700 loss: 109.511 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 123750 loss: 81.023 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 123800 loss: 77.286 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 123850 loss: 53.240 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 123900 loss: 104.874 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 123950 loss: 76.002 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 124000 loss: 60.936 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 124050 loss: 79.394 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 124100 loss: 95.315 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 124150 loss: 87.552 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 124200 loss: 115.810 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 124250 loss: 64.213 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 124300 loss: 105.624 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 124350 loss: 70.055 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 124400 loss: 30.519 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 124450 loss: 100.789 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 124500 loss: 65.025 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 124550 loss: 98.239 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 124600 loss: 76.726 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 124650 loss: 100.355 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 124700 loss: 108.290 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 124750 loss: 91.535 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 124800 loss: 104.438 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 124850 loss: 97.038 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 124900 loss: 76.585 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 124950 loss: 63.596 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 125000 loss: 60.951 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 125050 loss: 74.411 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 125100 loss: 52.041 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 125150 loss: 89.004 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 125200 loss: 65.358 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 125250 loss: 26.844 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 125300 loss: 108.224 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 125350 loss: 46.083 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 125400 loss: 84.820 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 125450 loss: 105.188 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 125500 loss: 129.710 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 125550 loss: 76.837 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 125600 loss: 88.705 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 125650 loss: 65.172 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 125700 loss: 76.576 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 125750 loss: 79.013 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 125800 loss: 31.561 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 125850 loss: 93.473 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 125900 loss: 73.363 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 125950 loss: 96.007 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 126000 loss: 77.464 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 126050 loss: 88.579 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 126100 loss: 45.944 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 126150 loss: 18.129 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 126200 loss: 61.464 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 126250 loss: 86.584 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 126300 loss: 62.177 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 126350 loss: 63.831 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 126400 loss: 95.744 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 126450 loss: 108.835 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 126500 loss: 90.911 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 126550 loss: 61.722 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 126600 loss: 76.156 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 126650 loss: 76.553 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 126700 loss: 105.163 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 126750 loss: 70.339 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 126800 loss: 32.306 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 126850 loss: 85.209 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 126900 loss: 88.011 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 126950 loss: 76.443 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 127000 loss: 75.485 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 127050 loss: 119.434 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 127100 loss: 75.635 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 127150 loss: 34.106 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 127200 loss: 84.131 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 127250 loss: 74.908 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 127300 loss: 61.356 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 127350 loss: 133.013 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 127400 loss: 118.311 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 127450 loss: 47.210 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 127500 loss: 58.475 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 127550 loss: 72.377 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 127600 loss: 50.367 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 127650 loss: 87.798 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 127700 loss: 78.534 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 127750 loss: 31.557 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 127800 loss: 127.150 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 127850 loss: 75.912 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 127900 loss: 144.277 training accuracy: 0.200 validation accuracy: 0.700 \n",
      "Step 127950 loss: 83.255 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 128000 loss: 34.404 training accuracy: 0.700 validation accuracy: 0.800 \n",
      "Step 128050 loss: 34.786 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 128100 loss: 60.643 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 128150 loss: 132.820 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 128200 loss: 94.675 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 128250 loss: 31.698 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 128300 loss: 44.688 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 128350 loss: 63.254 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 128400 loss: 43.596 training accuracy: 0.700 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 128450 loss: 79.656 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 128500 loss: 34.559 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 128550 loss: 62.377 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 128600 loss: 66.852 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 128650 loss: 62.975 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 128700 loss: 95.293 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 128750 loss: 76.203 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 128800 loss: 36.478 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 128850 loss: 25.889 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 128900 loss: 76.223 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 128950 loss: 66.406 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 129000 loss: 76.037 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 129050 loss: 75.792 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 129100 loss: 106.322 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 129150 loss: 105.560 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 129200 loss: 32.060 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 129250 loss: 187.175 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 129300 loss: 105.790 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 129350 loss: 84.620 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 129400 loss: 16.402 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 129450 loss: 46.881 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 129500 loss: 86.053 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 129550 loss: 100.174 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 129600 loss: 99.633 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 129650 loss: 94.618 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 129700 loss: 91.900 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 129750 loss: 127.806 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 129800 loss: 92.249 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 129850 loss: 120.709 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 129900 loss: 85.118 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 129950 loss: 75.635 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 130000 loss: 63.125 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 130050 loss: 88.024 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 130100 loss: 73.446 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 130150 loss: 60.999 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 130200 loss: 71.129 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 130250 loss: 118.152 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 130300 loss: 59.274 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 130350 loss: 86.376 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 130400 loss: 48.153 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 130450 loss: 44.492 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 130500 loss: 89.073 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 130550 loss: 96.599 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 130600 loss: 66.160 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 130650 loss: 73.224 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 130700 loss: 91.884 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 130750 loss: 15.973 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 130800 loss: 46.803 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 130850 loss: 75.844 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 130900 loss: 76.203 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 130950 loss: 19.906 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 131000 loss: 16.397 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 131050 loss: 75.403 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 131100 loss: 63.742 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 131150 loss: 63.170 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 131200 loss: 91.934 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 131250 loss: 105.706 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 131300 loss: 61.674 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 131350 loss: 92.946 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 131400 loss: 77.903 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 131450 loss: 62.050 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 131500 loss: 74.292 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 131550 loss: 85.720 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 131600 loss: 90.220 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 131650 loss: 16.187 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 131700 loss: 114.391 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 131750 loss: 45.669 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 131800 loss: 47.520 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 131850 loss: 43.706 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 131900 loss: 61.820 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 131950 loss: 51.171 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 132000 loss: 68.583 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 132050 loss: 96.620 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 132100 loss: 133.997 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 132150 loss: 90.107 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 132200 loss: 48.126 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 132250 loss: 41.481 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 132300 loss: 74.105 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 132350 loss: 78.195 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 132400 loss: 74.695 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 132450 loss: 61.204 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 132500 loss: 68.517 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 132550 loss: 148.695 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 132600 loss: 93.640 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 132650 loss: 32.115 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 132700 loss: 77.520 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 132750 loss: 66.510 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 132800 loss: 32.777 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 132850 loss: 35.851 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 132900 loss: 74.199 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 132950 loss: 79.200 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 133000 loss: 59.654 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 133050 loss: 95.892 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 133100 loss: 73.402 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 133150 loss: 88.551 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 133200 loss: 59.791 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 133250 loss: 48.716 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 133300 loss: 74.226 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 133350 loss: 50.910 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 133400 loss: 63.676 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 133450 loss: 61.800 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 133500 loss: 139.980 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 133550 loss: 77.373 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 133600 loss: 65.252 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 133650 loss: 120.907 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 133700 loss: 45.019 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 133750 loss: 4.350 training accuracy: 1.000 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 133800 loss: 89.922 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 133850 loss: 36.610 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 133900 loss: 60.109 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 133950 loss: 76.592 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 134000 loss: 84.457 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 134050 loss: 50.265 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 134100 loss: 89.424 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 134150 loss: 61.661 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 134200 loss: 44.980 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 134250 loss: 79.912 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 134300 loss: 64.240 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 134350 loss: 135.465 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 134400 loss: 54.718 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 134450 loss: 77.411 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 134500 loss: 32.207 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 134550 loss: 94.268 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 134600 loss: 39.295 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 134650 loss: 46.875 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 134700 loss: 16.683 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 134750 loss: 62.477 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 134800 loss: 32.440 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 134850 loss: 61.616 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 134900 loss: 46.654 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 134950 loss: 54.856 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 135000 loss: 105.573 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 135050 loss: 50.693 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 135100 loss: 90.008 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 135150 loss: 83.310 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 135200 loss: 101.760 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 135250 loss: 77.621 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 135300 loss: 90.034 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 135350 loss: 90.318 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 135400 loss: 75.237 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 135450 loss: 47.934 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 135500 loss: 73.083 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 135550 loss: 60.428 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 135600 loss: 32.050 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 135650 loss: 56.670 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 135700 loss: 116.991 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 135750 loss: 61.729 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 135800 loss: 17.016 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 135850 loss: 87.012 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 135900 loss: 75.272 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 135950 loss: 45.061 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 136000 loss: 45.716 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 136050 loss: 76.858 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 136100 loss: 92.938 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 136150 loss: 61.886 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 136200 loss: 39.134 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 136250 loss: 118.470 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 136300 loss: 58.994 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 136350 loss: 114.684 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 136400 loss: 32.285 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 136450 loss: 45.946 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 136500 loss: 78.677 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 136550 loss: 60.937 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 136600 loss: 79.845 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 136650 loss: 71.414 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 136700 loss: 44.692 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 136750 loss: 92.047 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 136800 loss: 78.486 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 136850 loss: 113.936 training accuracy: 0.300 validation accuracy: 0.800 \n",
      "Step 136900 loss: 60.030 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 136950 loss: 52.779 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 137000 loss: 77.436 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 137050 loss: 104.422 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 137100 loss: 73.841 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 137150 loss: 104.947 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 137200 loss: 106.631 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 137250 loss: 31.694 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 137300 loss: 56.420 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 137350 loss: 89.587 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 137400 loss: 109.252 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 137450 loss: 47.247 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 137500 loss: 32.513 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 137550 loss: 108.966 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 137600 loss: 78.795 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 137650 loss: 78.479 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 137700 loss: 76.575 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 137750 loss: 91.314 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 137800 loss: 32.763 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 137850 loss: 75.245 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 137900 loss: 60.377 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 137950 loss: 80.641 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 138000 loss: 94.233 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 138050 loss: 77.913 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 138100 loss: 48.193 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 138150 loss: 32.169 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 138200 loss: 76.247 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 138250 loss: 88.371 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 138300 loss: 88.895 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 138350 loss: 54.951 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 138400 loss: 87.891 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 138450 loss: 88.701 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 138500 loss: 88.804 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 138550 loss: 17.997 training accuracy: 0.900 validation accuracy: 0.600 \n",
      "Step 138600 loss: 95.049 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 138650 loss: 89.615 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 138700 loss: 117.772 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 138750 loss: 105.671 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 138800 loss: 62.391 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 138850 loss: 68.563 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 138900 loss: 100.908 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 138950 loss: 89.108 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 139000 loss: 87.059 training accuracy: 0.400 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 139050 loss: 74.822 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 139100 loss: 73.823 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 139150 loss: 111.171 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 139200 loss: 48.279 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 139250 loss: 36.616 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 139300 loss: 60.534 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 139350 loss: 83.852 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 139400 loss: 61.884 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 139450 loss: 61.826 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 139500 loss: 47.439 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 139550 loss: 149.912 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 139600 loss: 69.178 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 139650 loss: 72.721 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 139700 loss: 45.972 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 139750 loss: 128.492 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 139800 loss: 67.869 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 139850 loss: 78.335 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 139900 loss: 81.615 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 139950 loss: 73.809 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 140000 loss: 92.977 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 140050 loss: 114.286 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 140100 loss: 63.508 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 140150 loss: 46.035 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 140200 loss: 91.922 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 140250 loss: 72.882 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 140300 loss: 124.017 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 140350 loss: 83.414 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 140400 loss: 59.255 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 140450 loss: 74.263 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 140500 loss: 63.436 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 140550 loss: 97.693 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 140600 loss: 47.660 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 140650 loss: 76.233 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 140700 loss: 64.631 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 140750 loss: 35.998 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 140800 loss: 30.554 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 140850 loss: 47.808 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 140900 loss: 49.521 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 140950 loss: 73.422 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 141000 loss: 46.597 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 141050 loss: 34.124 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 141100 loss: 120.255 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 141150 loss: 101.130 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 141200 loss: 86.084 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 141250 loss: 66.265 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 141300 loss: 107.460 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 141350 loss: 70.922 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 141400 loss: 56.077 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 141450 loss: 76.793 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 141500 loss: 46.116 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 141550 loss: 71.404 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 141600 loss: 76.634 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 141650 loss: 89.381 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 141700 loss: 121.430 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 141750 loss: 63.563 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 141800 loss: 81.841 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 141850 loss: 119.044 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 141900 loss: 43.365 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 141950 loss: 91.789 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 142000 loss: 21.485 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 142050 loss: 53.188 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 142100 loss: 91.462 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 142150 loss: 77.192 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 142200 loss: 71.180 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 142250 loss: 59.739 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 142300 loss: 87.666 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 142350 loss: 79.345 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 142400 loss: 102.230 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 142450 loss: 107.928 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 142500 loss: 69.478 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 142550 loss: 135.864 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 142600 loss: 69.284 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 142650 loss: 49.967 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 142700 loss: 31.399 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 142750 loss: 133.220 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 142800 loss: 122.953 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 142850 loss: 44.496 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 142900 loss: 75.469 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 142950 loss: 63.971 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 143000 loss: 65.901 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 143050 loss: 31.820 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 143100 loss: 62.821 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 143150 loss: 38.365 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 143200 loss: 52.924 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 143250 loss: 62.190 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 143300 loss: 92.176 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 143350 loss: 86.779 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 143400 loss: 94.556 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 143450 loss: 13.402 training accuracy: 0.900 validation accuracy: 0.600 \n",
      "Step 143500 loss: 87.272 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 143550 loss: 90.842 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 143600 loss: 46.084 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 143650 loss: 73.837 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 143700 loss: 36.088 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 143750 loss: 117.710 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 143800 loss: 63.387 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 143850 loss: 108.227 training accuracy: 0.300 validation accuracy: 0.800 \n",
      "Step 143900 loss: 39.215 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 143950 loss: 74.762 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 144000 loss: 103.543 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 144050 loss: 112.364 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 144100 loss: 81.979 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 144150 loss: 49.795 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 144200 loss: 86.127 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 144250 loss: 58.319 training accuracy: 0.700 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 144300 loss: 59.406 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 144350 loss: 99.251 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 144400 loss: 123.106 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 144450 loss: 49.872 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 144500 loss: 64.884 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 144550 loss: 45.873 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 144600 loss: 101.914 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 144650 loss: 72.131 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 144700 loss: 88.041 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 144750 loss: 74.989 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 144800 loss: 46.192 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 144850 loss: 32.083 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 144900 loss: 116.732 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 144950 loss: 62.737 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 145000 loss: 81.382 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 145050 loss: 107.176 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 145100 loss: 46.663 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 145150 loss: 75.536 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 145200 loss: 88.581 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 145250 loss: 57.877 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 145300 loss: 17.643 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 145350 loss: 130.498 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 145400 loss: 49.093 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 145450 loss: 47.279 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 145500 loss: 89.348 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 145550 loss: 101.457 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 145600 loss: 90.000 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 145650 loss: 58.978 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 145700 loss: 47.760 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 145750 loss: 33.425 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 145800 loss: 43.167 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 145850 loss: 92.292 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 145900 loss: 73.657 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 145950 loss: 60.532 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 146000 loss: 88.211 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 146050 loss: 88.602 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 146100 loss: 44.698 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 146150 loss: 59.662 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 146200 loss: 81.907 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 146250 loss: 47.842 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 146300 loss: 90.737 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 146350 loss: 38.820 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 146400 loss: 109.802 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 146450 loss: 67.579 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 146500 loss: 68.978 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 146550 loss: 24.012 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 146600 loss: 103.635 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 146650 loss: 62.886 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 146700 loss: 64.855 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 146750 loss: 29.486 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 146800 loss: 75.559 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 146850 loss: 76.733 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 146900 loss: 68.885 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 146950 loss: 49.062 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 147000 loss: 89.938 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 147050 loss: 46.721 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 147100 loss: 75.055 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 147150 loss: 79.145 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 147200 loss: 78.424 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 147250 loss: 83.100 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 147300 loss: 100.195 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 147350 loss: 73.306 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 147400 loss: 83.594 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 147450 loss: 58.858 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 147500 loss: 48.472 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 147550 loss: 48.953 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 147600 loss: 59.599 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 147650 loss: 17.266 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 147700 loss: 63.285 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 147750 loss: 85.243 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 147800 loss: 77.999 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 147850 loss: 31.632 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 147900 loss: 58.576 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 147950 loss: 77.311 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 148000 loss: 107.901 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 148050 loss: 89.581 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 148100 loss: 77.582 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 148150 loss: 50.769 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 148200 loss: 72.500 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 148250 loss: 82.372 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 148300 loss: 58.216 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 148350 loss: 46.270 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 148400 loss: 60.937 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 148450 loss: 34.703 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 148500 loss: 106.410 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 148550 loss: 71.313 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 148600 loss: 62.006 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 148650 loss: 76.879 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 148700 loss: 135.072 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 148750 loss: 43.192 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 148800 loss: 62.042 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 148850 loss: 43.824 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 148900 loss: 82.412 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 148950 loss: 65.497 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 149000 loss: 47.504 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 149050 loss: 117.531 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 149100 loss: 61.947 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 149150 loss: 86.350 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 149200 loss: 50.932 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 149250 loss: 92.989 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 149300 loss: 56.055 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 149350 loss: 91.812 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 149400 loss: 117.988 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 149450 loss: 70.833 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 149500 loss: 45.365 training accuracy: 0.700 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 149550 loss: 86.141 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 149600 loss: 95.780 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 149650 loss: 113.279 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 149700 loss: 107.719 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 149750 loss: 77.036 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 149800 loss: 47.623 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 149850 loss: 45.353 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 149900 loss: 73.489 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 149950 loss: 94.001 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 150000 loss: 74.720 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 150050 loss: 62.148 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 150100 loss: 97.159 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 150150 loss: 77.062 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 150200 loss: 46.002 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 150250 loss: 106.534 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 150300 loss: 31.613 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 150350 loss: 77.016 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 150400 loss: 61.924 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 150450 loss: 82.936 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 150500 loss: 132.792 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 150550 loss: 106.701 training accuracy: 0.300 validation accuracy: 0.900 \n",
      "Step 150600 loss: 73.694 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 150650 loss: 77.474 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 150700 loss: 78.279 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 150750 loss: 62.819 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 150800 loss: 62.699 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 150850 loss: 77.963 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 150900 loss: 62.523 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 150950 loss: 116.056 training accuracy: 0.300 validation accuracy: 0.800 \n",
      "Step 151000 loss: 60.370 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 151050 loss: 85.933 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 151100 loss: 78.828 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 151150 loss: 66.206 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 151200 loss: 58.090 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 151250 loss: 74.007 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 151300 loss: 63.577 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 151350 loss: 132.032 training accuracy: 0.200 validation accuracy: 0.700 \n",
      "Step 151400 loss: 4.376 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 151450 loss: 110.219 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 151500 loss: 46.635 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 151550 loss: 76.047 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 151600 loss: 101.082 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 151650 loss: 62.756 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 151700 loss: 48.632 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 151750 loss: 46.683 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 151800 loss: 44.457 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 151850 loss: 63.026 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 151900 loss: 59.596 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 151950 loss: 75.811 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 152000 loss: 99.918 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 152050 loss: 87.253 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 152100 loss: 65.181 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 152150 loss: 93.121 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 152200 loss: 16.807 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 152250 loss: 128.284 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 152300 loss: 36.143 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 152350 loss: 36.171 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 152400 loss: 73.220 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 152450 loss: 35.614 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 152500 loss: 119.073 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 152550 loss: 60.443 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 152600 loss: 31.901 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 152650 loss: 89.099 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 152700 loss: 49.975 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 152750 loss: 45.949 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 152800 loss: 87.287 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 152850 loss: 46.565 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 152900 loss: 83.847 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 152950 loss: 73.196 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 153000 loss: 93.363 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 153050 loss: 69.256 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 153100 loss: 105.169 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 153150 loss: 101.245 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 153200 loss: 90.763 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 153250 loss: 32.470 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 153300 loss: 71.335 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 153350 loss: 48.043 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 153400 loss: 80.356 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 153450 loss: 62.761 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 153500 loss: 105.046 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 153550 loss: 67.432 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 153600 loss: 88.109 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 153650 loss: 1.734 training accuracy: 1.000 validation accuracy: 0.400 \n",
      "Step 153700 loss: 109.211 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 153750 loss: 87.460 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 153800 loss: 17.929 training accuracy: 0.900 validation accuracy: 0.200 \n",
      "Step 153850 loss: 58.795 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 153900 loss: 84.397 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 153950 loss: 42.825 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 154000 loss: 73.380 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 154050 loss: 89.149 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 154100 loss: 87.544 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 154150 loss: 31.704 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 154200 loss: 53.384 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 154250 loss: 44.568 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 154300 loss: 64.579 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 154350 loss: 108.288 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 154400 loss: 64.768 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 154450 loss: 73.397 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 154500 loss: 47.168 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 154550 loss: 104.876 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 154600 loss: 96.145 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 154650 loss: 18.320 training accuracy: 0.900 validation accuracy: 0.100 \n",
      "Step 154700 loss: 21.703 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 154750 loss: 77.623 training accuracy: 0.500 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 154800 loss: 16.022 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 154850 loss: 60.275 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 154900 loss: 74.982 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 154950 loss: 96.503 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 155000 loss: 117.173 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 155050 loss: 53.199 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 155100 loss: 78.209 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 155150 loss: 64.984 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 155200 loss: 78.975 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 155250 loss: 85.059 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 155300 loss: 100.921 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 155350 loss: 86.183 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 155400 loss: 30.982 training accuracy: 0.800 validation accuracy: 0.800 \n",
      "Step 155450 loss: 86.169 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 155500 loss: 91.618 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 155550 loss: 58.637 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 155600 loss: 90.471 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 155650 loss: 74.408 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 155700 loss: 135.813 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 155750 loss: 92.122 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 155800 loss: 93.120 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 155850 loss: 95.214 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 155900 loss: 45.479 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 155950 loss: 47.163 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 156000 loss: 88.095 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 156050 loss: 117.637 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 156100 loss: 87.982 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 156150 loss: 51.192 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 156200 loss: 117.522 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 156250 loss: 50.505 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 156300 loss: 45.260 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 156350 loss: 60.055 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 156400 loss: 91.383 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 156450 loss: 89.638 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 156500 loss: 71.483 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 156550 loss: 105.524 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 156600 loss: 64.501 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 156650 loss: 44.812 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 156700 loss: 65.081 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 156750 loss: 59.854 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 156800 loss: 83.719 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 156850 loss: 108.725 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 156900 loss: 77.330 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 156950 loss: 126.653 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 157000 loss: 94.070 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 157050 loss: 16.715 training accuracy: 0.900 validation accuracy: 0.700 \n",
      "Step 157100 loss: 139.812 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 157150 loss: 85.230 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 157200 loss: 42.693 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 157250 loss: 45.643 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 157300 loss: 76.482 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 157350 loss: 63.742 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 157400 loss: 79.724 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 157450 loss: 58.214 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 157500 loss: 55.092 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 157550 loss: 51.948 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 157600 loss: 87.484 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 157650 loss: 47.041 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 157700 loss: 31.088 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 157750 loss: 33.734 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 157800 loss: 64.646 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 157850 loss: 58.465 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 157900 loss: 89.192 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 157950 loss: 88.837 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 158000 loss: 50.039 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 158050 loss: 50.292 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 158100 loss: 64.231 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 158150 loss: 90.224 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 158200 loss: 35.433 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 158250 loss: 47.062 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 158300 loss: 58.152 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 158350 loss: 61.960 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 158400 loss: 46.196 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 158450 loss: 32.016 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 158500 loss: 74.825 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 158550 loss: 39.035 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 158600 loss: 21.202 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 158650 loss: 74.026 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 158700 loss: 62.089 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 158750 loss: 77.465 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 158800 loss: 55.514 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 158850 loss: 38.947 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 158900 loss: 88.534 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 158950 loss: 29.397 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 159000 loss: 102.692 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 159050 loss: 18.447 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 159100 loss: 48.492 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 159150 loss: 87.072 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 159200 loss: 88.866 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 159250 loss: 105.912 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 159300 loss: 63.693 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 159350 loss: 118.071 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 159400 loss: 43.912 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 159450 loss: 114.223 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 159500 loss: 86.455 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 159550 loss: 75.426 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 159600 loss: 89.562 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 159650 loss: 63.786 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 159700 loss: 76.454 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 159750 loss: 59.514 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 159800 loss: 109.948 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 159850 loss: 64.153 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 159900 loss: 32.804 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 159950 loss: 86.629 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 160000 loss: 94.600 training accuracy: 0.400 validation accuracy: 0.600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 160050 loss: 121.231 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 160100 loss: 31.932 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 160150 loss: 65.998 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 160200 loss: 161.202 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 160250 loss: 47.454 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 160300 loss: 58.923 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 160350 loss: 81.265 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 160400 loss: 101.537 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 160450 loss: 27.141 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 160500 loss: 49.116 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 160550 loss: 58.193 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 160600 loss: 161.487 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 160650 loss: 78.346 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 160700 loss: 108.196 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 160750 loss: 108.328 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 160800 loss: 120.262 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 160850 loss: 62.553 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 160900 loss: 137.409 training accuracy: 0.200 validation accuracy: 0.700 \n",
      "Step 160950 loss: 62.891 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 161000 loss: 68.074 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 161050 loss: 62.669 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 161100 loss: 75.263 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 161150 loss: 104.500 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 161200 loss: 47.968 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 161250 loss: 61.688 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 161300 loss: 78.289 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 161350 loss: 41.239 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 161400 loss: 104.926 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 161450 loss: 15.872 training accuracy: 0.900 validation accuracy: 0.100 \n",
      "Step 161500 loss: 149.852 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 161550 loss: 63.168 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 161600 loss: 90.434 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 161650 loss: 34.421 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 161700 loss: 31.687 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 161750 loss: 82.991 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 161800 loss: 34.515 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 161850 loss: 88.057 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 161900 loss: 47.032 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 161950 loss: 77.588 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 162000 loss: 104.783 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 162050 loss: 47.320 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 162100 loss: 16.691 training accuracy: 0.900 validation accuracy: 0.600 \n",
      "Step 162150 loss: 48.613 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 162200 loss: 72.134 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 162250 loss: 76.268 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 162300 loss: 105.700 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 162350 loss: 77.499 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 162400 loss: 76.511 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 162450 loss: 63.836 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 162500 loss: 81.289 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 162550 loss: 90.552 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 162600 loss: 117.232 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 162650 loss: 31.114 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 162700 loss: 46.417 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 162750 loss: 74.278 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 162800 loss: 80.797 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 162850 loss: 17.084 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 162900 loss: 107.668 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 162950 loss: 52.418 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 163000 loss: 120.569 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 163050 loss: 62.362 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 163100 loss: 18.153 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 163150 loss: 62.774 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 163200 loss: 101.946 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 163250 loss: 93.633 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 163300 loss: 56.413 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 163350 loss: 68.891 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 163400 loss: 59.435 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 163450 loss: 77.853 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 163500 loss: 91.502 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 163550 loss: 53.419 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 163600 loss: 116.362 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 163650 loss: 91.654 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 163700 loss: 49.052 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 163750 loss: 74.482 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 163800 loss: 55.323 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 163850 loss: 97.118 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 163900 loss: 56.307 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 163950 loss: 106.573 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 164000 loss: 18.695 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 164050 loss: 106.757 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 164100 loss: 47.634 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 164150 loss: 62.488 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 164200 loss: 17.316 training accuracy: 0.900 validation accuracy: 0.600 \n",
      "Step 164250 loss: 101.548 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 164300 loss: 46.327 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 164350 loss: 94.094 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 164400 loss: 6.722 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 164450 loss: 78.474 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 164500 loss: 115.599 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 164550 loss: 99.430 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 164600 loss: 69.926 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 164650 loss: 71.494 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 164700 loss: 51.871 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 164750 loss: 65.995 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 164800 loss: 66.481 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 164850 loss: 63.109 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 164900 loss: 31.069 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 164950 loss: 82.467 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 165000 loss: 59.711 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 165050 loss: 64.974 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 165100 loss: 59.546 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 165150 loss: 33.649 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 165200 loss: 35.824 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 165250 loss: 63.911 training accuracy: 0.600 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 165300 loss: 46.655 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 165350 loss: 66.216 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 165400 loss: 84.486 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 165450 loss: 99.217 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 165500 loss: 90.855 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 165550 loss: 73.028 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 165600 loss: 48.068 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 165650 loss: 18.082 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 165700 loss: 92.961 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 165750 loss: 63.192 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 165800 loss: 102.951 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 165850 loss: 49.628 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 165900 loss: 43.598 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 165950 loss: 74.226 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 166000 loss: 88.936 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 166050 loss: 51.727 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 166100 loss: 39.095 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 166150 loss: 92.885 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 166200 loss: 58.457 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 166250 loss: 73.979 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 166300 loss: 45.746 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 166350 loss: 58.514 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 166400 loss: 67.456 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 166450 loss: 95.351 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 166500 loss: 59.451 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 166550 loss: 47.421 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 166600 loss: 62.354 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 166650 loss: 58.732 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 166700 loss: 64.269 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 166750 loss: 47.665 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 166800 loss: 56.837 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 166850 loss: 16.583 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 166900 loss: 50.572 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 166950 loss: 75.867 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 167000 loss: 64.236 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 167050 loss: 134.360 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 167100 loss: 79.223 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 167150 loss: 16.438 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 167200 loss: 32.507 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 167250 loss: 75.083 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 167300 loss: 61.487 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 167350 loss: 72.724 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 167400 loss: 89.252 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 167450 loss: 61.904 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 167500 loss: 81.090 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 167550 loss: 104.067 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 167600 loss: 92.433 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 167650 loss: 15.459 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 167700 loss: 88.733 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 167750 loss: 92.814 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 167800 loss: 76.047 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 167850 loss: 52.678 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 167900 loss: 107.649 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 167950 loss: 61.988 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 168000 loss: 62.935 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 168050 loss: 15.720 training accuracy: 0.900 validation accuracy: 0.800 \n",
      "Step 168100 loss: 75.002 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 168150 loss: 46.859 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 168200 loss: 95.286 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 168250 loss: 64.643 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 168300 loss: 89.466 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 168350 loss: 39.052 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 168400 loss: 49.126 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 168450 loss: 46.435 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 168500 loss: 44.601 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 168550 loss: 73.861 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 168600 loss: 89.770 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 168650 loss: 90.587 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 168700 loss: 27.950 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 168750 loss: 48.545 training accuracy: 0.700 validation accuracy: 0.800 \n",
      "Step 168800 loss: 44.324 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 168850 loss: 62.888 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 168900 loss: 75.688 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 168950 loss: 20.534 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 169000 loss: 79.622 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 169050 loss: 94.056 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 169100 loss: 60.167 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 169150 loss: 92.060 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 169200 loss: 83.345 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 169250 loss: 124.291 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 169300 loss: 46.118 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 169350 loss: 78.970 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 169400 loss: 30.282 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 169450 loss: 74.298 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 169500 loss: 46.789 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 169550 loss: 91.708 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 169600 loss: 30.428 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 169650 loss: 35.836 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 169700 loss: 56.046 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 169750 loss: 66.268 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 169800 loss: 65.807 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 169850 loss: 90.652 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 169900 loss: 44.012 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 169950 loss: 33.342 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 170000 loss: 48.631 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 170050 loss: 103.645 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 170100 loss: 48.075 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 170150 loss: 66.079 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 170200 loss: 98.527 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 170250 loss: 32.104 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 170300 loss: 31.356 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 170350 loss: 101.226 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 170400 loss: 64.094 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 170450 loss: 102.429 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 170500 loss: 22.258 training accuracy: 0.800 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 170550 loss: 37.811 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 170600 loss: 63.143 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 170650 loss: 96.595 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 170700 loss: 33.470 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 170750 loss: 58.565 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 170800 loss: 46.024 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 170850 loss: 61.456 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 170900 loss: 62.498 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 170950 loss: 81.658 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 171000 loss: 90.135 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 171050 loss: 17.280 training accuracy: 0.900 validation accuracy: 0.600 \n",
      "Step 171100 loss: 90.691 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 171150 loss: 111.351 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 171200 loss: 47.977 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 171250 loss: 50.042 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 171300 loss: 99.747 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 171350 loss: 104.464 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 171400 loss: 65.261 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 171450 loss: 94.647 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 171500 loss: 88.630 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 171550 loss: 83.501 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 171600 loss: 33.306 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 171650 loss: 22.576 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 171700 loss: 49.252 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 171750 loss: 57.050 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 171800 loss: 45.727 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 171850 loss: 65.346 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 171900 loss: 59.999 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 171950 loss: 69.611 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 172000 loss: 80.570 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 172050 loss: 44.017 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 172100 loss: 16.292 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 172150 loss: 70.580 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 172200 loss: 70.159 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 172250 loss: 28.030 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 172300 loss: 82.282 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 172350 loss: 46.362 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 172400 loss: 73.677 training accuracy: 0.600 validation accuracy: 0.400 \n"
     ]
    }
   ],
   "source": [
    "# train the network for 100 epochs\n",
    "step = 0\n",
    "print_every = 50\n",
    "results = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "}\n",
    "for epoch in range(100):\n",
    "    # randomize the order in which we see the data in each epoch\n",
    "    random_order_indices = np.random.choice(train_tensor.shape[0], train_tensor.shape[0], replace=False)\n",
    "    \n",
    "    # iterate through the data in batches of size `batch_size`\n",
    "    for batch_indices in np.array_split(random_order_indices, random_order_indices.shape[0] // batch_size):\n",
    "      \n",
    "        train_data_batch = train_tensor[batch_indices]\n",
    "        train_labels_batch = train_labels[batch_indices]\n",
    "        train_onehot = to_one_hot(train_labels_batch, num_classes)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # get pass batch through layers\n",
    "        hidden_layer = layer_1(train_data_batch)\n",
    "        output = layer_2(hidden_layer)\n",
    "\n",
    "        # compute cross entropy\n",
    "        loss = train_onehot * torch.log(output+ 1e-6) + (1 - train_onehot) * torch.log(1 - output + 1e-6)\n",
    "        loss = -1 * loss.sum()\n",
    "\n",
    "        # backpropagate the loss\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # evaluate accuracy on both the training and validation datasets every 50 steps\n",
    "        if step % print_every == 0:\n",
    "            \n",
    "            # don't track gradients\n",
    "            with torch.no_grad():\n",
    "                # compute the predicted outputs\n",
    "                train_prediction = output.argmax(1).numpy()\n",
    "\n",
    "                # compute the accuracy over the batch\n",
    "                acc_training = np.mean(train_prediction == train_labels_batch.numpy())\n",
    "\n",
    "                # compute the loss on all the validation data\n",
    "                loss_np = []\n",
    "                output_np = []\n",
    "                labels_np = []\n",
    "\n",
    "                random_order_indices = np.random.choice(valid_tensor.shape[0], valid_tensor.shape[0], replace=False)\n",
    "\n",
    "                for batch_indices in np.array_split(random_order_indices, random_order_indices.shape[0] // batch_size):\n",
    "                    valid_data_batch = valid_tensor[batch_indices]\n",
    "                    valid_labels_batch = valid_labels[batch_indices]\n",
    "\n",
    "                    # pass through layers\n",
    "                    valid_hidden = layer_1(valid_data_batch)\n",
    "                    valid_output = layer_2(valid_hidden)\n",
    "\n",
    "                    # compute the predicted outputs\n",
    "\n",
    "                    prediction_np = valid_output.argmax(1).numpy()\n",
    "\n",
    "                    output_np = np.concatenate(prediction_np.reshape(-1,1), axis=0)\n",
    "                    labels_np = np.concatenate(valid_labels_batch.numpy().reshape(-1,1), axis=0)\n",
    "\n",
    "\n",
    "                # compute the accuracy over the whole dataset\n",
    "                acc_validation = np.mean(output_np == labels_np)\n",
    "\n",
    "                results['train_loss'].append(loss.item())\n",
    "                results['train_acc'].append(acc_training)\n",
    "                results['val_acc'].append(acc_validation)\n",
    "                print('Step {} loss: {:.3f} training accuracy: {:.3f} validation accuracy: {:.3f} '.format(\n",
    "                    step, loss.item(), acc_training, acc_validation))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f405e3996a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['train_loss'])\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Training loss')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['train_acc'], label='Training accuracy')\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['val_acc'], label='Validation accuracy')\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEknZ39tGLqI"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "1. How did our network do? Is the classification accuracy high? \n",
    "    - The classification accuracy is pretty poor -- it ranges between 20% and 70%.\n",
    "2. How many iterations did it take for the training accuracy to stop increasing?\n",
    "    - The training accuracy converged after around 100,000 steps.\n",
    "3. How many iterations did it take for the training loss to stop decreasing?\n",
    "    - The training accuracy converged after around 150,000 steps.\n",
    "4. How many iterations did it take for the validation accuracy to stop increasing?\n",
    "    - The validation accuracy converged after around 100,000 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49RJD1tqGOaW"
   },
   "source": [
    "## Exercise 3 - network width\n",
    "\n",
    "Create a network with a wider hidden layer and compare its performance to the network with 10 hidden neurons we just built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrN_IneACxNf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50 loss: 254.344 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100 loss: 273.006 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150 loss: 265.139 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 200 loss: 274.221 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 300 loss: 275.714 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 400 loss: 267.902 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 450 loss: 239.642 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 500 loss: 263.600 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 550 loss: 246.674 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 600 loss: 252.269 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 650 loss: 269.264 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 700 loss: 266.947 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 750 loss: 274.630 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 800 loss: 257.810 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 850 loss: 274.924 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 900 loss: 266.443 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 950 loss: 255.644 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1000 loss: 264.483 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1050 loss: 273.320 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1100 loss: 269.789 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1150 loss: 247.068 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1200 loss: 276.266 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1250 loss: 275.512 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1300 loss: 252.344 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 1350 loss: 276.288 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1400 loss: 233.509 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1450 loss: 276.231 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 1500 loss: 241.232 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 1550 loss: 248.649 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1600 loss: 269.808 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1650 loss: 270.951 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 1700 loss: 247.963 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1750 loss: 244.292 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1800 loss: 275.360 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 1950 loss: 264.834 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2000 loss: 273.988 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2050 loss: 276.307 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2100 loss: 273.361 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2150 loss: 263.784 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2250 loss: 269.005 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2350 loss: 248.675 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 2400 loss: 248.989 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2450 loss: 272.734 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2500 loss: 276.252 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2550 loss: 264.709 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 2650 loss: 270.141 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2700 loss: 247.670 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 2750 loss: 266.515 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2800 loss: 236.268 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 2850 loss: 276.307 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2900 loss: 276.019 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2950 loss: 266.162 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3000 loss: 276.247 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3050 loss: 248.384 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3100 loss: 263.894 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3350 loss: 268.296 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3400 loss: 275.518 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3450 loss: 241.060 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3500 loss: 276.307 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3550 loss: 255.884 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3600 loss: 215.663 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 3650 loss: 246.336 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 3700 loss: 266.555 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3750 loss: 272.960 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3850 loss: 260.877 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3900 loss: 242.915 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3950 loss: 240.987 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 4000 loss: 264.729 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4050 loss: 225.268 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 4100 loss: 253.622 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4150 loss: 275.583 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4200 loss: 262.906 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4250 loss: 227.499 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4300 loss: 248.486 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 4350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4400 loss: 276.309 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4450 loss: 276.309 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4500 loss: 239.813 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4550 loss: 262.036 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4600 loss: 242.310 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4650 loss: 269.903 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4700 loss: 245.527 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4750 loss: 263.924 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4800 loss: 254.600 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4850 loss: 266.029 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4900 loss: 243.032 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 4950 loss: 257.848 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5000 loss: 270.107 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5050 loss: 276.244 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5100 loss: 226.917 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 5150 loss: 276.291 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5200 loss: 264.358 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5250 loss: 268.861 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5300 loss: 248.122 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 5350 loss: 264.337 training accuracy: 0.000 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5400 loss: 227.392 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 5450 loss: 238.870 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 5500 loss: 268.632 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 5550 loss: 270.105 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5650 loss: 258.916 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5700 loss: 270.269 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5750 loss: 248.615 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 5800 loss: 267.021 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5850 loss: 264.511 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5900 loss: 238.704 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 5950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6000 loss: 264.049 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6050 loss: 263.312 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6100 loss: 273.119 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6150 loss: 239.102 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 6200 loss: 248.669 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 6250 loss: 227.715 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 6300 loss: 239.841 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 6350 loss: 248.740 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 6400 loss: 270.555 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6450 loss: 182.102 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 6500 loss: 262.147 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 6550 loss: 266.913 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6600 loss: 265.317 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6650 loss: 232.367 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 6700 loss: 217.025 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 6750 loss: 188.442 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 6800 loss: 240.098 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 6850 loss: 246.248 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 6900 loss: 256.413 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6950 loss: 264.807 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7000 loss: 258.684 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7050 loss: 254.892 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 7100 loss: 237.896 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 7150 loss: 234.771 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7200 loss: 213.701 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 7250 loss: 242.101 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 7300 loss: 256.433 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7350 loss: 229.226 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7400 loss: 254.031 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7450 loss: 195.407 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 7500 loss: 248.677 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7550 loss: 248.602 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 7600 loss: 237.127 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 7650 loss: 225.687 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7700 loss: 264.214 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 7750 loss: 249.980 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7800 loss: 262.878 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 7850 loss: 233.800 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 7900 loss: 245.195 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7950 loss: 270.635 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 8000 loss: 260.040 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8050 loss: 263.907 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 8100 loss: 241.382 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 8150 loss: 256.220 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 8200 loss: 236.253 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 8250 loss: 240.924 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 8300 loss: 275.683 training accuracy: 0.000 validation accuracy: 0.500 \n",
      "Step 8350 loss: 231.546 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 8400 loss: 242.250 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8450 loss: 273.188 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 8500 loss: 242.875 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 8550 loss: 235.259 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 8600 loss: 249.944 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 8650 loss: 213.026 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 8700 loss: 203.107 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 8750 loss: 248.680 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8800 loss: 184.528 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 8850 loss: 265.558 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 8900 loss: 238.564 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 8950 loss: 264.502 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 9000 loss: 257.893 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 9050 loss: 237.349 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 9100 loss: 244.612 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 9150 loss: 241.214 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 9200 loss: 210.055 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 9250 loss: 238.523 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 9300 loss: 247.652 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 9350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 9400 loss: 236.203 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 9450 loss: 175.582 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 9500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9550 loss: 210.704 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 9600 loss: 221.027 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 9650 loss: 264.433 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 9700 loss: 182.182 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 9750 loss: 238.946 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 9800 loss: 218.395 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 9850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 9900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 9950 loss: 210.777 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 10000 loss: 238.439 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 10050 loss: 194.449 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 10100 loss: 216.080 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 10150 loss: 209.534 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 10200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 10250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 10300 loss: 204.109 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 10350 loss: 242.299 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 10400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 10450 loss: 205.440 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 10500 loss: 223.972 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 10550 loss: 220.199 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 10600 loss: 276.309 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 10650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 10700 loss: 244.920 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 10750 loss: 242.099 training accuracy: 0.100 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10800 loss: 225.009 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 10850 loss: 265.744 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 10900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 10950 loss: 236.886 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 11000 loss: 213.766 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 11050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 11100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 11150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 11200 loss: 234.320 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11250 loss: 242.227 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11300 loss: 156.563 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 11350 loss: 250.204 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 11400 loss: 236.688 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11450 loss: 166.615 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 11500 loss: 257.001 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 11550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 11600 loss: 221.058 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 11650 loss: 92.804 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 11700 loss: 208.892 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 11750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 11800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 11850 loss: 155.041 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 11900 loss: 221.976 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11950 loss: 187.512 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 12000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12050 loss: 184.742 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 12100 loss: 234.328 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12150 loss: 261.802 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 12200 loss: 209.867 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 12250 loss: 248.676 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12300 loss: 182.051 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 12350 loss: 212.716 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 12400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 12450 loss: 222.735 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 12500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 12550 loss: 186.569 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 12600 loss: 233.999 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12650 loss: 210.646 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 12700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 12750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 12800 loss: 169.874 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 12850 loss: 193.309 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 12900 loss: 233.274 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12950 loss: 236.182 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 13000 loss: 191.730 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 13050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 13100 loss: 213.561 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 13150 loss: 272.327 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13200 loss: 168.410 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 13250 loss: 168.066 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 13300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 13350 loss: 163.859 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 13400 loss: 236.352 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 13450 loss: 110.638 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 13500 loss: 220.447 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 13550 loss: 133.321 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 13600 loss: 221.047 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 13650 loss: 182.729 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 13700 loss: 150.721 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 13750 loss: 248.676 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 13800 loss: 184.332 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 13850 loss: 253.012 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 13900 loss: 212.913 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 13950 loss: 193.415 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 14000 loss: 165.316 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 14050 loss: 221.002 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 14100 loss: 161.209 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 14150 loss: 211.631 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 14200 loss: 180.988 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 14250 loss: 239.478 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 14300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 14350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 14400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 14450 loss: 115.051 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 14500 loss: 238.081 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 14550 loss: 215.323 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 14600 loss: 228.638 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 14650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 14700 loss: 153.792 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 14750 loss: 160.392 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 14800 loss: 229.161 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 14850 loss: 237.336 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 14900 loss: 184.187 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 14950 loss: 104.536 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 15000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 15050 loss: 184.547 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 15100 loss: 212.055 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 15150 loss: 221.280 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 15200 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 15250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 15300 loss: 207.492 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 15350 loss: 138.163 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 15400 loss: 138.156 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 15450 loss: 191.076 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 15500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 15550 loss: 188.636 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 15600 loss: 208.854 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 15650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 15700 loss: 154.049 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 15750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 15800 loss: 259.099 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 15850 loss: 224.149 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 15900 loss: 138.163 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 15950 loss: 154.752 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 16000 loss: 267.728 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 16050 loss: 199.524 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 16100 loss: 195.266 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 16150 loss: 185.094 training accuracy: 0.300 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16200 loss: 127.102 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 16250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 16300 loss: 188.856 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 16350 loss: 153.531 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 16400 loss: 180.897 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 16450 loss: 126.223 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 16500 loss: 165.785 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 16550 loss: 98.797 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 16600 loss: 85.596 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 16650 loss: 165.407 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 16700 loss: 160.200 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 16750 loss: 137.972 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 16800 loss: 183.059 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 16850 loss: 70.559 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 16900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 16950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 17000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 17050 loss: 163.660 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 17100 loss: 220.557 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 17150 loss: 171.049 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 17200 loss: 163.643 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 17250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 17300 loss: 98.600 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 17350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 17400 loss: 165.840 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 17450 loss: 172.865 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 17500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 17550 loss: 103.724 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 17600 loss: 154.472 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 17650 loss: 101.662 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 17700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 17750 loss: 125.771 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 17800 loss: 215.067 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 17850 loss: 226.573 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 17900 loss: 192.271 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 17950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 18000 loss: 164.223 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 18050 loss: 131.627 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 18100 loss: 84.502 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 18150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 18200 loss: 181.224 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 18250 loss: 153.434 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 18300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 18350 loss: 156.469 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 18400 loss: 147.075 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 18450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 18500 loss: 108.851 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 18550 loss: 109.027 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 18600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.000 \n",
      "Step 18650 loss: 155.129 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 18700 loss: 181.690 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 18750 loss: 211.823 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 18800 loss: 153.871 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 18850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 18900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 18950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 19000 loss: 45.307 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 19050 loss: 165.278 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 19100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 19150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 19200 loss: 211.974 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 19250 loss: 180.623 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 19300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 19350 loss: 138.151 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 19400 loss: 173.941 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 19450 loss: 74.120 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 19500 loss: 138.153 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 19550 loss: 129.113 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 19600 loss: 215.352 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 19650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 19700 loss: 138.340 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 19750 loss: 121.133 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 19800 loss: 153.288 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 19850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 19900 loss: 176.943 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 19950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 20000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 20050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 20100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 20150 loss: 110.473 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 20200 loss: 106.572 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 20250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 20300 loss: 216.210 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 20350 loss: 165.785 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 20400 loss: 178.386 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 20450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 20500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 20550 loss: 70.913 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 20600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 20650 loss: 155.864 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 20700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 20750 loss: 92.474 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 20800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 20850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 20900 loss: 127.693 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 20950 loss: 173.506 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 21000 loss: 211.194 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 21050 loss: 138.070 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 21100 loss: 137.069 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 21150 loss: 153.744 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 21200 loss: 133.604 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 21250 loss: 128.432 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 21300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 21350 loss: 181.261 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 21400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 21450 loss: 137.368 training accuracy: 0.500 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 21550 loss: 116.889 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 21600 loss: 130.170 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 21650 loss: 136.577 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 21700 loss: 224.884 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 21750 loss: 100.417 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 21800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 21850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 21900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 21950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 22000 loss: 101.362 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 22050 loss: 165.769 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 22100 loss: 110.517 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 22150 loss: 100.217 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 22200 loss: 127.485 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 22250 loss: 102.827 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 22300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 22350 loss: 125.693 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 22400 loss: 164.942 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 22450 loss: 209.334 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 22500 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 22550 loss: 98.260 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 22600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 22650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 22700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 22750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 22800 loss: 218.282 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 22850 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 22900 loss: 165.537 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 22950 loss: 218.300 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 23000 loss: 215.763 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 23050 loss: 211.845 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 23100 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 23150 loss: 84.289 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 23200 loss: 165.672 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 23250 loss: 193.401 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 23300 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 23350 loss: 193.416 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 23400 loss: 156.466 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 23450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 23500 loss: 183.786 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 23550 loss: 176.765 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 23600 loss: 173.118 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 23650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 23700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 23750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 23800 loss: 119.677 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 23850 loss: 86.857 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 23900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 23950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 24000 loss: 116.603 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 24050 loss: 155.282 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 24100 loss: 84.094 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 24150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 24200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 24250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 24300 loss: 207.530 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 24350 loss: 86.332 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 24400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 24450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 24500 loss: 99.031 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 24550 loss: 186.670 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 24600 loss: 173.729 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 24650 loss: 71.426 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 24700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 24750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 24800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 24850 loss: 127.573 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 24900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 24950 loss: 154.323 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 25000 loss: 138.148 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 25050 loss: 106.940 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 25100 loss: 158.755 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 25150 loss: 109.961 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 25200 loss: 158.238 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 25250 loss: 127.033 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 25300 loss: 153.632 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 25350 loss: 181.255 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 25400 loss: 165.775 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 25450 loss: 40.458 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 25500 loss: 98.992 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 25550 loss: 165.813 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 25600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 25650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 25700 loss: 105.832 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 25750 loss: 117.345 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 25800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 25850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 25900 loss: 137.988 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 25950 loss: 174.197 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 26000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 26050 loss: 62.064 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 26100 loss: 88.395 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 26150 loss: 55.258 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 26200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 26250 loss: 82.892 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 26300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 26350 loss: 128.577 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 26400 loss: 125.743 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 26450 loss: 182.452 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 26500 loss: 154.652 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 26550 loss: 221.041 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 26600 loss: 178.492 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 26650 loss: 132.487 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 26700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 26750 loss: 218.015 training accuracy: 0.200 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26800 loss: 165.783 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 26850 loss: 126.994 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 26900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 26950 loss: 210.677 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 27000 loss: 127.449 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 27050 loss: 166.114 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 27100 loss: 181.355 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 27150 loss: 203.770 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 27200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 27250 loss: 165.785 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 27300 loss: 178.128 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 27350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 27400 loss: 193.261 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 27450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 27500 loss: 94.534 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 27550 loss: 168.476 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 27600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 27650 loss: 81.377 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 27700 loss: 165.782 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 27750 loss: 116.856 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 27800 loss: 126.203 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 27850 loss: 129.842 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 27900 loss: 142.222 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 27950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 28000 loss: 171.178 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 28050 loss: 190.034 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 28100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 28150 loss: 169.179 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 28200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 28250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 28300 loss: 153.515 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 28350 loss: 188.030 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 28400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 28450 loss: 98.549 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 28500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 28550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 28600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 28650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 28700 loss: 82.892 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 28750 loss: 100.676 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 28800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 28850 loss: 153.440 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 28900 loss: 187.020 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 28950 loss: 58.178 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 29000 loss: 125.766 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 29050 loss: 43.578 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 29100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 29150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 29200 loss: 181.007 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 29250 loss: 153.895 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 29300 loss: 98.774 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 29350 loss: 113.747 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 29400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 29450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 29500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 29550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 29600 loss: 165.776 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 29650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 29700 loss: 155.299 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 29750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 29800 loss: 129.296 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 29850 loss: 197.310 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 29900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 29950 loss: 162.666 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 30000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 30050 loss: 125.885 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 30100 loss: 109.180 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 30150 loss: 153.872 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 30200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 30250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 30300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 30350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 30400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 30450 loss: 205.231 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 30500 loss: 159.910 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 30550 loss: 248.677 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 30600 loss: 138.284 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 30650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 30700 loss: 126.765 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 30750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 30800 loss: 43.197 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 30850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 30900 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 30950 loss: 160.298 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 31000 loss: 141.162 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 31050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 31100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 31150 loss: 170.983 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 31200 loss: 153.453 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 31250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 31300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 31350 loss: 151.924 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 31400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 31450 loss: 98.427 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 31500 loss: 157.477 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 31550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 31600 loss: 181.223 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 31650 loss: 244.922 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 31700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 31750 loss: 138.145 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 31800 loss: 220.407 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 31850 loss: 164.664 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 31900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 31950 loss: 60.948 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 32000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 32050 loss: 98.134 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 32100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 32150 loss: 121.768 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 32200 loss: 210.862 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 32250 loss: 60.424 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 32300 loss: 44.773 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 32350 loss: 169.909 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 32400 loss: 153.394 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 32450 loss: 153.620 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 32500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 32550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 32600 loss: 98.120 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 32650 loss: 99.985 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 32700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 32750 loss: 98.166 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 32800 loss: 138.138 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 32850 loss: 155.808 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 32900 loss: 155.678 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 32950 loss: 153.360 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 33000 loss: 170.918 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 33050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 33100 loss: 153.657 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 33150 loss: 180.992 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 33200 loss: 162.749 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 33250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 33300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 33350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 33400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 33450 loss: 153.711 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 33500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 33550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 33600 loss: 199.652 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 33650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 33700 loss: 71.579 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 33750 loss: 141.161 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 33800 loss: 170.165 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 33850 loss: 125.309 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 33900 loss: 82.524 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 33950 loss: 217.499 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 34000 loss: 125.986 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 34050 loss: 182.186 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 34100 loss: 128.315 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 34150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 34200 loss: 171.119 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 34250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 34300 loss: 165.783 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 34350 loss: 181.045 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 34400 loss: 147.740 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 34450 loss: 184.656 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 34500 loss: 210.493 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 34550 loss: 137.347 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 34600 loss: 165.763 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 34650 loss: 193.183 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 34700 loss: 153.386 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 34750 loss: 156.032 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 34800 loss: 127.787 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 34850 loss: 165.035 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 34900 loss: 159.965 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 34950 loss: 175.396 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 35000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 35050 loss: 180.994 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 35100 loss: 153.369 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 35150 loss: 135.511 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 35200 loss: 113.864 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 35250 loss: 121.075 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 35300 loss: 141.026 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 35350 loss: 143.493 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 35400 loss: 160.940 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 35450 loss: 142.307 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 35500 loss: 64.161 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 35550 loss: 125.901 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 35600 loss: 130.174 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 35650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 35700 loss: 153.574 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 35750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 35800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 35850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 35900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 35950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 36000 loss: 163.776 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 36050 loss: 142.075 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 36100 loss: 149.032 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 36150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 36200 loss: 156.103 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 36250 loss: 196.841 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 36300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.000 \n",
      "Step 36350 loss: 146.708 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 36400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 36450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 36500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 36550 loss: 192.174 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 36600 loss: 74.008 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 36650 loss: 115.829 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 36700 loss: 141.252 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 36750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 36800 loss: 73.813 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 36850 loss: 142.634 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 36900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 36950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 37000 loss: 53.847 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 37050 loss: 165.777 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 37100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 37150 loss: 247.382 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 37200 loss: 159.330 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 37250 loss: 70.466 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 37300 loss: 125.966 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 37350 loss: 187.213 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 37400 loss: 169.153 training accuracy: 0.300 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 37450 loss: 150.429 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 37500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 37550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 37600 loss: 125.786 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 37650 loss: 158.329 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 37700 loss: 165.893 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 37750 loss: 141.309 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 37800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 37850 loss: 221.013 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 37900 loss: 98.740 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 37950 loss: 138.139 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 38000 loss: 125.848 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 38050 loss: 126.374 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 38100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 38150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 38200 loss: 145.558 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 38250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 38300 loss: 116.919 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 38350 loss: 125.785 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 38400 loss: 70.660 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 38450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 38500 loss: 193.415 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 38550 loss: 168.933 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 38600 loss: 165.784 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 38650 loss: 125.726 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 38700 loss: 162.400 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 38750 loss: 121.057 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 38800 loss: 74.321 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 38850 loss: 125.612 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 38900 loss: 126.232 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 38950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 39000 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 39050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 39100 loss: 153.381 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 39150 loss: 181.152 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 39200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 39250 loss: 165.784 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 39300 loss: 185.771 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 39350 loss: 126.282 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 39400 loss: 153.842 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 39450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 39500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 39550 loss: 169.093 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 39600 loss: 110.471 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 39650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 39700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 39750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 39800 loss: 126.995 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 39850 loss: 190.954 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 39900 loss: 108.845 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 39950 loss: 99.049 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 40000 loss: 144.308 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 40050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 40100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 40150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 40200 loss: 125.811 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 40250 loss: 132.470 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 40300 loss: 169.343 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 40350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 40400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 40450 loss: 182.490 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 40500 loss: 115.770 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 40550 loss: 119.268 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 40600 loss: 153.535 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 40650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 40700 loss: 76.386 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 40750 loss: 125.779 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 40800 loss: 174.996 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 40850 loss: 98.485 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 40900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 40950 loss: 98.345 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 41000 loss: 172.587 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 41050 loss: 125.794 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 41100 loss: 98.269 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 41150 loss: 175.174 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 41200 loss: 98.695 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 41250 loss: 168.287 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 41300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 41350 loss: 165.587 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 41400 loss: 126.216 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 41450 loss: 125.725 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 41500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 41550 loss: 181.034 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 41600 loss: 119.154 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 41650 loss: 125.699 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 41700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 41750 loss: 108.210 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 41800 loss: 169.042 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 41850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 41900 loss: 103.311 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 41950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 42000 loss: 98.233 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 42050 loss: 169.772 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 42100 loss: 159.799 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 42150 loss: 86.109 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 42200 loss: 157.311 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 42250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 42300 loss: 224.561 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 42350 loss: 193.389 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 42400 loss: 110.547 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 42450 loss: 164.117 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 42500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 42550 loss: 98.100 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 42600 loss: 119.969 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 42650 loss: 127.781 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 42700 loss: 110.383 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 42750 loss: 99.778 training accuracy: 0.600 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 42800 loss: 75.489 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 42850 loss: 185.114 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 42900 loss: 98.670 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 42950 loss: 153.376 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 43000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 43050 loss: 181.360 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 43100 loss: 107.254 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 43150 loss: 99.151 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 43200 loss: 78.063 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 43250 loss: 177.197 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 43300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 43350 loss: 153.902 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 43400 loss: 181.632 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 43450 loss: 138.165 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 43500 loss: 71.333 training accuracy: 0.700 validation accuracy: 0.000 \n",
      "Step 43550 loss: 101.573 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 43600 loss: 129.049 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 43650 loss: 180.989 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 43700 loss: 207.517 training accuracy: 0.200 validation accuracy: 0.700 \n",
      "Step 43750 loss: 129.026 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 43800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 43850 loss: 110.265 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 43900 loss: 72.309 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 43950 loss: 127.173 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 44000 loss: 138.150 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 44050 loss: 86.969 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 44100 loss: 112.568 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 44150 loss: 99.119 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 44200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 44250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 44300 loss: 153.387 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 44350 loss: 102.571 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 44400 loss: 132.304 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 44450 loss: 120.478 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 44500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 44550 loss: 193.406 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 44600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 44650 loss: 138.142 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 44700 loss: 152.748 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 44750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 44800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 44850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 44900 loss: 161.098 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 44950 loss: 197.875 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 45000 loss: 102.059 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 45050 loss: 104.263 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 45100 loss: 87.900 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 45150 loss: 168.927 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 45200 loss: 128.601 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 45250 loss: 113.959 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 45300 loss: 196.325 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 45350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 45400 loss: 137.989 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 45450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 45500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 45550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 45600 loss: 99.070 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 45650 loss: 42.833 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 45700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 45750 loss: 82.892 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 45800 loss: 208.629 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 45850 loss: 98.618 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 45900 loss: 127.653 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 45950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 46000 loss: 126.894 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 46050 loss: 153.559 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 46100 loss: 127.245 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 46150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 46200 loss: 173.757 training accuracy: 0.200 validation accuracy: 0.700 \n",
      "Step 46250 loss: 114.904 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 46300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 46350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 46400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 46450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 46500 loss: 97.738 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 46550 loss: 154.021 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 46600 loss: 181.002 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 46650 loss: 138.039 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 46700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 46750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 46800 loss: 153.731 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 46850 loss: 113.528 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 46900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 46950 loss: 125.679 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 47000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 47050 loss: 169.052 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 47100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 47150 loss: 157.180 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 47200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 47250 loss: 130.671 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 47300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 47350 loss: 128.162 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 47400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 47450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 47500 loss: 162.163 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 47550 loss: 125.873 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 47600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 47650 loss: 125.729 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 47700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 47750 loss: 138.080 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 47800 loss: 128.511 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 47850 loss: 160.666 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 47900 loss: 208.662 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 47950 loss: 154.294 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 48000 loss: 42.870 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 48050 loss: 134.096 training accuracy: 0.500 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 48100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 48150 loss: 135.991 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 48200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 48250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 48300 loss: 170.222 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 48350 loss: 236.278 training accuracy: 0.100 validation accuracy: 0.700 \n",
      "Step 48400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 48450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 48500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 48550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 48600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 48650 loss: 45.011 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 48700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 48750 loss: 98.639 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 48800 loss: 135.428 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 48850 loss: 98.929 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 48900 loss: 155.597 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 48950 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 49000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 49050 loss: 153.432 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 49100 loss: 85.702 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 49150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 49200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 49250 loss: 181.354 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 49300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 49350 loss: 58.025 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 49400 loss: 110.521 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 49450 loss: 153.399 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 49500 loss: 126.098 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 49550 loss: 126.340 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 49600 loss: 128.055 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 49650 loss: 135.862 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 49700 loss: 172.598 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 49750 loss: 126.201 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 49800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 49850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 49900 loss: 98.318 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 49950 loss: 208.803 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 50000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 50050 loss: 188.736 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 50100 loss: 55.493 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 50150 loss: 208.598 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 50200 loss: 98.097 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 50250 loss: 116.700 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 50300 loss: 169.415 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 50350 loss: 183.746 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 50400 loss: 181.118 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 50450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 50500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 50550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 50600 loss: 138.132 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 50650 loss: 159.610 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 50700 loss: 70.684 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 50750 loss: 130.821 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 50800 loss: 186.136 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 50850 loss: 118.424 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 50900 loss: 140.939 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 50950 loss: 128.878 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 51000 loss: 168.997 training accuracy: 0.300 validation accuracy: 0.800 \n",
      "Step 51050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 51100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 51150 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.100 \n",
      "Step 51200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 51250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 51300 loss: 208.302 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 51350 loss: 186.582 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 51400 loss: 70.467 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 51450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 51500 loss: 138.153 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 51550 loss: 147.965 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 51600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 51650 loss: 138.149 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 51700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 51750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 51800 loss: 181.043 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 51850 loss: 110.453 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 51900 loss: 98.096 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 51950 loss: 182.744 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 52000 loss: 137.734 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 52050 loss: 126.433 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 52100 loss: 193.369 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 52150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 52200 loss: 196.475 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 52250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 52300 loss: 116.723 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 52350 loss: 113.973 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 52400 loss: 168.858 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 52450 loss: 193.415 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 52500 loss: 154.021 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 52550 loss: 138.153 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 52600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 52650 loss: 146.722 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 52700 loss: 108.393 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 52750 loss: 181.459 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 52800 loss: 193.416 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 52850 loss: 126.497 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 52900 loss: 129.505 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 52950 loss: 187.634 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 53000 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 53050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 53100 loss: 153.426 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 53150 loss: 73.669 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 53200 loss: 180.992 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 53250 loss: 113.322 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 53300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 53350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 53400 loss: 58.660 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 53450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 53500 loss: 153.401 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 53550 loss: 99.686 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 53600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 53650 loss: 209.766 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 53700 loss: 181.653 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 53750 loss: 153.554 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 53800 loss: 43.408 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 53850 loss: 168.958 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 53900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 53950 loss: 129.712 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 54000 loss: 125.736 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 54050 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 54100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 54150 loss: 85.827 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 54200 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 54250 loss: 244.792 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 54300 loss: 85.834 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 54350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 54400 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 54450 loss: 71.733 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 54500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 54550 loss: 115.032 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 54600 loss: 125.758 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 54650 loss: 126.191 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 54700 loss: 133.072 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 54750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 54800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 54850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 54900 loss: 153.473 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 54950 loss: 75.526 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 55000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 55050 loss: 169.850 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 55100 loss: 181.235 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 55150 loss: 109.574 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 55200 loss: 98.498 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 55250 loss: 87.608 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 55300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 55350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 55400 loss: 98.126 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 55450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 55500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 55550 loss: 125.876 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 55600 loss: 126.210 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 55650 loss: 138.113 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 55700 loss: 98.481 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 55750 loss: 85.913 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 55800 loss: 196.701 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 55850 loss: 102.350 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 55900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 55950 loss: 133.023 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 56000 loss: 126.995 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 56050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 56100 loss: 161.830 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 56150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 56200 loss: 99.156 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 56250 loss: 153.638 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 56300 loss: 181.210 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 56350 loss: 197.974 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 56400 loss: 70.933 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 56450 loss: 98.426 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 56500 loss: 70.464 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 56550 loss: 169.730 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 56600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 56650 loss: 98.807 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 56700 loss: 170.521 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 56750 loss: 208.622 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 56800 loss: 150.370 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 56850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 56900 loss: 181.003 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 56950 loss: 125.935 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 57000 loss: 145.763 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 57050 loss: 98.898 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 57100 loss: 128.960 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 57150 loss: 113.636 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 57200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 57250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 57300 loss: 113.590 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 57350 loss: 131.240 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 57400 loss: 125.738 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 57450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 57500 loss: 193.470 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 57550 loss: 113.456 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 57600 loss: 193.415 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 57650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 57700 loss: 141.403 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 57750 loss: 98.511 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 57800 loss: 126.253 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 57850 loss: 125.816 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 57900 loss: 153.373 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 57950 loss: 70.558 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 58000 loss: 70.491 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 58050 loss: 141.258 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 58100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 58150 loss: 113.332 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 58200 loss: 98.646 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 58250 loss: 99.873 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 58300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 58350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 58400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 58450 loss: 100.275 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 58500 loss: 118.582 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 58550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 58600 loss: 129.606 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 58650 loss: 113.704 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 58700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 58750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 58800 loss: 130.315 training accuracy: 0.400 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 58850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 58900 loss: 125.744 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 58950 loss: 125.853 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 59000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 59050 loss: 98.180 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 59100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 59150 loss: 86.609 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 59200 loss: 141.338 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 59250 loss: 70.633 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 59300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 59350 loss: 168.565 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 59400 loss: 159.389 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 59450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 59500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 59550 loss: 125.775 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 59600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 59650 loss: 158.982 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 59700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 59750 loss: 138.161 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 59800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 59850 loss: 138.083 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 59900 loss: 147.502 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 59950 loss: 181.131 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 60000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 60050 loss: 153.767 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 60100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 60150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 60200 loss: 42.836 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 60250 loss: 43.024 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 60300 loss: 174.124 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 60350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 60400 loss: 110.515 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 60450 loss: 183.928 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 60500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 60550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 60600 loss: 70.747 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 60650 loss: 74.799 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 60700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 60750 loss: 193.403 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 60800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 60850 loss: 184.307 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 60900 loss: 87.138 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 60950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 61000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 61050 loss: 188.151 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 61100 loss: 211.177 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 61150 loss: 142.336 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 61200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 61250 loss: 141.087 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 61300 loss: 153.361 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 61350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 61400 loss: 42.891 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 61450 loss: 125.811 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 61500 loss: 192.495 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 61550 loss: 100.342 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 61600 loss: 153.367 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 61650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 61700 loss: 122.385 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 61750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 61800 loss: 98.172 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 61850 loss: 158.391 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 61900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 61950 loss: 85.936 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 62000 loss: 125.810 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 62050 loss: 138.086 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 62100 loss: 98.156 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 62150 loss: 128.665 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 62200 loss: 165.785 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 62250 loss: 169.346 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 62300 loss: 181.312 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 62350 loss: 128.899 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 62400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 62450 loss: 101.426 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 62500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 62550 loss: 193.343 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 62600 loss: 165.702 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 62650 loss: 123.674 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 62700 loss: 98.423 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 62750 loss: 193.416 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 62800 loss: 126.098 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 62850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 62900 loss: 198.629 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 62950 loss: 165.805 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 63000 loss: 98.098 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 63050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 63100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 63150 loss: 82.897 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 63200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 63250 loss: 193.413 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 63300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 63350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 63400 loss: 43.801 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 63450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 63500 loss: 181.035 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 63550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 63600 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 63650 loss: 109.068 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 63700 loss: 60.571 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 63750 loss: 125.900 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 63800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 63850 loss: 162.890 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 63900 loss: 104.546 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 63950 loss: 70.495 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 64000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 64050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 64100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 64150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 64200 loss: 125.589 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 64250 loss: 142.536 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 64300 loss: 101.055 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 64350 loss: 168.673 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 64400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 64450 loss: 154.956 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 64500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 64550 loss: 113.509 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 64600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 64650 loss: 153.397 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 64700 loss: 134.883 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 64750 loss: 70.469 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 64800 loss: 182.205 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 64850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 64900 loss: 141.309 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 64950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 65000 loss: 165.785 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 65050 loss: 208.753 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 65100 loss: 138.153 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 65150 loss: 125.635 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 65200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 65250 loss: 224.186 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 65300 loss: 125.734 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 65350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 65400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 65450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 65500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 65550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 65600 loss: 58.142 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 65650 loss: 98.193 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 65700 loss: 182.691 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 65750 loss: 153.922 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 65800 loss: 169.058 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 65850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 65900 loss: 125.727 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 65950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 66000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 66050 loss: 206.934 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 66100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 66150 loss: 98.313 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 66200 loss: 63.060 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 66250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 66300 loss: 153.415 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 66350 loss: 153.746 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 66400 loss: 135.696 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 66450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 66500 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 66550 loss: 124.971 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 66600 loss: 70.466 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 66650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 66700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 66750 loss: 70.613 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 66800 loss: 208.954 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 66850 loss: 114.143 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 66900 loss: 58.204 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 66950 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 67000 loss: 127.172 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 67050 loss: 181.085 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 67100 loss: 82.933 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 67150 loss: 138.142 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 67200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 67250 loss: 70.508 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 67300 loss: 153.377 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 67350 loss: 86.343 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 67400 loss: 208.619 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 67450 loss: 153.853 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 67500 loss: 153.354 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 67550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 67600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 67650 loss: 142.509 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 67700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 67750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 67800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 67850 loss: 102.108 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 67900 loss: 165.769 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 67950 loss: 70.819 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 68000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 68050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 68100 loss: 153.384 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 68150 loss: 117.209 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 68200 loss: 101.788 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 68250 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 68300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 68350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 68400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 68450 loss: 165.679 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 68500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 68550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 68600 loss: 223.878 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 68650 loss: 125.729 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 68700 loss: 181.381 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 68750 loss: 157.343 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 68800 loss: 148.246 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 68850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 68900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 68950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 69000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 69050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 69100 loss: 208.619 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 69150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 69200 loss: 180.998 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 69250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 69300 loss: 74.044 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 69350 loss: 141.174 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 69400 loss: 224.196 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 69450 loss: 86.207 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 69500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 69550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 69600 loss: 183.832 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 69650 loss: 165.759 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 69700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 69750 loss: 113.337 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 69800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 69850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 69900 loss: 113.413 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 69950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 70000 loss: 138.145 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 70050 loss: 125.834 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 70100 loss: 58.200 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 70150 loss: 98.103 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 70200 loss: 58.311 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 70250 loss: 118.958 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 70300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 70350 loss: 125.949 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 70400 loss: 100.983 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 70450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 70500 loss: 153.365 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 70550 loss: 193.416 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 70600 loss: 113.407 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 70650 loss: 125.728 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 70700 loss: 180.998 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 70750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 70800 loss: 125.877 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 70850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 70900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 70950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 71000 loss: 73.905 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 71050 loss: 85.848 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 71100 loss: 126.002 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 71150 loss: 82.890 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 71200 loss: 153.816 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 71250 loss: 125.726 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 71300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 71350 loss: 110.496 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 71400 loss: 208.621 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 71450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 71500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 71550 loss: 99.598 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 71600 loss: 125.775 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 71650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 71700 loss: 208.715 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 71750 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 71800 loss: 156.263 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 71850 loss: 141.225 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 71900 loss: 140.971 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 71950 loss: 113.420 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 72000 loss: -0.000 training accuracy: 1.000 validation accuracy: 0.300 \n",
      "Step 72050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 72100 loss: 153.411 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 72150 loss: 221.047 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 72200 loss: 181.305 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 72250 loss: 98.098 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 72300 loss: 196.724 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 72350 loss: 153.358 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 72400 loss: 125.294 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 72450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 72500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 72550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 72600 loss: 128.552 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 72650 loss: 208.644 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 72700 loss: 211.796 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 72750 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 72800 loss: 141.034 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 72850 loss: 153.375 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 72900 loss: 140.935 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 72950 loss: 208.634 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 73000 loss: 99.650 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 73050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 73100 loss: 153.387 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 73150 loss: 129.424 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 73200 loss: 125.936 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 73250 loss: 141.035 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 73300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 73350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 73400 loss: 98.147 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 73450 loss: 180.993 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 73500 loss: 126.356 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 73550 loss: 248.677 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 73600 loss: 138.127 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 73650 loss: 132.818 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 73700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 73750 loss: 125.755 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 73800 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 73850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 73900 loss: 127.282 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 73950 loss: 138.153 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 74000 loss: 208.717 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 74050 loss: 141.044 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 74100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 74150 loss: 208.505 training accuracy: 0.200 validation accuracy: 0.800 \n",
      "Step 74200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 74250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 74300 loss: 125.828 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 74350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 74400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 74450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 74500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 74550 loss: 199.740 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 74600 loss: 170.652 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 74650 loss: 153.359 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 74700 loss: 169.161 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 74750 loss: 70.559 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 74800 loss: 42.835 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 74850 loss: 165.778 training accuracy: 0.400 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 74900 loss: 168.573 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 74950 loss: 125.730 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 75000 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 75050 loss: 181.766 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 75100 loss: 133.784 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 75150 loss: 85.819 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 75200 loss: 98.585 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 75250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 75300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 75350 loss: 141.049 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 75400 loss: 125.726 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 75450 loss: 140.933 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 75500 loss: 181.105 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 75550 loss: 99.180 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 75600 loss: 113.546 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 75650 loss: 208.829 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 75700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 75750 loss: 125.735 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 75800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 75850 loss: 164.809 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 75900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 75950 loss: 165.731 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 76000 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 76050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 76100 loss: 181.141 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 76150 loss: 181.443 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 76200 loss: 58.736 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 76250 loss: 113.514 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 76300 loss: 181.036 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 76350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 76400 loss: 180.988 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 76450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 76500 loss: 181.050 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 76550 loss: 153.439 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 76600 loss: 140.975 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 76650 loss: 153.348 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 76700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 76750 loss: 125.728 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 76800 loss: 85.735 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 76850 loss: 156.235 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 76900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 76950 loss: 126.093 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 77000 loss: 165.784 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 77050 loss: 181.148 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 77100 loss: 168.637 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 77150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 77200 loss: 208.623 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 77250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 77300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 77350 loss: 154.760 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 77400 loss: 141.126 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 77450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 77500 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 77550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 77600 loss: 183.807 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 77650 loss: 168.561 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 77700 loss: 168.597 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 77750 loss: 42.930 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 77800 loss: 98.462 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 77850 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 77900 loss: 126.090 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 77950 loss: 208.635 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 78000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 78050 loss: 98.101 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 78100 loss: 70.465 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 78150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 78200 loss: 110.525 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 78250 loss: 70.477 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 78300 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 78350 loss: 153.359 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 78400 loss: 181.208 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 78450 loss: 70.524 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 78500 loss: 165.728 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 78550 loss: 153.909 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 78600 loss: 153.371 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 78650 loss: 113.295 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 78700 loss: 236.298 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 78750 loss: 98.860 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 78800 loss: 153.596 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 78850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 78900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 78950 loss: 181.008 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 79000 loss: 86.334 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 79050 loss: 98.273 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 79100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 79150 loss: 168.558 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 79200 loss: 113.831 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 79250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 79300 loss: 126.050 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 79350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 79400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 79450 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 79500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 79550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 79600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 79650 loss: 73.257 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 79700 loss: 70.609 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 79750 loss: 210.230 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 79800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 79850 loss: 165.768 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 79900 loss: 58.622 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 79950 loss: 196.402 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 80000 loss: 125.745 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 80050 loss: 58.141 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 80100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 80150 loss: 181.032 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 80200 loss: 153.528 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 80250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 80300 loss: 153.378 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 80350 loss: 221.046 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 80400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 80450 loss: 70.510 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 80500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 80550 loss: 72.021 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 80600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 80650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 80700 loss: 125.714 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 80750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 80800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 80850 loss: 208.738 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 80900 loss: 180.998 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 80950 loss: 85.751 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 81000 loss: 130.143 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 81050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 81100 loss: 85.705 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 81150 loss: 99.030 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 81200 loss: 140.992 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 81250 loss: 70.466 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 81300 loss: 98.099 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 81350 loss: 43.950 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 81400 loss: 181.013 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 81450 loss: 153.374 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 81500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 81550 loss: 165.748 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 81600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 81650 loss: 180.988 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 81700 loss: 208.619 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 81750 loss: 70.697 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 81800 loss: 153.433 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 81850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 81900 loss: 181.010 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 81950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 82000 loss: 196.216 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 82050 loss: 140.976 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 82100 loss: 98.107 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 82150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 82200 loss: 181.015 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 82250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 82300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 82350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 82400 loss: 165.202 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 82450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 82500 loss: 87.822 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 82550 loss: 153.224 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 82600 loss: 132.228 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 82650 loss: 71.190 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 82700 loss: 181.266 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 82750 loss: 55.244 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 82800 loss: 98.140 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 82850 loss: 85.688 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 82900 loss: 153.358 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 82950 loss: 181.022 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 83000 loss: 88.075 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 83050 loss: 181.058 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 83100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 83150 loss: 165.763 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 83200 loss: 125.853 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 83250 loss: 148.949 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 83300 loss: 125.952 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 83350 loss: 70.681 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 83400 loss: 113.549 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 83450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 83500 loss: 208.598 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 83550 loss: 114.094 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 83600 loss: 115.925 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 83650 loss: 153.630 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 83700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 83750 loss: 140.970 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 83800 loss: 125.819 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 83850 loss: 85.680 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 83900 loss: 169.449 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 83950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 84000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 84050 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 84100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 84150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 84200 loss: 158.847 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 84250 loss: 125.743 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 84300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 84350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 84400 loss: 179.306 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 84450 loss: 153.359 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 84500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 84550 loss: 99.527 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 84600 loss: 181.002 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 84650 loss: 126.784 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 84700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 84750 loss: 125.746 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 84800 loss: 137.895 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 84850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 84900 loss: 141.360 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 84950 loss: 153.360 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 85000 loss: 113.627 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 85050 loss: 125.750 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 85100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 85150 loss: 113.322 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 85200 loss: 98.106 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 85250 loss: 116.497 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 85300 loss: 168.616 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 85350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 85400 loss: 153.433 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 85450 loss: 168.676 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 85500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 85550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 85600 loss: 86.090 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 85650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85700 loss: -0.000 training accuracy: 1.000 validation accuracy: 0.200 \n",
      "Step 85750 loss: 153.407 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 85800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 85850 loss: 98.768 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 85900 loss: 153.418 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 85950 loss: 182.030 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 86000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 86050 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 86100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 86150 loss: 153.382 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 86200 loss: 171.623 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 86250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 86300 loss: 153.646 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 86350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 86400 loss: 126.205 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 86450 loss: 168.574 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 86500 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 86550 loss: 136.696 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 86600 loss: 125.797 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 86650 loss: 140.956 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 86700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 86750 loss: 181.102 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 86800 loss: 168.614 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 86850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 86900 loss: 153.235 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 86950 loss: 208.626 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 87000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 87050 loss: 104.875 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 87100 loss: 153.380 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 87150 loss: 129.211 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 87200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 87250 loss: 82.889 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 87300 loss: 138.006 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 87350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 87400 loss: 174.386 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 87450 loss: 125.761 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 87500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 87550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 87600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 87650 loss: 168.982 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 87700 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 87750 loss: 71.338 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 87800 loss: 125.792 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 87850 loss: 85.960 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 87900 loss: 70.636 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 87950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 88000 loss: 183.022 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 88050 loss: 153.404 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 88100 loss: 70.527 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 88150 loss: 193.408 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 88200 loss: 141.289 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 88250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 88300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 88350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 88400 loss: 196.357 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 88450 loss: 110.521 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 88500 loss: 156.638 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 88550 loss: 126.039 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 88600 loss: 140.853 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 88650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 88700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 88750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 88800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 88850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 88900 loss: 181.008 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 88950 loss: 125.759 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 89000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 89050 loss: 113.634 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 89100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 89150 loss: 98.203 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 89200 loss: 181.110 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 89250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 89300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 89350 loss: 153.363 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 89400 loss: 70.601 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 89450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 89500 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 89550 loss: 98.077 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 89600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 89650 loss: 153.392 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 89700 loss: 153.432 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 89750 loss: 141.003 training accuracy: 0.400 validation accuracy: 0.900 \n",
      "Step 89800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 89850 loss: 125.727 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 89900 loss: 113.339 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 89950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 90000 loss: 181.143 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 90050 loss: 125.973 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 90100 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 90150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 90200 loss: 125.840 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 90250 loss: 70.538 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 90300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 90350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 90400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 90450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 90500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 90550 loss: 128.612 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 90600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 90650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 90700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 90750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 90800 loss: 113.634 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 90850 loss: 127.899 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 90900 loss: 113.333 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 90950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 91000 loss: 113.381 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 91050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 91100 loss: 126.751 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 91150 loss: 181.077 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 91200 loss: 128.522 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 91250 loss: 168.726 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 91300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 91350 loss: 86.314 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 91400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 91450 loss: 128.787 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 91500 loss: 153.522 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 91550 loss: 141.145 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 91600 loss: 148.788 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 91650 loss: 125.729 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 91700 loss: 134.826 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 91750 loss: 140.993 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 91800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 91850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 91900 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 91950 loss: 70.632 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 92000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 92050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 92100 loss: 125.730 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 92150 loss: 85.857 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 92200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 92250 loss: 153.362 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 92300 loss: 208.621 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 92350 loss: 125.764 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 92400 loss: 128.570 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 92450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 92500 loss: 86.089 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 92550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 92600 loss: 150.195 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 92650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 92700 loss: 156.971 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 92750 loss: 110.513 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 92800 loss: 141.091 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 92850 loss: 126.179 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 92900 loss: 153.471 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 92950 loss: 110.515 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 93000 loss: 138.349 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 93050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 93100 loss: -0.000 training accuracy: 1.000 validation accuracy: 0.400 \n",
      "Step 93150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 93200 loss: 208.687 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 93250 loss: 125.827 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 93300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 93350 loss: 180.971 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 93400 loss: 196.282 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 93450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 93500 loss: 58.126 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 93550 loss: 153.468 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 93600 loss: 153.409 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 93650 loss: 156.236 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 93700 loss: 70.466 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 93750 loss: 125.725 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 93800 loss: 181.169 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 93850 loss: 181.403 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 93900 loss: 128.532 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 93950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 94000 loss: 168.616 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 94050 loss: 156.591 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 94100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 94150 loss: 104.295 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 94200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 94250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 94300 loss: 236.270 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 94350 loss: 208.921 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 94400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 94450 loss: 153.563 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 94500 loss: 153.450 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 94550 loss: 165.613 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 94600 loss: 113.172 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 94650 loss: 98.117 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 94700 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 94750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 94800 loss: 141.036 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 94850 loss: 98.147 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 94900 loss: 179.554 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 94950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 95000 loss: 125.846 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 95050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 95100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 95150 loss: 153.468 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 95200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 95250 loss: 42.866 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 95300 loss: 208.619 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 95350 loss: 153.359 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 95400 loss: 149.327 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 95450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 95500 loss: 126.362 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 95550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 95600 loss: 153.372 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 95650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 95700 loss: 45.662 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 95750 loss: 113.403 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 95800 loss: 240.647 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 95850 loss: 153.641 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 95900 loss: 110.497 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 95950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 96000 loss: 70.502 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 96050 loss: 153.473 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 96100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 96150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 96200 loss: 125.760 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 96250 loss: 114.128 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 96300 loss: 189.920 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 96350 loss: 125.762 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 96400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 96450 loss: 236.250 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 96500 loss: 125.737 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 96550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 96600 loss: 98.133 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 96650 loss: 153.389 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 96700 loss: 236.398 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 96750 loss: 98.272 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 96800 loss: 70.464 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 96850 loss: 138.061 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 96900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 96950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 97000 loss: 156.308 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 97050 loss: 43.171 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 97100 loss: 125.906 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 97150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 97200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 97250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 97300 loss: 125.899 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 97350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 97400 loss: 142.089 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 97450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 97500 loss: 101.156 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 97550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 97600 loss: 236.492 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 97650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 97700 loss: 165.785 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 97750 loss: 168.619 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 97800 loss: 153.359 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 97850 loss: 125.940 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 97900 loss: 208.737 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 97950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 98000 loss: 42.870 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 98050 loss: 98.419 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 98100 loss: 196.709 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 98150 loss: 141.441 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 98200 loss: 145.147 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 98250 loss: 165.744 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 98300 loss: 55.248 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 98350 loss: 138.152 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 98400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 98450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 98500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 98550 loss: 125.727 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 98600 loss: 98.121 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 98650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 98700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 98750 loss: 70.501 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 98800 loss: 113.610 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 98850 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 98900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 98950 loss: 125.857 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 99000 loss: 181.171 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 99050 loss: 153.378 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 99100 loss: 98.158 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 99150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 99200 loss: 181.249 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 99250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 99300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 99350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 99400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 99450 loss: 125.747 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 99500 loss: 223.847 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 99550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 99600 loss: 193.412 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 99650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 99700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 99750 loss: 180.996 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 99800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 99850 loss: 125.763 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 99900 loss: 98.271 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 99950 loss: 113.655 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 100000 loss: 125.736 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 100050 loss: 113.615 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 100100 loss: 125.747 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 100150 loss: 125.449 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 100200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 100250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 100300 loss: 113.032 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 100350 loss: 72.780 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 100400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 100450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 100500 loss: 113.342 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 100550 loss: 125.829 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 100600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 100650 loss: 82.891 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 100700 loss: 153.499 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 100750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 100800 loss: 153.377 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 100850 loss: 110.457 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 100900 loss: 140.907 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 100950 loss: 98.223 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 101000 loss: 47.640 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 101050 loss: 110.525 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 101100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 101150 loss: 153.417 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 101200 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 101250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 101300 loss: 128.639 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 101350 loss: 98.097 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 101400 loss: 153.408 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 101450 loss: 208.632 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 101500 loss: 141.037 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 101550 loss: 82.871 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 101600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 101650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 101700 loss: 153.388 training accuracy: 0.400 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 101750 loss: 110.520 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 101800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 101850 loss: 113.714 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 101900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 101950 loss: 153.374 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 102000 loss: 153.402 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 102050 loss: 156.271 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 102100 loss: 208.595 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 102150 loss: 125.729 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 102200 loss: 126.121 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 102250 loss: 98.119 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 102300 loss: 106.042 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 102350 loss: 153.426 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 102400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 102450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 102500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 102550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 102600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 102650 loss: 70.530 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 102700 loss: 116.675 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 102750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 102800 loss: 153.360 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 102850 loss: 125.732 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 102900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 102950 loss: 110.521 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 103000 loss: 85.737 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 103050 loss: 168.798 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 103100 loss: 225.579 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 103150 loss: 143.836 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 103200 loss: 125.975 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 103250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 103300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 103350 loss: 153.350 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 103400 loss: 85.737 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 103450 loss: 128.453 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 103500 loss: 70.474 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 103550 loss: 153.365 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 103600 loss: 153.361 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 103650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 103700 loss: 180.988 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 103750 loss: 98.150 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 103800 loss: 138.149 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 103850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 103900 loss: 169.088 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 103950 loss: 181.004 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 104000 loss: 98.200 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 104050 loss: 153.411 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 104100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 104150 loss: 125.732 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 104200 loss: 153.429 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 104250 loss: 153.425 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 104300 loss: 113.743 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 104350 loss: 113.395 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 104400 loss: 147.070 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 104450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 104500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 104550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 104600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 104650 loss: 125.732 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 104700 loss: 113.428 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 104750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 104800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 104850 loss: 137.474 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 104900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 104950 loss: 98.161 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 105000 loss: 168.856 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 105050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 105100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 105150 loss: 208.221 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 105200 loss: 183.745 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 105250 loss: 153.546 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 105300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 105350 loss: 128.924 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 105400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 105450 loss: 125.405 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 105500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 105550 loss: 153.383 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 105600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 105650 loss: 125.934 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 105700 loss: 141.172 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 105750 loss: 168.881 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 105800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 105850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 105900 loss: 125.723 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 105950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 106000 loss: 98.271 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 106050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 106100 loss: 168.862 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 106150 loss: 125.759 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 106200 loss: 159.454 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 106250 loss: 113.264 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 106300 loss: 70.734 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 106350 loss: 181.047 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 106400 loss: 113.302 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 106450 loss: 208.647 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 106500 loss: 138.116 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 106550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 106600 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 106650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 106700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 106750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 106800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 106850 loss: 82.896 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 106900 loss: 169.134 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 106950 loss: 180.988 training accuracy: 0.300 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 107000 loss: 85.810 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 107050 loss: 125.736 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 107100 loss: 113.403 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 107150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 107200 loss: 98.192 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 107250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 107300 loss: 113.323 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 107350 loss: 98.591 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 107400 loss: 125.821 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 107450 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 107500 loss: 153.355 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 107550 loss: 70.553 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 107600 loss: 98.110 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 107650 loss: 128.529 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 107700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 107750 loss: 140.994 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 107800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 107850 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 107900 loss: 153.598 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 107950 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 108000 loss: 129.084 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 108050 loss: 85.771 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 108100 loss: 141.006 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 108150 loss: 125.785 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 108200 loss: 125.729 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 108250 loss: 156.865 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 108300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 108350 loss: 98.101 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 108400 loss: 98.123 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 108450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 108500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 108550 loss: 125.735 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 108600 loss: 156.250 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 108650 loss: 181.040 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 108700 loss: 168.613 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 108750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 108800 loss: 141.159 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 108850 loss: 70.540 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 108900 loss: 113.416 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 108950 loss: 126.084 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 109000 loss: 141.705 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 109050 loss: 138.063 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 109100 loss: 138.152 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 109150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 109200 loss: 31.493 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 109250 loss: 153.378 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 109300 loss: 98.110 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 109350 loss: 58.129 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 109400 loss: 236.257 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 109450 loss: 58.051 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 109500 loss: 85.740 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 109550 loss: 141.000 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 109600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 109650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 109700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 109750 loss: 113.310 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 109800 loss: 138.149 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 109850 loss: 125.735 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 109900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 109950 loss: 125.856 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 110000 loss: 70.400 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 110050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 110100 loss: 138.153 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 110150 loss: 98.219 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 110200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 110250 loss: 125.840 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 110300 loss: 125.774 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 110350 loss: 153.327 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 110400 loss: 55.199 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 110450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 110500 loss: 181.020 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 110550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 110600 loss: 196.201 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 110650 loss: 181.013 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 110700 loss: 168.609 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 110750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 110800 loss: 236.254 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 110850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 110900 loss: 110.494 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 110950 loss: 153.352 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 111000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 111050 loss: 223.990 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 111100 loss: 236.323 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 111150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 111200 loss: 153.370 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 111250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 111300 loss: 181.178 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 111350 loss: 125.728 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 111400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 111450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 111500 loss: 98.171 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 111550 loss: 193.415 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 111600 loss: 85.797 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 111650 loss: 125.756 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 111700 loss: 98.102 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 111750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 111800 loss: 168.731 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 111850 loss: 141.012 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 111900 loss: 193.276 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 111950 loss: 153.360 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 112000 loss: 125.786 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 112050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 112100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 112150 loss: 98.100 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 112200 loss: 114.229 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 112250 loss: 153.361 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 112300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 112350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 112400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 112450 loss: 113.294 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 112500 loss: 168.735 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 112550 loss: 98.118 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 112600 loss: 116.163 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 112650 loss: 153.359 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 112700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 112750 loss: 125.846 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 112800 loss: 138.143 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 112850 loss: 141.068 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 112900 loss: 70.459 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 112950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 113000 loss: 113.303 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 113050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 113100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 113150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 113200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 113250 loss: 85.667 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 113300 loss: 73.280 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 113350 loss: 42.876 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 113400 loss: 156.214 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 113450 loss: 98.037 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 113500 loss: 125.777 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 113550 loss: 181.008 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 113600 loss: 188.787 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 113650 loss: 208.694 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 113700 loss: 42.866 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 113750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 113800 loss: 70.524 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 113850 loss: 208.621 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 113900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 113950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 114000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 114050 loss: 128.590 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 114100 loss: 181.083 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 114150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 114200 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 114250 loss: 85.679 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 114300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 114350 loss: 153.358 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 114400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 114450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 114500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 114550 loss: 98.143 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 114600 loss: 125.744 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 114650 loss: 124.789 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 114700 loss: 144.148 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 114750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 114800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 114850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 114900 loss: 153.406 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 114950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 115000 loss: 125.730 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 115050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 115100 loss: 180.997 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 115150 loss: 51.556 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 115200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 115250 loss: 168.623 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 115300 loss: 42.867 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 115350 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 115400 loss: 156.232 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 115450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 115500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 115550 loss: 70.495 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 115600 loss: 168.568 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 115650 loss: 85.594 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 115700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 115750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 115800 loss: 70.474 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 115850 loss: 125.761 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 115900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 115950 loss: 153.424 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 116000 loss: 85.823 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 116050 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 116100 loss: 153.982 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 116150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 116200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 116250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 116300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 116350 loss: 113.396 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 116400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 116450 loss: 113.255 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 116500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 116550 loss: 180.994 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 116600 loss: 168.654 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 116650 loss: 180.997 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 116700 loss: 141.179 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 116750 loss: 153.366 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 116800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 116850 loss: 183.902 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 116900 loss: 100.974 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 116950 loss: 153.365 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 117000 loss: 192.819 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 117050 loss: 156.051 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 117100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 117150 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 117200 loss: 70.464 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 117250 loss: 110.525 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 117300 loss: 98.105 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 117350 loss: 85.770 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 117400 loss: 181.138 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 117450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 117500 loss: 141.177 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 117550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 117600 loss: 225.486 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 117650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 117700 loss: 141.019 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 117750 loss: 181.118 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 117800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 117850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 117900 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 117950 loss: 153.379 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 118000 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 118050 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 118100 loss: 135.226 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 118150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 118200 loss: 180.993 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 118250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 118300 loss: 113.476 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 118350 loss: 98.152 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 118400 loss: 70.484 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 118450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 118500 loss: 168.408 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 118550 loss: 153.566 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 118600 loss: 113.290 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 118650 loss: 141.042 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 118700 loss: 153.505 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 118750 loss: 98.252 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 118800 loss: 125.755 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 118850 loss: 70.506 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 118900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 118950 loss: 153.843 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 119000 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 119050 loss: 128.403 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 119100 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 119150 loss: 125.687 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 119200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 119250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 119300 loss: 85.906 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 119350 loss: 125.736 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 119400 loss: 140.804 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 119450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 119500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 119550 loss: 138.152 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 119600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 119650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 119700 loss: 180.986 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 119750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 119800 loss: 70.498 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 119850 loss: 85.766 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 119900 loss: 125.733 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 119950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 120000 loss: 153.455 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 120050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 120100 loss: 70.467 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 120150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 120200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 120250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 120300 loss: 133.649 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 120350 loss: 208.666 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 120400 loss: 113.338 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 120450 loss: 98.382 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 120500 loss: 125.679 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 120550 loss: 70.467 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 120600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 120650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 120700 loss: 82.892 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 120750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 120800 loss: 85.840 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 120850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 120900 loss: 171.546 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 120950 loss: 85.609 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 121000 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 121050 loss: 128.677 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 121100 loss: 140.930 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 121150 loss: 181.002 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 121200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 121250 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 121300 loss: 125.894 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 121350 loss: 98.097 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 121400 loss: 153.097 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 121450 loss: 181.128 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 121500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 121550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 121600 loss: 98.125 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 121650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 121700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 121750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 121800 loss: 168.564 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 121850 loss: 125.866 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 121900 loss: 153.370 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 121950 loss: 141.243 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 122000 loss: 113.301 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 122050 loss: 85.713 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 122100 loss: 113.312 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 122150 loss: 125.722 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 122200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 122250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 122300 loss: 100.793 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 122350 loss: 153.365 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 122400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 122450 loss: 140.948 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 122500 loss: 98.106 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 122550 loss: 156.150 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 122600 loss: 113.353 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 122650 loss: 73.328 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 122700 loss: 98.103 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 122750 loss: 153.371 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 122800 loss: 156.202 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 122850 loss: 113.374 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 122900 loss: 125.728 training accuracy: 0.500 validation accuracy: 0.600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 122950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 123000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 123050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 123100 loss: 153.330 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 123150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 123200 loss: 236.300 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 123250 loss: 181.014 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 123300 loss: 70.641 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 123350 loss: 141.016 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 123400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 123450 loss: 193.416 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 123500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 123550 loss: 140.989 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 123600 loss: 30.470 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 123650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 123700 loss: 125.560 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 123750 loss: 140.934 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 123800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 123850 loss: 113.321 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 123900 loss: 128.628 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 123950 loss: 223.902 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 124000 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 124050 loss: 141.249 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 124100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 124150 loss: 125.741 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 124200 loss: 140.928 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 124250 loss: 153.476 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 124300 loss: 153.418 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 124350 loss: 211.543 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 124400 loss: 181.005 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 124450 loss: 125.694 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 124500 loss: 98.102 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 124550 loss: 98.113 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 124600 loss: 113.304 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 124650 loss: 125.808 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 124700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 124750 loss: 183.779 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 124800 loss: 208.679 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 124850 loss: 183.821 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 124900 loss: 208.193 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 124950 loss: 193.362 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 125000 loss: 141.637 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 125050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 125100 loss: 153.361 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 125150 loss: 141.013 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 125200 loss: 153.387 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 125250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 125300 loss: 98.637 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 125350 loss: 85.822 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 125400 loss: 99.392 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 125450 loss: 98.055 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 125500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 125550 loss: 180.988 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 125600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 125650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 125700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 125750 loss: 98.141 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 125800 loss: 181.038 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 125850 loss: 98.058 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 125900 loss: 168.822 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 125950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 126000 loss: 98.056 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 126050 loss: 196.246 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 126100 loss: 116.197 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 126150 loss: 153.476 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 126200 loss: 70.465 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 126250 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 126300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 126350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 126400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 126450 loss: 138.151 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 126500 loss: 181.029 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 126550 loss: 180.989 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 126600 loss: 42.846 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 126650 loss: 125.728 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 126700 loss: 98.096 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 126750 loss: 125.752 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 126800 loss: 70.316 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 126850 loss: 173.064 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 126900 loss: 98.155 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 126950 loss: 128.444 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 127000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 127050 loss: 208.624 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 127100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 127150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 127200 loss: 98.179 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 127250 loss: 153.566 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 127300 loss: 70.494 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 127350 loss: 125.792 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 127400 loss: 125.617 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 127450 loss: 196.211 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 127500 loss: 138.067 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 127550 loss: 125.761 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 127600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 127650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 127700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 127750 loss: 70.511 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 127800 loss: 113.334 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 127850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 127900 loss: 100.935 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 127950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 128000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 128050 loss: 153.403 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 128100 loss: 153.412 training accuracy: 0.400 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 128150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 128200 loss: 181.199 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 128250 loss: 98.103 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 128300 loss: 131.405 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 128350 loss: 153.363 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 128400 loss: 143.697 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 128450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 128500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 128550 loss: 141.082 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 128600 loss: 113.639 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 128650 loss: 98.140 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 128700 loss: 98.128 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 128750 loss: 140.931 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 128800 loss: 140.935 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 128850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 128900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 128950 loss: 168.595 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 129000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 129050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 129100 loss: 153.637 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 129150 loss: 116.434 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 129200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 129250 loss: 168.681 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 129300 loss: 98.147 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 129350 loss: 196.233 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 129400 loss: 95.809 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 129450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 129500 loss: 137.973 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 129550 loss: 156.249 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 129600 loss: 113.274 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 129650 loss: 70.493 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 129700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 129750 loss: 196.225 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 129800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 129850 loss: 153.461 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 129900 loss: 196.238 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 129950 loss: 154.020 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 130000 loss: 98.096 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 130050 loss: 125.738 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 130100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 130150 loss: 125.727 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 130200 loss: 138.149 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 130250 loss: 153.064 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 130300 loss: 153.509 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 130350 loss: 125.796 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 130400 loss: 165.778 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 130450 loss: 140.863 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 130500 loss: 140.965 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 130550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 130600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 130650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 130700 loss: 168.609 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 130750 loss: 180.995 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 130800 loss: 236.252 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 130850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 130900 loss: 165.761 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 130950 loss: 196.236 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 131000 loss: 113.298 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 131050 loss: 70.516 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 131100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 131150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 131200 loss: 140.998 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 131250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 131300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 131350 loss: 125.804 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 131400 loss: 125.730 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 131450 loss: 113.591 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 131500 loss: 128.527 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 131550 loss: 104.592 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 131600 loss: 70.596 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 131650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 131700 loss: 113.338 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 131750 loss: 125.727 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 131800 loss: 141.333 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 131850 loss: 82.930 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 131900 loss: 183.434 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 131950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 132000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 132050 loss: 153.403 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 132100 loss: 168.769 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 132150 loss: 168.717 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 132200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 132250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 132300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 132350 loss: 125.901 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 132400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 132450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 132500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 132550 loss: 180.945 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 132600 loss: 153.417 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 132650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 132700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 132750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 132800 loss: 208.659 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 132850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 132900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 132950 loss: 125.771 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 133000 loss: 115.145 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 133050 loss: 70.469 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 133100 loss: 128.627 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 133150 loss: 125.753 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 133200 loss: 153.366 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 133250 loss: 82.896 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 133300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 133350 loss: 42.854 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 133400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 133450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 133500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 133550 loss: 128.466 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 133600 loss: 100.929 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 133650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 133700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 133750 loss: 141.413 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 133800 loss: 125.739 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 133850 loss: 85.748 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 133900 loss: 153.573 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 133950 loss: 168.758 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 134000 loss: 153.352 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 134050 loss: 168.718 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 134100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 134150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 134200 loss: 125.846 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 134250 loss: 85.770 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 134300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 134350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 134400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 134450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 134500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 134550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 134600 loss: 113.308 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 134650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 134700 loss: 168.701 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 134750 loss: 98.193 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 134800 loss: 153.376 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 134850 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 134900 loss: 27.630 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 134950 loss: 128.550 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 135000 loss: 165.705 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 135050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 135100 loss: 125.774 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 135150 loss: 125.728 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 135200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 135250 loss: 251.487 training accuracy: 0.000 validation accuracy: 0.400 \n",
      "Step 135300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 135350 loss: 98.126 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 135400 loss: 153.358 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 135450 loss: 153.429 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 135500 loss: 125.902 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 135550 loss: 140.779 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 135600 loss: 141.030 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 135650 loss: 113.396 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 135700 loss: 153.311 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 135750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 135800 loss: 153.473 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 135850 loss: 140.929 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 135900 loss: 70.496 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 135950 loss: 125.785 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 136000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 136050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 136100 loss: 42.920 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 136150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 136200 loss: 180.920 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 136250 loss: 164.375 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 136300 loss: 110.522 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 136350 loss: 180.996 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 136400 loss: 100.989 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 136450 loss: 125.725 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 136500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 136550 loss: 135.581 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 136600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 136650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 136700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 136750 loss: 153.368 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 136800 loss: 181.009 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 136850 loss: 125.756 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 136900 loss: 70.516 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 136950 loss: 168.735 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 137000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 137050 loss: 125.783 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 137100 loss: 138.109 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 137150 loss: 181.068 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 137200 loss: 125.727 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 137250 loss: 125.734 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 137300 loss: 153.359 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 137350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 137400 loss: 185.917 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 137450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 137500 loss: 125.779 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 137550 loss: 128.515 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 137600 loss: 165.796 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 137650 loss: 70.712 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 137700 loss: 70.575 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 137750 loss: 70.465 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 137800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 137850 loss: 153.479 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 137900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 137950 loss: 113.350 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 138000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 138050 loss: 196.295 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 138100 loss: 168.629 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 138150 loss: 113.395 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 138200 loss: 165.784 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 138250 loss: 153.396 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 138300 loss: 208.622 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 138350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 138400 loss: 98.100 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 138450 loss: 58.123 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 138500 loss: 153.405 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 138550 loss: 70.472 training accuracy: 0.700 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 138600 loss: 141.095 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 138650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 138700 loss: 113.307 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 138750 loss: 141.178 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 138800 loss: 125.727 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 138850 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 138900 loss: 110.505 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 138950 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 139000 loss: 196.208 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 139050 loss: 156.223 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 139100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 139150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 139200 loss: 153.344 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 139250 loss: 153.395 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 139300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 139350 loss: 132.568 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 139400 loss: 168.771 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 139450 loss: 223.945 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 139500 loss: 180.998 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 139550 loss: 153.391 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 139600 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 139650 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 139700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 139750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 139800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 139850 loss: 110.570 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 139900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 139950 loss: 140.983 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 140000 loss: 70.505 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 140050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 140100 loss: 140.934 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 140150 loss: 153.310 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 140200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 140250 loss: 70.464 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 140300 loss: 85.720 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 140350 loss: 98.150 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 140400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 140450 loss: 43.074 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 140500 loss: 140.653 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 140550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 140600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 140650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 140700 loss: 153.405 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 140750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 140800 loss: 153.364 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 140850 loss: 98.112 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 140900 loss: 85.668 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 140950 loss: 125.769 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 141000 loss: 145.597 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 141050 loss: 98.236 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 141100 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 141150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 141200 loss: 196.396 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 141250 loss: 153.377 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 141300 loss: 153.375 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 141350 loss: 208.816 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 141400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 141450 loss: 183.844 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 141500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 141550 loss: 129.538 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 141600 loss: 42.842 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 141650 loss: 43.015 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 141700 loss: 140.983 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 141750 loss: 125.726 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 141800 loss: 168.416 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 141850 loss: 153.366 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 141900 loss: 101.153 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 141950 loss: 113.432 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 142000 loss: 168.559 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 142050 loss: 123.702 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 142100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 142150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 142200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 142250 loss: 42.833 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 142300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 142350 loss: 153.360 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 142400 loss: 125.726 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 142450 loss: 180.990 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 142500 loss: 125.726 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 142550 loss: 138.214 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 142600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 142650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 142700 loss: 153.383 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 142750 loss: 98.096 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 142800 loss: 125.862 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 142850 loss: 196.506 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 142900 loss: 138.166 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 142950 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 143000 loss: 126.014 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 143050 loss: 208.667 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 143100 loss: 138.157 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 143150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 143200 loss: 125.726 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 143250 loss: 125.761 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 143300 loss: 70.473 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 143350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 143400 loss: 85.972 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 143450 loss: 113.304 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 143500 loss: 168.648 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 143550 loss: 98.105 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 143600 loss: 113.344 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 143650 loss: 110.506 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 143700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 143750 loss: 131.067 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 143800 loss: 125.735 training accuracy: 0.500 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 143850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 143900 loss: 125.723 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 143950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 144000 loss: 100.905 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 144050 loss: 98.100 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 144100 loss: 85.874 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 144150 loss: 153.363 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 144200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 144250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 144300 loss: 141.281 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 144350 loss: 125.718 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 144400 loss: 156.596 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 144450 loss: 181.075 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 144500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 144550 loss: 153.362 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 144600 loss: 153.373 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 144650 loss: 101.731 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 144700 loss: 125.719 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 144750 loss: 196.254 training accuracy: 0.200 validation accuracy: 0.800 \n",
      "Step 144800 loss: 153.391 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 144850 loss: 153.437 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 144900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 144950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 145000 loss: 168.717 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 145050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 145100 loss: 168.413 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 145150 loss: 153.409 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 145200 loss: 101.461 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 145250 loss: 142.040 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 145300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 145350 loss: 140.928 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 145400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 145450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 145500 loss: 73.264 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 145550 loss: 193.414 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 145600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 145650 loss: 180.822 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 145700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 145750 loss: 141.022 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 145800 loss: 128.623 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 145850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 145900 loss: 221.047 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 145950 loss: 153.358 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 146000 loss: 113.352 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 146050 loss: 98.341 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 146100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 146150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.000 \n",
      "Step 146200 loss: 179.136 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 146250 loss: 42.970 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 146300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 146350 loss: 180.991 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 146400 loss: 153.364 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 146450 loss: 140.950 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 146500 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 146550 loss: 156.187 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 146600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 146650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 146700 loss: 70.481 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 146750 loss: 58.055 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 146800 loss: 116.425 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 146850 loss: 140.931 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 146900 loss: 58.055 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 146950 loss: 58.121 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 147000 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 147050 loss: 98.195 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 147100 loss: 98.110 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 147150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 147200 loss: 110.520 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 147250 loss: 70.465 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 147300 loss: 140.960 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 147350 loss: 98.109 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 147400 loss: 70.481 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 147450 loss: 165.552 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 147500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 147550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 147600 loss: 125.726 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 147650 loss: 125.679 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 147700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 147750 loss: 153.359 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 147800 loss: 180.985 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 147850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 147900 loss: 113.711 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 147950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 148000 loss: 82.807 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 148050 loss: 98.094 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 148100 loss: 70.466 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 148150 loss: 113.464 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 148200 loss: 165.785 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 148250 loss: 125.749 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 148300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 148350 loss: 153.515 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 148400 loss: 70.645 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 148450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 148500 loss: 196.256 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 148550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 148600 loss: 58.078 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 148650 loss: 58.168 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 148700 loss: 140.961 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 148750 loss: 125.726 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 148800 loss: 98.103 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 148850 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 148900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 148950 loss: 168.571 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 149000 loss: 125.730 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 149050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 149100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 149150 loss: 208.622 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 149200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 149250 loss: 125.740 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 149300 loss: 126.251 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 149350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 149400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 149450 loss: 113.354 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 149500 loss: 125.812 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 149550 loss: 168.611 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 149600 loss: 125.746 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 149650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 149700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 149750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 149800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 149850 loss: 180.958 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 149900 loss: 153.359 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 149950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 150000 loss: 70.464 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 150050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 150100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 150150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 150200 loss: 113.318 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 150250 loss: 181.000 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 150300 loss: 70.464 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 150350 loss: 85.681 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 150400 loss: 125.748 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 150450 loss: 153.260 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 150500 loss: 140.941 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 150550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 150600 loss: 98.202 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 150650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 150700 loss: 111.662 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 150750 loss: 113.225 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 150800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 150850 loss: 126.246 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 150900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 150950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 151000 loss: 134.611 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 151050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 151100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 151150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 151200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 151250 loss: 181.281 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 151300 loss: 94.927 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 151350 loss: 168.701 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 151400 loss: 98.097 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 151450 loss: 153.479 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 151500 loss: 70.620 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 151550 loss: 183.793 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 151600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 151650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 151700 loss: 141.080 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 151750 loss: 181.032 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 151800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 151850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 151900 loss: 70.543 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 151950 loss: 141.029 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 152000 loss: 208.634 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 152050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 152100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 152150 loss: 180.990 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 152200 loss: 168.454 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 152250 loss: 168.656 training accuracy: 0.300 validation accuracy: 0.800 \n",
      "Step 152300 loss: 138.151 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 152350 loss: 101.020 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 152400 loss: 58.147 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 152450 loss: 98.125 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 152500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 152550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 152600 loss: 110.517 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 152650 loss: 70.465 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 152700 loss: 141.166 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 152750 loss: 87.210 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 152800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 152850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 152900 loss: 125.746 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 152950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 153000 loss: 156.323 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 153050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 153100 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 153150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 153200 loss: 85.713 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 153250 loss: 153.675 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 153300 loss: 85.916 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 153350 loss: 113.184 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 153400 loss: 70.470 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 153450 loss: 98.195 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 153500 loss: 55.201 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 153550 loss: 251.457 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 153600 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 153650 loss: 70.520 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 153700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 153750 loss: 42.834 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 153800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 153850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 153900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 153950 loss: 169.513 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 154000 loss: 208.640 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 154050 loss: 125.727 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 154100 loss: 168.580 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 154150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 154200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 154250 loss: 156.569 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 154300 loss: 125.801 training accuracy: 0.500 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 154350 loss: 236.333 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 154400 loss: 153.410 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 154450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 154500 loss: 141.104 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 154550 loss: 125.728 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 154600 loss: 113.470 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 154650 loss: 236.296 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 154700 loss: 98.165 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 154750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 154800 loss: 153.470 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 154850 loss: 113.578 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 154900 loss: 42.872 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 154950 loss: 125.908 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 155000 loss: 113.365 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 155050 loss: 208.629 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 155100 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 155150 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 155200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 155250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 155300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 155350 loss: 70.486 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 155400 loss: 113.453 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 155450 loss: 141.016 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 155500 loss: 153.384 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 155550 loss: 140.329 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 155600 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 155650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 155700 loss: 180.993 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 155750 loss: 193.465 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 155800 loss: 180.992 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 155850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 155900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 155950 loss: 98.117 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 156000 loss: 98.418 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 156050 loss: 181.095 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 156100 loss: 168.656 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 156150 loss: 181.021 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 156200 loss: 98.175 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 156250 loss: 98.378 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 156300 loss: 116.509 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 156350 loss: 125.729 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 156400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 156450 loss: -0.000 training accuracy: 1.000 validation accuracy: 0.300 \n",
      "Step 156500 loss: 126.004 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 156550 loss: 168.638 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 156600 loss: 92.020 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 156650 loss: 125.857 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 156700 loss: 98.319 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 156750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 156800 loss: 86.041 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 156850 loss: 107.813 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 156900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 156950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 157000 loss: 180.996 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 157050 loss: 156.405 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 157100 loss: 168.942 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 157150 loss: 208.683 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 157200 loss: 125.795 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 157250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 157300 loss: 98.186 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 157350 loss: 70.465 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 157400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 157450 loss: 139.700 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 157500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 157550 loss: 153.505 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 157600 loss: 168.582 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 157650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 157700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 157750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 157800 loss: 140.942 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 157850 loss: 98.156 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 157900 loss: 55.263 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 157950 loss: 181.270 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 158000 loss: 97.993 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 158050 loss: 125.733 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 158100 loss: 98.503 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 158150 loss: 209.465 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 158200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 158250 loss: 98.145 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 158300 loss: 125.726 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 158350 loss: 98.097 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 158400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 158450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 158500 loss: 113.581 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 158550 loss: 98.120 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 158600 loss: 251.692 training accuracy: 0.000 validation accuracy: 0.700 \n",
      "Step 158650 loss: 192.435 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 158700 loss: 141.074 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 158750 loss: 141.079 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 158800 loss: 125.709 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 158850 loss: 140.838 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 158900 loss: 180.991 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 158950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 159000 loss: 113.383 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 159050 loss: 140.991 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 159100 loss: 98.099 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 159150 loss: 153.375 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 159200 loss: 125.733 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 159250 loss: 196.219 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 159300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 159350 loss: 85.723 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 159400 loss: 126.014 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 159450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 159500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 159550 loss: 180.991 training accuracy: 0.300 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 159600 loss: 110.533 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 159650 loss: 125.904 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 159700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 159750 loss: 208.619 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 159800 loss: 181.773 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 159850 loss: 208.666 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 159900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 159950 loss: 101.144 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 160000 loss: 153.358 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 160050 loss: 98.136 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 160100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 160150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 160200 loss: 153.441 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 160250 loss: 70.571 training accuracy: 0.700 validation accuracy: 0.800 \n",
      "Step 160300 loss: 156.301 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 160350 loss: 141.284 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 160400 loss: 85.704 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 160450 loss: 70.467 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 160500 loss: 126.095 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 160550 loss: 169.983 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 160600 loss: 153.362 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 160650 loss: 110.539 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 160700 loss: 196.218 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 160750 loss: 98.110 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 160800 loss: 98.001 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 160850 loss: 140.885 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 160900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 160950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 161000 loss: 69.190 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 161050 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.600 \n",
      "Step 161100 loss: 125.809 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 161150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 161200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 161250 loss: 156.224 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 161300 loss: 125.812 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 161350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 161400 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 161450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 161500 loss: 153.404 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 161550 loss: 125.749 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 161600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 161650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 161700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 161750 loss: 141.045 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 161800 loss: 138.140 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 161850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 161900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 161950 loss: 208.299 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 162000 loss: 98.104 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 162050 loss: 161.004 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 162100 loss: 153.384 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 162150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 162200 loss: 98.322 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 162250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 162300 loss: 181.034 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 162350 loss: 156.219 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 162400 loss: 208.662 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 162450 loss: 98.096 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 162500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 162550 loss: 153.398 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 162600 loss: 138.177 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 162650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 162700 loss: 196.390 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 162750 loss: 101.061 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 162800 loss: 125.752 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 162850 loss: 46.030 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 162900 loss: 85.723 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 162950 loss: 168.583 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 163000 loss: 141.618 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 163050 loss: 168.581 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 163100 loss: 141.005 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 163150 loss: 125.812 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 163200 loss: 98.101 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 163250 loss: 181.184 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 163300 loss: 128.726 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 163350 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 163400 loss: 98.098 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 163450 loss: 140.966 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 163500 loss: 98.154 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 163550 loss: 208.781 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 163600 loss: 113.541 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 163650 loss: 168.604 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 163700 loss: 156.172 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 163750 loss: 183.776 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 163800 loss: 42.848 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 163850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 163900 loss: 85.551 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 163950 loss: 138.977 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 164000 loss: 140.940 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 164050 loss: 168.238 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 164100 loss: 171.481 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 164150 loss: 87.702 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 164200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 164250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 164300 loss: 125.728 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 164350 loss: 153.371 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 164400 loss: 180.989 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 164450 loss: 168.619 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 164500 loss: 171.466 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 164550 loss: 98.190 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 164600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 164650 loss: 184.061 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 164700 loss: 236.250 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 164750 loss: 168.576 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 164800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 164850 loss: 181.149 training accuracy: 0.300 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 164900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 164950 loss: 70.464 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 165000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 165050 loss: 153.470 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 165100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 165150 loss: 70.536 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 165200 loss: 125.825 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 165250 loss: 145.809 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 165300 loss: 236.253 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 165350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 165400 loss: 165.785 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 165450 loss: 113.606 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 165500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 165550 loss: 140.973 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 165600 loss: 208.619 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 165650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 165700 loss: 113.329 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 165750 loss: 174.374 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 165800 loss: 125.777 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 165850 loss: 125.755 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 165900 loss: 113.350 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 165950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 166000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 166050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 166100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 166150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 166200 loss: 15.225 training accuracy: 0.900 validation accuracy: 0.100 \n",
      "Step 166250 loss: 85.841 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 166300 loss: 98.199 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 166350 loss: 125.752 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 166400 loss: 153.371 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 166450 loss: 197.146 training accuracy: 0.200 validation accuracy: 0.700 \n",
      "Step 166500 loss: 85.694 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 166550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 166600 loss: 137.663 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 166650 loss: 82.890 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 166700 loss: 98.092 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 166750 loss: 98.145 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 166800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 166850 loss: 125.733 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 166900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 166950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 167000 loss: 98.167 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 167050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 167100 loss: 125.751 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 167150 loss: 140.934 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 167200 loss: 223.904 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 167250 loss: 180.438 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 167300 loss: 125.820 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 167350 loss: 140.981 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 167400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 167450 loss: 153.416 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 167500 loss: 128.733 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 167550 loss: 125.731 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 167600 loss: 98.099 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 167650 loss: 42.904 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 167700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 167750 loss: 208.621 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 167800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 167850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 167900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 167950 loss: 125.928 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 168000 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 168050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 168100 loss: 98.006 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 168150 loss: 42.836 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 168200 loss: 168.565 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 168250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 168300 loss: 183.787 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 168350 loss: 70.529 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 168400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 168450 loss: 58.121 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 168500 loss: 156.174 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 168550 loss: 141.020 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 168600 loss: 86.043 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 168650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 168700 loss: 236.269 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 168750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 168800 loss: 85.740 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 168850 loss: 138.148 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 168900 loss: 128.626 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 168950 loss: 125.773 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 169000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 169050 loss: 85.542 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 169100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 169150 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 169200 loss: 125.766 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 169250 loss: 208.679 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 169300 loss: 100.752 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 169350 loss: 165.784 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 169400 loss: 181.454 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 169450 loss: 184.012 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 169500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 169550 loss: 153.459 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 169600 loss: 153.413 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 169650 loss: 55.261 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 169700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 169750 loss: 156.178 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 169800 loss: 180.991 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 169850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 169900 loss: 165.775 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 169950 loss: 153.359 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 170000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 170050 loss: 153.367 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 170100 loss: 156.158 training accuracy: 0.300 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 170150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 170200 loss: 128.541 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 170250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 170300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 170350 loss: 197.181 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 170400 loss: 153.364 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 170450 loss: 153.411 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 170500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 170550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 170600 loss: 153.357 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 170650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 170700 loss: 208.651 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 170750 loss: 153.368 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 170800 loss: 85.723 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 170850 loss: 70.466 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 170900 loss: 114.418 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 170950 loss: 85.715 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 171000 loss: 140.933 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 171050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 171100 loss: 125.590 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 171150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 171200 loss: 70.469 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 171250 loss: 100.925 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 171300 loss: 141.116 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 171350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 171400 loss: 181.135 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 171450 loss: 126.060 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 171500 loss: 208.661 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 171550 loss: 236.263 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 171600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 171650 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 171700 loss: 182.041 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 171750 loss: 129.284 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 171800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 171850 loss: 98.121 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 171900 loss: 140.934 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 171950 loss: 129.797 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 172000 loss: 168.648 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 172050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 172100 loss: 125.882 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 172150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 172200 loss: 110.297 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 172250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 172300 loss: 181.034 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 172350 loss: 165.772 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 172400 loss: 125.729 training accuracy: 0.500 validation accuracy: 0.600 \n"
     ]
    }
   ],
   "source": [
    "# let's set some hyperparameters\n",
    "batch_size = 10\n",
    "learning_rate = 0.00001\n",
    "n_epochs = 100\n",
    "print_every = 50\n",
    "# ========\n",
    "# Build the neural network with a wider hidden layer\n",
    "num_hidden = 100\n",
    "# ========\n",
    "\n",
    "# build the neural network\n",
    "layer_1 = layer(input_size, num_hidden, activation=nn.ReLU())\n",
    "layer_2 = layer(num_hidden, num_classes, activation=nn.Softmax(dim=-1))\n",
    "\n",
    "# create a hidden (middle) layer\n",
    "hidden_layer = layer_1(train_tensor)\n",
    "\n",
    "# create the output layer used to classify\n",
    "output = layer_2(hidden_layer)\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.SGD([layer_1.weight, layer_1.bias,\n",
    "                       layer_2.weight, layer_2.bias],\n",
    "                       lr=learning_rate)\n",
    "\n",
    "# train the network\n",
    "step = 0\n",
    "results = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "}\n",
    "for epoch in range(n_epochs):\n",
    "    # randomize the order in which we see the data in each epoch\n",
    "    random_order_indices = np.random.choice(train_tensor.shape[0], train_tensor.shape[0], replace=False)\n",
    "    \n",
    "    # iterate through the data in batches of size `batch_size`\n",
    "    for batch_indices in np.array_split(random_order_indices, random_order_indices.shape[0] // batch_size):\n",
    "      \n",
    "        train_data_batch = train_tensor[batch_indices]\n",
    "        train_labels_batch = train_labels[batch_indices]\n",
    "        train_onehot = to_one_hot(train_labels_batch, num_classes)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # get pass batch through layers\n",
    "        hidden_layer = layer_1(train_data_batch)\n",
    "        output = layer_2(hidden_layer)\n",
    "\n",
    "        # compute cross entropy\n",
    "        loss = train_onehot * torch.log(output+ 1e-6) + (1 - train_onehot) * torch.log(1 - output + 1e-6)\n",
    "        loss = -1 * loss.sum()\n",
    "\n",
    "        # backpropagate the loss\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # evaluate accuracy on both the training and validation datasets\n",
    "        if step % print_every == 0:\n",
    "            \n",
    "            # don't track gradients\n",
    "            with torch.no_grad():\n",
    "                # compute the predicted outputs\n",
    "                train_prediction = output.argmax(1).numpy()\n",
    "\n",
    "                # compute the accuracy over the batch\n",
    "                acc_training = np.mean(train_prediction == train_labels_batch.numpy())\n",
    "\n",
    "                # compute the loss on all the validation data\n",
    "                loss_np = []\n",
    "                output_np = []\n",
    "                labels_np = []\n",
    "\n",
    "                random_order_indices = np.random.choice(valid_tensor.shape[0], valid_tensor.shape[0], replace=False)\n",
    "\n",
    "                for batch_indices in np.array_split(random_order_indices, random_order_indices.shape[0] // batch_size):\n",
    "                    valid_data_batch = valid_tensor[batch_indices]\n",
    "                    valid_labels_batch = valid_labels[batch_indices]\n",
    "\n",
    "                    # pass through layers\n",
    "                    valid_hidden = layer_1(valid_data_batch)\n",
    "                    valid_output = layer_2(valid_hidden)\n",
    "\n",
    "                    # compute the predicted outputs\n",
    "\n",
    "                    prediction_np = valid_output.argmax(1).numpy()\n",
    "\n",
    "                    output_np = np.concatenate(prediction_np.reshape(-1,1), axis=0)\n",
    "                    labels_np = np.concatenate(valid_labels_batch.numpy().reshape(-1,1), axis=0)\n",
    "\n",
    "\n",
    "                # compute the accuracy over the whole dataset\n",
    "                acc_validation = np.mean(output_np == labels_np)\n",
    "\n",
    "                results['train_loss'].append(loss.item())\n",
    "                results['train_acc'].append(acc_training)\n",
    "                results['val_acc'].append(acc_validation)\n",
    "                print('Step {} loss: {:.3f} training accuracy: {:.3f} validation accuracy: {:.3f} '.format(\n",
    "                    step, loss.item(), acc_training, acc_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrN_IneACxNf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f405e252a30>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['train_loss'])\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Training loss')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['train_acc'], label='Training accuracy')\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['val_acc'], label='Validation accuracy')\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6jgM8CMGRnQ"
   },
   "source": [
    "## Exercise 4 - network depth\n",
    "\n",
    "Create a network with *two* hidden layers and compare its performance to the network with one hidden layer we just built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFJ5vLUi_rCY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 500 loss: 276.232 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 650 loss: 243.108 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 900 loss: 191.659 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 1000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 1050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 1100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 1150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 1200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 1250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 1300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 1350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 1400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 1450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 1500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 1550 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 1600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 1650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 1700 loss: 212.717 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 1750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 1800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 1850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 1900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 1950 loss: 184.411 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 2000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 2050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 2100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 2150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 2200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 2250 loss: 165.764 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 2300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 2350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 2400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 2450 loss: 155.438 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 2500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 2550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 2600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 2650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 2700 loss: 236.308 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 2750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 2800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 2850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 2900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 2950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 3000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 3050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 3100 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 3150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 3200 loss: 161.447 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 3250 loss: 221.015 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 3300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 3350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 3400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 3450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 3500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 3550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 3600 loss: 186.590 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 3650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 3700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 3750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 3800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 3850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 3900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 3950 loss: 125.751 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 4000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 4050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 4100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 4150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 4200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 4250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 4300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 4350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 4400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 4450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 4500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 4550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 4600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 4650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 4700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 4750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 4800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 4850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 4900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 4950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 5000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 5050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 5100 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 5150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 5200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 5250 loss: 192.977 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 5300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 5350 loss: 157.795 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 5400 loss: 165.540 training accuracy: 0.400 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 5500 loss: 138.136 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 5550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 5600 loss: 192.644 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 5650 loss: 191.158 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 5700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 5750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 5800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 5850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 5900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 5950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 6000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 6050 loss: 165.779 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 6100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 6150 loss: 221.049 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 6200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 6250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 6300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 6350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 6400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 6450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 6500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 6550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 6600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 6650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 6700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 6750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 6800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 6850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 6900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 6950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 7000 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 7050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 7100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 7150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 7200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 7250 loss: 112.123 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 7300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 7350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 7400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 7450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 7500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 7550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 7600 loss: 128.698 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 7650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 7700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 7750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 7800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 7850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 7900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 7950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 8000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 8050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 8100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 8150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 8200 loss: 132.741 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 8250 loss: 165.782 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 8300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 8350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 8400 loss: 193.402 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 8450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 8500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 8550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 8600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 8650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 8700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 8750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 8800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 8850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 8900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 8950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 9000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 9050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 9100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 9150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 9200 loss: 193.132 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 9250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 9300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 9350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 9400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 9450 loss: 109.794 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 9500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 9550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 9600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 9650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 9700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 9750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 9800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 9850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 9900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 9950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 10000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 10050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 10100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 10150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 10200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 10250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 10300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 10350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 10400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 10450 loss: 164.025 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 10500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 10550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 10600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 10650 loss: 137.217 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 10700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 10750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 10800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 10900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 10950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 11000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 11050 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 11100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 11150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 11200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 11250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 11300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 11350 loss: 185.379 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 11400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 11450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 11500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 11550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 11600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 11650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 11700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 11750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 11800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 11850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 11900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 11950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 12000 loss: 137.487 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 12050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 12100 loss: 215.263 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 12150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 12200 loss: 133.066 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 12250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 12300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 12350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 12400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 12450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.000 \n",
      "Step 12500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 12550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 12600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 12650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 12700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 12750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 12800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 12850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 12900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 12950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 13000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 13050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 13100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 13150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 13200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 13250 loss: -0.000 training accuracy: 1.000 validation accuracy: 0.200 \n",
      "Step 13300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 13350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 13400 loss: 131.937 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 13450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 13500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 13550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 13600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 13650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 13700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 13750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 13800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 13850 loss: 136.792 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 13900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 13950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 14000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 14050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 14100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 14150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 14200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 14250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 14300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 14350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 14400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 14450 loss: 82.660 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 14500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 14550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 14600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 14650 loss: 106.489 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 14700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 14750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 14800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 14850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 14900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 14950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 15000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 15050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 15100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 15150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 15200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 15250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 15300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 15350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 15400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 15450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 15500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 15550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 15600 loss: 101.539 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 15650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 15700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 15750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 15800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 15850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 15900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 15950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 16000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 16050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 16100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 16200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 16250 loss: 133.505 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 16300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 16350 loss: 107.131 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 16400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 16450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 16500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 16550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 16600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 16650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 16700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 16750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 16800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 16850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 16900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 16950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 17000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 17050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 17100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 17150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 17200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 17250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 17300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 17350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 17400 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 17450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 17500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 17550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 17600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 17650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 17700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 17750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 17800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 17850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 17900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 17950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 18000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 18050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 18100 loss: 106.258 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 18150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 18200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 18250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 18300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 18350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 18400 loss: 183.876 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 18450 loss: 110.405 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 18500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 18550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 18600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 18650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 18700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 18750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 18800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 18850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.000 \n",
      "Step 18900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 18950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 19000 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 19050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 19100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 19150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.000 \n",
      "Step 19200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 19250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 19300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 19350 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.000 \n",
      "Step 19400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 19450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 19500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 19550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 19600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 19650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 19700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 19750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 19800 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 19850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 19900 loss: 165.716 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 19950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 20000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 20050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 20100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 20150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 20200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 20250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 20300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 20350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 20400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 20450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 20500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 20550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 20600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 20650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 20700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 20750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 20800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 20850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 20900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 20950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 21000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 21050 loss: 153.965 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 21100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 21150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 21200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 21250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 21300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 21350 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 21400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 21500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 21550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 21600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 21650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 21700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 21750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 21800 loss: 72.071 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 21850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 21900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 21950 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 22000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 22050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 22100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 22150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 22200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 22250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 22300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 22350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 22400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 22450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 22500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 22550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 22600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 22650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 22700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 22750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 22800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 22850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 22900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 22950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 23000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 23050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 23100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 23150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 23200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.000 \n",
      "Step 23250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 23300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 23350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 23400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 23450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 23500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 23550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 23600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 23650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 23700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 23750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 23800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 23850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 23900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 23950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 24000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 24050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 24100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 24150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 24200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 24250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 24300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 24350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 24400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 24450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 24500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 24550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 24600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 24650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 24700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 24750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 24800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 24850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 24900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 24950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 25000 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 25050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 25100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 25150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 25200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 25250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 25300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 25350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 25400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 25450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 25500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 25550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 25600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 25650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 25700 loss: 158.900 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 25750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 25800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 25850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 25900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 25950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 26000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 26050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 26100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 26150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 26200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 26250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 26300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 26350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 26400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 26450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 26500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 26550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 26600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 26650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 26700 loss: 188.507 training accuracy: 0.300 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 26800 loss: 213.388 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 26850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 26900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 26950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 27000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 27050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 27100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 27150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 27200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 27250 loss: 165.783 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 27300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 27350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 27400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 27450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 27500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 27550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 27600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 27650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 27700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 27750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 27800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 27850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 27900 loss: 153.503 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 27950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 28000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 28050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 28100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 28150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 28200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 28250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 28300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 28350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 28400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 28450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 28500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 28550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 28600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 28650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 28700 loss: 156.878 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 28750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 28800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 28850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 28900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 28950 loss: 104.824 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 29000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 29050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 29100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 29150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 29200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 29250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 29300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 29350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 29400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 29450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 29500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 29550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 29600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 29650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 29700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 29750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 29800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 29850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 29900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 29950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 30000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 30050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 30100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 30150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 30200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 30250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 30300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 30350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 30400 loss: 156.147 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 30450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 30500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 30550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 30600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 30650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 30700 loss: 98.095 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 30750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 30800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 30850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 30900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 30950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 31000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 31050 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 31100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 31150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 31200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 31250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 31300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 31350 loss: 102.359 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 31400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 31450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 31500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 31550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 31600 loss: 108.918 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 31650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 31700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 31750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 31800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 31850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 31900 loss: 209.626 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 31950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 32000 loss: 161.530 training accuracy: 0.400 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 32050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 32100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 32150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 32200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 32250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 32300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 32350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 32400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 32450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 32500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 32550 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 32600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 32650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 32700 loss: 189.332 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 32750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 32800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 32850 loss: 185.628 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 32900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 32950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 33000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 33050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 33100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 33150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 33200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 33250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 33300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 33350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 33400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 33450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 33500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 33550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 33600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 33650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 33700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 33750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 33800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 33850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 33900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 33950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 34000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 34050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 34100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 34150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 34200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 34250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 34300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 34350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 34400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 34450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 34500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 34550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 34600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 34650 loss: 190.732 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 34700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 34750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 34800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 34850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 34900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 34950 loss: 212.972 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 35000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 35050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 35100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 35150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 35200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 35250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 35300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 35350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 35400 loss: 164.111 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 35450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 35500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 35550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 35600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 35650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 35700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 35750 loss: 109.576 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 35800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 35850 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 35900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 35950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 36000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 36050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 36100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 36150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 36200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 36250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 36300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 36350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 36400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 36450 loss: 165.681 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 36500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 36550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 36600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 36650 loss: 155.952 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 36700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 36750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 36800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 36850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 36900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 36950 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 37000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 37050 loss: 110.077 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 37100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 37150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 37200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 37250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 37300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 37350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 37400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 37450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 37500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 37550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 37600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 37650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 37700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 37750 loss: 192.761 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 37800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 37850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 37900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 37950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 38000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 38050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 38100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 38150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 38200 loss: 126.825 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 38250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 38300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 38350 loss: 165.053 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 38400 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 38450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 38500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 38550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 38600 loss: 157.752 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 38650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 38700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 38750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 38800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 38850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 38900 loss: 211.231 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 38950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 39000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 39050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 39100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 39150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 39200 loss: 138.138 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 39250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 39300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 39350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 39400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 39450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 39500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 39550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 39600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 39650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 39700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 39750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 39800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 39850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 39900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 39950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 40000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 40050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 40100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 40150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 40200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 40250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 40300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 40350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 40400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 40450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 40500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 40550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 40600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 40650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 40700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 40750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 40800 loss: 193.376 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 40850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 40900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 40950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 41000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 41050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 41100 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 41150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 41200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 41250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 41300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 41350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 41400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 41450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 41500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 41550 loss: 162.610 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 41600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 41650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 41700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 41750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 41800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 41850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 41900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 41950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 42000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 42050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 42100 loss: 160.846 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 42150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 42200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 42250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 42300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 42350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 42400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 42450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 42500 loss: 125.733 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 42550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 42600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 42650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 42700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 42750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 42800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 42850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 42900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 42950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 43000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 43050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 43100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 43150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 43200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 43250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 43300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 43350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 43400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 43450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 43500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 43550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 43600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 43650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 43700 loss: 181.511 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 43750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 43800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 43850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 43900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 43950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 44000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 44050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 44100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 44150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 44200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 44250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.500 \n",
      "Step 44300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 44350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 44400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 44450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 44500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 44550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 44600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 44650 loss: 208.675 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 44700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 44750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 44800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 44850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 44900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 44950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 45000 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 45050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 45100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 45150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 45200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 45250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 45300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 45350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 45400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 45450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 45500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 45550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 45600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 45650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 45700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 45750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 45800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 45850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 45900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 45950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 46000 loss: 191.836 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 46050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 46100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 46150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 46200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 46250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 46300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 46350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 46400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 46450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 46500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 46550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 46600 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 46650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 46700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 46750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 46800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.700 \n",
      "Step 46850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 46900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 46950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 47000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 47050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 47100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 47150 loss: 108.129 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 47200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 47250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 47300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 47350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 47400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 47450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 47500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 47550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 47600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 47650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 47700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 47750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 47800 loss: 110.224 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 47850 loss: 163.620 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 47900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 47950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 48000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 48050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 48100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 48150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 48200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 48250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 48300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 48350 loss: 137.135 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 48400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 48450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 48500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 48550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 48600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 48650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 48700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 48750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 48800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 48850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 48900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 48950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 49000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 49050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 49100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 49150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 49200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 49250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 49300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 49350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 49400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 49450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 49500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 49550 loss: 189.872 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 49600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 49650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 49700 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 49750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 49800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 49850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 49900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 49950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 50000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 50050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 50100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 50150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 50200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 50250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 50300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 50350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 50400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 50450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 50500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 50550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 50600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 50650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 50700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 50750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 50800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 50850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 50900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 50950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 51000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 51050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 51100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 51150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 51200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 51250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 51300 loss: 193.387 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 51350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 51400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 51450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 51500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 51550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 51600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 51650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 51700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 51750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 51800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 51850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 51900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 51950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 52000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 52050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 52100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 52150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 52200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 52250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 52300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 52350 loss: 82.895 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 52400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 52450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 52500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 52550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 52600 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 52650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 52700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 52750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 52800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 52850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 52900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 52950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 53000 loss: 101.343 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 53050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 53100 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 53150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 53200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 53250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 53300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 53350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 53400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 53450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 53500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 53550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 53600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 53650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 53700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 53750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 53800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 53850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 53900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 53950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 54000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 54050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 54100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 54150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 54200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 54250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 54300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 54350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 54400 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 54450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 54500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 54550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 54600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 54650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 54700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 54750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 54800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 54850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 54900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 54950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 55000 loss: 82.082 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 55050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 55100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 55150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 55200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 55250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 55300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 55350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 55400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 55450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 55500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 55550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 55600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 55650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 55700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 55750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 55800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 55850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 55900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 55950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 56000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 56050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 56100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 56150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 56200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 56250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 56300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 56350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 56400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 56450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 56500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 56550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 56600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 56650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 56700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 56750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 56800 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 56850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 56900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 56950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 57000 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 57050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 57100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 57150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 57200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 57250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 57300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 57350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 57400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 57450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 57500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 57550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 57600 loss: 126.408 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 57650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 57700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 57750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 57800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 57850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 57900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 57950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 58000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 58050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 58100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 58150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 58200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 58250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 58300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 58350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 58400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 58450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 58500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 58550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 58600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 58650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 58700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 58750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 58800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 58850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 58900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 58950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 59000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 59050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 59100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 59150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 59200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 59250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 59300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 59350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 59400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 59450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 59500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 59550 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 59600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 59650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 59700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.000 \n",
      "Step 59750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 59800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 59850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 59900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 59950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 60000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 60050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 60100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 60150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 60200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 60250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 60300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 60350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 60400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 60450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 60500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 60550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 60600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 60650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 60700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 60750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 60800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 60850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 60900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 60950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 61000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 61050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 61100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 61150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 61200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 61250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 61300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 61350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 61400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 61450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 61500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 61550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 61600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 61650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 61700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 61750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 61800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 61850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 61900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 61950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 62000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 62050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 62100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 62150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 62200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 62250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 62300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 62350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 62400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 62450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 62500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 62550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 62600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 62650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 62700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 62750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 62800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 62850 loss: 181.025 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 62900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 62950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 63000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 63050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 63100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 63150 loss: 138.123 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 63200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 63250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 63300 loss: 220.529 training accuracy: 0.200 validation accuracy: 0.700 \n",
      "Step 63350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 63400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 63450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 63500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 63550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 63600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 63650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 63700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 63750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 63800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 63850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 63900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 63950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 64000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 64050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 64100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 64150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 64200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 64250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 64300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 64350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 64400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 64450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 64500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 64550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 64600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 64650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 64700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 64750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 64800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 64850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 64900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 64950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 65000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 65050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 65100 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 65150 loss: 168.883 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 65200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 65250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 65300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 65350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 65400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 65450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 65500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 65550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 65600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 65650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 65700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 65750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 65800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 65850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 65900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 65950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 66000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 66050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 66100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 66150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 66200 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 66250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 66300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 66350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 66400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 66450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 66500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 66550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 66600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 66650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 66700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 66750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 66800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 66850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 66900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 66950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 67000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 67050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 67100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 67150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 67200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 67250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 67300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 67350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 67400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 67450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 67500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 67550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 67600 loss: 128.252 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 67650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 67700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 67750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 67800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 67850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 67900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 67950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 68000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 68050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 68100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 68150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 68200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 68250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 68300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 68350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 68400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 68450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 68500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 68550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 68600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 68650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 68700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 68750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 68800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 68850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 68900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 68950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 69000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 69050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 69100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 69150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 69200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 69250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 69300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 69350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 69400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 69450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 69500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 69550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 69600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 69650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 69700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 69750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 69800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 69850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 69900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 69950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 70000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 70050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 70100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 70150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 70200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 70250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 70300 loss: 98.247 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 70350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 70400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 70450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 70500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 70550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 70600 loss: 43.218 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 70650 loss: 136.938 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 70700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 70750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 70800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 70850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 70900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 70950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 71000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 71050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 71100 loss: 188.698 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 71150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 71200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 71250 loss: 105.109 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 71300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 71350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 71400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 71450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 71500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 71550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 71600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 71650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 71700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 71750 loss: 220.728 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 71800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 71850 loss: 110.522 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 71900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 71950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 72000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 72050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 72100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 72150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 72200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 72250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 72300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 72350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 72400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 72450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 72500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 72550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 72600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 72650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 72700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 72750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 72800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 72850 loss: 127.938 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 72900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 72950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 73000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 73050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 73100 loss: 164.174 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 73150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 73200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 73250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 73300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 73350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 73400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 73450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 73500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 73550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 73600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 73650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 73700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 73750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 73800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 73850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 73900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 73950 loss: 220.956 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 74000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 74050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 74100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 74150 loss: 193.322 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 74200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 74250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 74300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 74350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 74400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 74450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 74500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 74550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 74600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 74650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 74700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 74750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 74800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 74850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 74900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 74950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 75000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 75050 loss: 161.750 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 75100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 75150 loss: 248.468 training accuracy: 0.100 validation accuracy: 0.700 \n",
      "Step 75200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 75250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 75300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 75350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 75400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 75450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 75500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 75550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 75600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 75650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 75700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 75750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 75800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 75850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 75900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 75950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 76000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 76050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 76100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 76150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 76200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 76250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 76300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 76350 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 76400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 76450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 76500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 76550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 76600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 76650 loss: 163.459 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 76700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 76750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 76800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 76850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 76900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 76950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 77000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 77050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 77100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 77150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 77200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 77250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 77300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 77350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 77400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 77450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 77500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 77550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 77600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 77650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 77700 loss: 82.884 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 77750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 77800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 77850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 77900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 77950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 78000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 78050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 78100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 78150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 78200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 78250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 78300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 78350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 78400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 78450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 78500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 78550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 78600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 78650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 78700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 78750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 78800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 78850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 78900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 78950 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 79000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 79050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 79100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 79150 loss: 125.774 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 79200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 79250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 79300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 79350 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 79400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 79450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 79500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 79550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 79600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 79650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 79700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 79750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 79800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 79850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 79900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 79950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 80000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 80050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 80100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 80150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 80200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 80250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 80300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 80350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 80400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 80450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 80500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 80550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 80600 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 80650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 80700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.600 \n",
      "Step 80750 loss: 125.728 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 80800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 80850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 80900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 80950 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 81000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 81050 loss: 100.914 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 81100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 81150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 81200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 81250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 81300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 81350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 81400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 81450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 81500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 81550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 81600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 81650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 81700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 81750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 81800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 81850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 81900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 81950 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 82000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 82050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 82100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 82150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 82200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 82250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 82300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 82350 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 82400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 82450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 82500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 82550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 82600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 82650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 82700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 82750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 82800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 82850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 82900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 82950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 83000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 83050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 83100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 83150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 83200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 83250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 83300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 83350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 83400 loss: 135.231 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 83450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 83500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 83550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 83600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 83650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 83700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 83750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 83800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 83850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 83900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 83950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 84000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 84050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 84100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 84150 loss: 98.600 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 84200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 84250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 84300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 84350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 84400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 84450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 84500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 84550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 84600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 84650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 84700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 84750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 84800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 84850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 84900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 84950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 85000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 85100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 85150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 85200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 85250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 85300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 85350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 85400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 85450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 85500 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.600 \n",
      "Step 85550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 85600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 85650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 85700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 85750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 85800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 85850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 85900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 85950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 86000 loss: 158.126 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 86050 loss: 165.626 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 86100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.800 \n",
      "Step 86150 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 86200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 86250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 86300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 86350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 86400 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 86450 loss: 70.765 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 86500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 86550 loss: 135.046 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 86600 loss: 193.082 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 86650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 86700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 86750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 86800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 86850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 86900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 86950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 87000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 87050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 87100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 87150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 87200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 87250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 87300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 87350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 87400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 87450 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 87500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 87550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 87600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 87650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 87700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 87750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 87800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 87850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 87900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 87950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 88000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 88050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 88100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 88150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 88200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 88250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 88300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 88350 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 88400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 88450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 88500 loss: 53.929 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 88550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 88600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 88650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 88700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 88750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 88800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 88850 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 88900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 88950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 89000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 89050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 89100 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 89150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 89200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 89250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 89300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 89350 loss: 99.108 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 89400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 89450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 89500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 89550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 89600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 89650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 89700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 89750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 89800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 89850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 89900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 89950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 90000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 90050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 90100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 90150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 90200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 90250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 90300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 90350 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 90400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 90450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 90500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 90550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 90600 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 90650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 90700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 90750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 90800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 90850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 90900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 90950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 91000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 91050 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 91100 loss: 165.761 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 91150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 91200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 91250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 91300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 91350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 91400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 91450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 91500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 91550 loss: 136.447 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 91600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 91650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 91700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 91750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 91800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 91850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 91900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 91950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 92000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 92050 loss: 161.158 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 92100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 92150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 92200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 92250 loss: 55.122 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 92300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 92350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 92400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 92450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 92500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 92550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 92600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 92650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 92700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 92750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 92800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 92850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 92900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 92950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 93000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 93050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 93100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 93150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 93200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 93250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 93300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 93350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 93400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 93450 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.100 \n",
      "Step 93500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 93550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 93600 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.200 \n",
      "Step 93650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 93700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 93750 loss: 153.372 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 93800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 93850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 93900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 93950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 94000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 94050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 94100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 94150 loss: 182.250 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 94200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 94250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 94300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 94350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 94400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 94450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 94500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 94550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 94600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 94650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 94700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 94750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 94800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 94850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 94900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 94950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 95000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 95050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 95100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 95150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 95200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 95250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 95300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 95350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 95400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 95450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 95500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 95550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 95600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 95650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 95700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 95750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 95800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 95850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 95900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 95950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 96000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 96050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 96100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 96150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 96200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 96250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 96300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 96350 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 96400 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.200 \n",
      "Step 96450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 96500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 96550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 96600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 96650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 96700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 96750 loss: 100.648 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 96800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 96850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 96900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 96950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 97000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 97050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 97100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 97150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 97200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 97250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 97300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 97350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 97400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 97450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 97500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 97550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 97600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 97650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 97700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 97750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 97800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 97850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 97900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 97950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 98000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 98050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 98100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 98150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 98200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 98250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 98300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 98350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 98400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 98450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 98500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 98550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 98600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 98650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 98700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 98750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 98800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 98850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 98900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.000 \n",
      "Step 98950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 99000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 99050 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 99100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 99150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 99200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 99250 loss: 151.579 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 99300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 99350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 99400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 99450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 99500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 99550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 99600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 99650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 99700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 99750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 99800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 99850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 99900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 99950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 100000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 100050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 100100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 100150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 100200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 100250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 100300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 100350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 100400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 100450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 100500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 100550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 100600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 100650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 100700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 100750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 100800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 100850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 100900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 101000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 101050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 101100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 101150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 101200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 101250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 101300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 101350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 101400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 101450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 101500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 101550 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 101600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 101650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 101700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 101750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 101800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 101850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 101900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 101950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 102000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 102050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 102100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 102150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.700 \n",
      "Step 102200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 102250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 102300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 102350 loss: 55.260 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 102400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 102450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 102500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 102550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 102600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 102650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 102700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 102750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 102800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 102850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 102900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 102950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 103000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 103050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 103100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 103150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 103200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.000 \n",
      "Step 103250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 103300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 103350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 103400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 103450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 103500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 103550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 103600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 103650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 103700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 103750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 103800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 103850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 103900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 103950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 104000 loss: 193.384 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 104050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 104100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 104150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 104200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 104250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 104300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 104350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 104400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 104450 loss: 165.718 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 104500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 104550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 104600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 104650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 104700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 104750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 104800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 104850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 104900 loss: -0.000 training accuracy: 1.000 validation accuracy: 0.500 \n",
      "Step 104950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 105000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 105050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 105100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 105150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 105200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 105250 loss: 155.211 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 105300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 105350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 105400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 105450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 105500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 105550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 105600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 105650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 105700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 105750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 105800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 105850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 105900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 105950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 106000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 106050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 106100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 106150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 106200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 106250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 106300 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 106350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 106400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 106450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 106500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 106550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 106600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 106650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 106700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 106750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 106800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 106850 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 106900 loss: 137.735 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 106950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 107000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 107050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 107100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 107150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 107200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 107250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 107300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 107350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 107400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 107450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 107500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 107550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 107600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 107650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 107700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 107750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 107800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 107850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 107900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 107950 loss: 191.831 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 108000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 108050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 108100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 108150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 108200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 108250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 108300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 108350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 108400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 108450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 108500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 108550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 108600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 108650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 108700 loss: 99.325 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 108750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 108800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.800 \n",
      "Step 108850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 108900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 108950 loss: 110.503 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 109000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 109050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 109100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 109150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 109200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 109250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 109300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 109350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 109400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 109450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 109500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 109550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 109600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 109650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.700 \n",
      "Step 109700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 109750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 109800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 109850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 109900 loss: 138.119 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 109950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 110000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 110050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 110100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 110150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 110200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 110250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 110300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 110350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 110400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 110450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 110500 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 110550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 110600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 110650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 110700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 110750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 110800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 110850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 110900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 110950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 111000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 111050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 111100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 111150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 111200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 111250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 111300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 111350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 111400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 111450 loss: 138.153 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 111500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 111550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 111600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 111650 loss: 129.231 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 111700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 111750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 111800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 111850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 111900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 111950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 112000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 112050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 112100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 112150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 112200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 112250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 112300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 112350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 112400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 112450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 112500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 112550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 112600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 112650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 112700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 112750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 112800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 112850 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 112900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 112950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 113000 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 113050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 113100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 113150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 113200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 113250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 113300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 113350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 113400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 113450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 113500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 113550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 113600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 113650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 113700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 113750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 113800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 113850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 113900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 113950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 114000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 114050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 114100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 114150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 114200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 114250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 114300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 114350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 114400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 114450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 114500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 114550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 114600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 114650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 114700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 114750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 114800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 114850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 114900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 114950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 115000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 115050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 115100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 115150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 115200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 115250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 115300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.800 \n",
      "Step 115350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 115400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 115450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 115500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 115550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 115600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 115650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 115700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 115750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 115800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 115850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 115900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 115950 loss: 193.070 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 116000 loss: 82.487 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 116050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 116100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 116150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 116200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 116250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 116300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 116350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 116400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 116450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 116500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 116550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 116600 loss: 138.117 training accuracy: 0.500 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 116650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 116700 loss: 138.034 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 116750 loss: 165.738 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 116800 loss: 133.787 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 116850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 116900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 116950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 117000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 117050 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 117100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 117150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 117200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 117250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 117300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 117350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 117400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 117450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 117500 loss: 186.461 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 117550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 117600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 117650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 117700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 117750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 117800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 117850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 117900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 117950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 118000 loss: 193.029 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 118050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 118100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 118150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 118200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 118250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 118300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 118350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 118400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 118450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 118500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 118550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 118600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 118650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 118700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 118750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 118800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 118850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 118900 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 118950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 119000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 119050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 119100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 119150 loss: 161.906 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 119200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 119250 loss: 138.153 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 119300 loss: 138.150 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 119350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 119400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 119450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 119500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 119550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 119600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 119650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 119700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 119750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 119800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 119850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 119900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 119950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 120000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 120050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 120100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 120150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 120200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 120250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 120300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 120350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.900 \n",
      "Step 120400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 120450 loss: 136.558 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 120500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 120550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 120600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 120650 loss: 110.523 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 120700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 120750 loss: 98.713 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 120800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 120850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 120900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 120950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 121000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 121050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 121100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 121150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 121200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 121250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 121300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 121350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 121400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 121450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 121500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 121550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 121600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 121650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 121700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 121750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 121800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 121850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 121900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 121950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 122000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 122050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 122100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 122150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 122200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 122250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 122300 loss: -0.000 training accuracy: 1.000 validation accuracy: 0.200 \n",
      "Step 122350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 122400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 122450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 122500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 122550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 122600 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 122650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 122700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.800 \n",
      "Step 122750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 122800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 122850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 122900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 122950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 123000 loss: 190.590 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 123050 loss: 193.375 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 123100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 123150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 123200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 123250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 123300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 123350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 123400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 123450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 123500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 123550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 123600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 123650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 123700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 123750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 123800 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 123850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 123900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 123950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 124000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 124050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 124100 loss: 209.479 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 124150 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 124200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 124250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 124300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 124350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 124400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 124450 loss: 129.290 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 124500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 124550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 124600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 124650 loss: 106.431 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 124700 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 124750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 124800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 124850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 124900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 124950 loss: 214.477 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 125000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 125050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 125100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 125150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 125200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 125250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 125300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 125350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 125400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 125450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 125500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 125550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 125600 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 125650 loss: 136.968 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 125700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 125750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 125800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 125850 loss: 131.021 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 125900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 125950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 126000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 126050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 126100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 126150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 126200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 126250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 126300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 126350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 126400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 126450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 126500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 126550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 126600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 126650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 126700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 126750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 126800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 126850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 126900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 126950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 127000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 127050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 127100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 127150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 127200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 127250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.100 \n",
      "Step 127300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 127350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 127400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 127450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 127500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 127550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 127600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 127650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 127700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 127750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 127800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 127850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 127900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 127950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 128000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 128050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 128100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 128150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 128200 loss: 98.148 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 128250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 128300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 128350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 128400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 128450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 128500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 128550 loss: 107.648 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 128600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 128650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 128700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 128750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 128800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 128850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 128900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 128950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 129000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 129050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 129100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 129150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 129200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 129250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 129300 loss: 110.228 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 129350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 129400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 129450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 129500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 129550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 129600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 129650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 129700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 129750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 129800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 129850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 129900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 129950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 130000 loss: 138.133 training accuracy: 0.500 validation accuracy: 0.900 \n",
      "Step 130050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 130100 loss: 155.635 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 130150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 130200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 130250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 130300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 130350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 130400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 130450 loss: 135.883 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 130500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 130550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 130600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 130650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 130700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 130750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 130800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 130850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 130900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 130950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 131000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 131050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 131100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 131150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 131200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 131250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 131300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 131350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 131400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 131450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 131500 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 131550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 131600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 131650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 131700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 131750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 131800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 131850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 131900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 131950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 132000 loss: 210.269 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 132050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 132100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 132150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 132200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 132250 loss: 193.410 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 132300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 132350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 132400 loss: 106.972 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 132450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 132500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 132550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 132600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 132650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 132700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 132750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 132800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 132850 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 132900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 132950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 133000 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 133050 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 133100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 133150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 133200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 133250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 133300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 133350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 133400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 133450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 133500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 133550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 133600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 133650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 133700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 133750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 133800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 133850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 133900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 133950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 134000 loss: 55.261 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 134050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 134100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 134150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 134200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 134250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 134300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 134350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 134400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 134450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 134500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 134550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 134600 loss: 193.245 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 134650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 134700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 134750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 134800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 134850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 134900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 134950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 135000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 135050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 135100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 135150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 135200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 135250 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 135300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 135350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 135400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 135450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 135500 loss: 72.481 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 135550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 135600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 135650 loss: 87.916 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 135700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 135750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 135800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 135850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 135900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 135950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 136000 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 136050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 136100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 136150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 136200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 136250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 136300 loss: 101.609 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 136350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 136400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.000 \n",
      "Step 136450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 136500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 136550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 136600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 136650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 136700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 136750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 136800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 136850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 136900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 136950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 137000 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.600 \n",
      "Step 137050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 137100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 137150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 137200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 137250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 137300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 137350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 137400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 137450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 137500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 137550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 137600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 137650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 137700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 137750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 137800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 137850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 137900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 137950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 138000 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 138050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 138100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 138150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 138200 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 138250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 138300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 138350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 138400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 138450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 138500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 138550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 138600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 138650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 138700 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 138750 loss: 71.450 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 138800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 138850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 138900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 138950 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.800 \n",
      "Step 139000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 139050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 139100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 139150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 139200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 139250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 139300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 139350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 139400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 139450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 139500 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 139550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 139600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 139650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 139700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 139750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 139800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 139850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 139900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 139950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 140000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 140050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 140100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 140150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 140200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 140250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 140300 loss: 138.150 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 140350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 140400 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.200 \n",
      "Step 140450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 140500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 140550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 140600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 140650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 140700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 140750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 140800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 140850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 140900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 140950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 141000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 141050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 141100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 141150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 141200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 141250 loss: 82.914 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 141300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 141350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 141400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 141450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 141500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 141550 loss: 82.929 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 141600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 141650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 141700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 141750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 141800 loss: 107.675 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 141850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 141900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 141950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 142000 loss: 102.189 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 142050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 142100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 142150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 142200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 142250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 142300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 142350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 142400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 142450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 142500 loss: 82.891 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 142550 loss: 110.501 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 142600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 142650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 142700 loss: 138.151 training accuracy: 0.500 validation accuracy: 0.400 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 142750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 142800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 142850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 142900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 142950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 143000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 143050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 143100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 143150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 143200 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 143250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 143300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 143350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 143400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 143450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 143500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 143550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 143600 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 143650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 143700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 143750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 143800 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.600 \n",
      "Step 143850 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 143900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 143950 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 144000 loss: 82.891 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 144050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 144100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 144150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 144200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 144250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 144300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 144350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 144400 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 144450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 144500 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 144550 loss: 82.882 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 144600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 144650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 144700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 144750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 144800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 144850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 144900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 144950 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 145000 loss: 126.353 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 145050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 145100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 145150 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 145200 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.500 \n",
      "Step 145250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 145300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 145350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 145400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 145450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 145500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 145550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 145600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 145650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 145700 loss: 55.226 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 145750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 145800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 145850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 145900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 145950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 146000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 146050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 146100 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 146150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 146200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 146250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 146300 loss: 193.342 training accuracy: 0.300 validation accuracy: 0.800 \n",
      "Step 146350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 146400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 146450 loss: 137.368 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 146500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 146550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 146600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 146650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 146700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 146750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 146800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 146850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 146900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 146950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 147000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 147050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 147100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 147150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 147200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 147250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 147300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 147350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 147400 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 147450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 147500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 147550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 147600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 147650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 147700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 147750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 147800 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.800 \n",
      "Step 147850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 147900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 147950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 148000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 148050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 148100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 148150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 148200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 148250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 148300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 148350 loss: -0.000 training accuracy: 1.000 validation accuracy: 0.300 \n",
      "Step 148400 loss: 78.333 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 148450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 148500 loss: 165.783 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 148550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 148600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 148650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 148700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 148750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 148800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 148850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 148900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 148950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 149000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 149050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 149100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 149150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.800 \n",
      "Step 149200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 149250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 149300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 149350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 149400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 149450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.100 \n",
      "Step 149500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 149550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 149600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 149650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 149700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 149750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 149800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 149850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 149900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 149950 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 150000 loss: 110.512 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 150050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 150100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 150150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 150200 loss: 212.677 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 150250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 150300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 150350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 150400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 150450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 150500 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 150550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 150600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 150650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 150700 loss: 137.800 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 150750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 150800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 150850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 150900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 150950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 151000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 151050 loss: 88.503 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 151100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 151150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 151200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 151250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 151300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 151350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 151400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 151450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 151500 loss: 121.472 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 151550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 151600 loss: 77.207 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 151650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 151700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 151750 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 151800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 151850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 151900 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.200 \n",
      "Step 151950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 152000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 152050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 152100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 152150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 152200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 152250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 152300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 152350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 152400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 152450 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 152500 loss: 165.509 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 152550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 152600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 152650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 152700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 152750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 152800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 152850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 152900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 152950 loss: 73.429 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 153000 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 153050 loss: 193.336 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 153100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 153150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 153200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 153250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 153300 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 153350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 153400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 153450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 153500 loss: 241.756 training accuracy: 0.100 validation accuracy: 0.600 \n",
      "Step 153550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 153600 loss: 159.058 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 153650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 153700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 153750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 153800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 153850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 153900 loss: 135.788 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 153950 loss: 220.538 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 154000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 154050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 154100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 154150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 154200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.800 \n",
      "Step 154250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 154300 loss: 104.021 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 154350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 154400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 154450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 154500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 154550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 154600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 154650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 154700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 154750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 154800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 154850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.800 \n",
      "Step 154900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 154950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 155000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 155050 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 155100 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 155150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 155200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 155250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 155300 loss: 138.118 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 155350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 155400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 155450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 155500 loss: 82.888 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 155550 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 155600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 155650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 155700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.900 \n",
      "Step 155750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 155800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 155850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 155900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 155950 loss: 101.744 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 156000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 156050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 156100 loss: 137.597 training accuracy: 0.500 validation accuracy: 0.800 \n",
      "Step 156150 loss: 161.260 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 156200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 156250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 156300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 156350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 156400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 156450 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 156500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 156550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 156600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 156650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 156700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.400 \n",
      "Step 156750 loss: 192.813 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 156800 loss: 137.586 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 156850 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 156900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 156950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 157000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 157050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 157100 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 157150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 157200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 157250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 157300 loss: 133.506 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 157350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 157400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 157450 loss: 104.286 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 157500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 157550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 157600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 157650 loss: 220.900 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 157700 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 157750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 157800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 157850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 157900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 157950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 158000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 158050 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 158100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 158150 loss: 187.560 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 158200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 158250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 158300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 158350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 158400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 158450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 158500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 158550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 158600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 158650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 158700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 158750 loss: 132.620 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 158800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 158850 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 158900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 158950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 159000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 159050 loss: 193.402 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 159100 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.200 \n",
      "Step 159150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 159200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 159250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 159300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 159350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 159400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 159450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 159500 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.200 \n",
      "Step 159550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 159600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 159650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 159700 loss: 136.465 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 159750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 159800 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.800 \n",
      "Step 159850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 159900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 159950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 160000 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 160050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 160100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 160150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 160200 loss: 165.785 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 160250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 160300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 160350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 160400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 160450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 160500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 160550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 160600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 160650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 160700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 160750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 160800 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 160850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 160900 loss: -0.000 training accuracy: 1.000 validation accuracy: 0.600 \n",
      "Step 160950 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.100 \n",
      "Step 161000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 161050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 161100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 161150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 161200 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 161250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.700 \n",
      "Step 161300 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 161350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 161400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 161450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 161500 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 161550 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.800 \n",
      "Step 161600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 161650 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 161700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 161750 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 161800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 161850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 161900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 161950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 162000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 162050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 162100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 162150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 162200 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 162250 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 162300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 162350 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 162400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 162450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 162500 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 162550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 162600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 162650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 162700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 162750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 162800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 162850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 162900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 162950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 163000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 163050 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.700 \n",
      "Step 163100 loss: 135.254 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 163150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 163200 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.600 \n",
      "Step 163250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 163300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 163350 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 163400 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 163450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.300 \n",
      "Step 163500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 163550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 163600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 163650 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 163700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 163750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 163800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 163850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 163900 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 163950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 164000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 164050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.100 \n",
      "Step 164100 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 164150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 164200 loss: 138.154 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 164250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 164300 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 164350 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.200 \n",
      "Step 164400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 164450 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n",
      "Step 164500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 164550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 164600 loss: 106.800 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 164650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 164700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 164750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 164800 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 164850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 164900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 164950 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.400 \n",
      "Step 165000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 165050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 165100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 165150 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 165200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 165250 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 165300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 165350 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 165400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 165450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 165500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 165550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 165600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 165650 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 165700 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 165750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 165800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 165850 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 165900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 165950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 166000 loss: 182.800 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 166050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 166100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 166150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 166200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 166250 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.200 \n",
      "Step 166300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 166350 loss: 161.339 training accuracy: 0.400 validation accuracy: 0.200 \n",
      "Step 166400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 166450 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 166500 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 166550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 166600 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 166650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 166700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 166750 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 166800 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 166850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.800 \n",
      "Step 166900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 166950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 167000 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 167050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 167100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 167150 loss: 165.761 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 167200 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 167250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 167300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 167350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 167400 loss: 188.765 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 167450 loss: 45.269 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 167500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 167550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 167600 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 167650 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.300 \n",
      "Step 167700 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.700 \n",
      "Step 167750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.400 \n",
      "Step 167800 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 167850 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 167900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 167950 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 168000 loss: 162.413 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 168050 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 168100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 168150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 168200 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 168250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.400 \n",
      "Step 168300 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 168350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 168400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 168450 loss: 100.540 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 168500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 168550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 168600 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 168650 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 168700 loss: 99.452 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 168750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 168800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 168850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.500 \n",
      "Step 168900 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 168950 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.500 \n",
      "Step 169000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 169050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 169100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 169150 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.600 \n",
      "Step 169200 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 169250 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 169300 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 169350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.300 \n",
      "Step 169400 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 169450 loss: 153.367 training accuracy: 0.400 validation accuracy: 0.500 \n",
      "Step 169500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 169550 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 169600 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 169650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.600 \n",
      "Step 169700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 169750 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 169800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 169850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 169900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.700 \n",
      "Step 169950 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.600 \n",
      "Step 170000 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 170050 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 170100 loss: 110.472 training accuracy: 0.600 validation accuracy: 0.200 \n",
      "Step 170150 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 170200 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 170250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 170300 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 170350 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 170400 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 170450 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 170500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.500 \n",
      "Step 170550 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 170600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 170650 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n",
      "Step 170700 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 170750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 170800 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 170850 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 170900 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.600 \n",
      "Step 170950 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 171000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.200 \n",
      "Step 171050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 171100 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 171150 loss: 81.138 training accuracy: 0.700 validation accuracy: 0.700 \n",
      "Step 171200 loss: 27.631 training accuracy: 0.900 validation accuracy: 0.200 \n",
      "Step 171250 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.500 \n",
      "Step 171300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.300 \n",
      "Step 171350 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.500 \n",
      "Step 171400 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.500 \n",
      "Step 171450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.600 \n",
      "Step 171500 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 171550 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 171600 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.600 \n",
      "Step 171650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.400 \n",
      "Step 171700 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 171750 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.300 \n",
      "Step 171800 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 171850 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 171900 loss: 110.524 training accuracy: 0.600 validation accuracy: 0.700 \n",
      "Step 171950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.300 \n",
      "Step 172000 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.500 \n",
      "Step 172050 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.400 \n",
      "Step 172100 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.300 \n",
      "Step 172150 loss: 165.786 training accuracy: 0.400 validation accuracy: 0.400 \n",
      "Step 172200 loss: 106.916 training accuracy: 0.600 validation accuracy: 0.400 \n",
      "Step 172250 loss: 55.262 training accuracy: 0.800 validation accuracy: 0.300 \n",
      "Step 172300 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.600 \n",
      "Step 172350 loss: 138.155 training accuracy: 0.500 validation accuracy: 0.400 \n",
      "Step 172400 loss: 82.893 training accuracy: 0.700 validation accuracy: 0.200 \n"
     ]
    }
   ],
   "source": [
    "# let's set some hyperparameters\n",
    "batch_size = 10\n",
    "learning_rate = 0.00001\n",
    "n_epochs = 100\n",
    "print_every = 50\n",
    "num_hidden = 100\n",
    "\n",
    "# build the neural network\n",
    "layer_1 = layer(input_size, num_hidden, activation=nn.ReLU())\n",
    "# ========\n",
    "# Create an additional hidden layer\n",
    "layer_2 = layer(num_hidden, num_hidden, activation=nn.ReLU())\n",
    "# ========\n",
    "layer_3 = layer(num_hidden, num_classes, activation=nn.Softmax(dim=-1))\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.SGD(\n",
    "    # ========\n",
    "    # Add all of the network weights for the three layers\n",
    "    [layer_1.weight, layer_1.bias,\n",
    "     layer_2.weight, layer_2.bias,\n",
    "     layer_3.weight, layer_3.bias],\n",
    "    # ========\n",
    "    lr=learning_rate)\n",
    "\n",
    "# train the network\n",
    "step = 0\n",
    "results = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "}\n",
    "for epoch in range(n_epochs):\n",
    "    # randomize the order in which we see the data in each epoch\n",
    "    random_order_indices = np.random.choice(train_tensor.shape[0], train_tensor.shape[0], replace=False)\n",
    "    \n",
    "    # iterate through the data in batches of size `batch_size`\n",
    "    for batch_indices in np.array_split(random_order_indices, random_order_indices.shape[0] // batch_size):\n",
    "      \n",
    "        train_data_batch = train_tensor[batch_indices]\n",
    "        train_labels_batch = train_labels[batch_indices]\n",
    "        train_onehot = to_one_hot(train_labels_batch, num_classes)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # get pass batch through layers\n",
    "        hidden_layer1 = layer_1(train_data_batch)\n",
    "        # ========\n",
    "        # Apply your additional hidden layer\n",
    "        hidden_layer2 = layer_2(hidden_layer1)\n",
    "        # ========\n",
    "        output = layer_3(hidden_layer2)\n",
    "        \n",
    "        # compute cross entropy\n",
    "        loss = train_onehot * torch.log(output+ 1e-6) + (1 - train_onehot) * torch.log(1 - output + 1e-6)\n",
    "        loss = -1 * loss.sum()\n",
    "\n",
    "        # backpropagate the loss\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # evaluate accuracy on both the training and validation datasets\n",
    "        if step % print_every == 0:\n",
    "            \n",
    "            # don't track gradients\n",
    "            with torch.no_grad():\n",
    "                # compute the predicted outputs\n",
    "                train_prediction = output.argmax(1).numpy()\n",
    "\n",
    "                # compute the accuracy over the batch\n",
    "                acc_training = np.mean(train_prediction == train_labels_batch.numpy())\n",
    "\n",
    "                # compute the loss on all the validation data\n",
    "                loss_np = []\n",
    "                output_np = []\n",
    "                labels_np = []\n",
    "\n",
    "                random_order_indices = np.random.choice(valid_tensor.shape[0], valid_tensor.shape[0], replace=False)\n",
    "\n",
    "                for batch_indices in np.array_split(random_order_indices, random_order_indices.shape[0] // batch_size):\n",
    "                    valid_data_batch = valid_tensor[batch_indices]\n",
    "                    valid_labels_batch = valid_labels[batch_indices]\n",
    "\n",
    "                    # pass through layers\n",
    "                    valid_hidden1 = layer_1(valid_data_batch)\n",
    "                    # ========\n",
    "                    # Apply your additional hidden layer\n",
    "                    valid_hidden2 = layer_2(valid_hidden1)\n",
    "                    # ========\n",
    "                    valid_output = layer_3(valid_hidden2)\n",
    "\n",
    "                    # compute the predicted outputs\n",
    "\n",
    "                    prediction_np = valid_output.argmax(1).numpy()\n",
    "\n",
    "                    output_np = np.concatenate(prediction_np.reshape(-1,1), axis=0)\n",
    "                    labels_np = np.concatenate(valid_labels_batch.numpy().reshape(-1,1), axis=0)\n",
    "\n",
    "\n",
    "                # compute the accuracy over the whole dataset\n",
    "                acc_validation = np.mean(output_np == labels_np)\n",
    "\n",
    "                results['train_loss'].append(loss.item())\n",
    "                results['train_acc'].append(acc_training)\n",
    "                results['val_acc'].append(acc_validation)\n",
    "                print('Step {} loss: {:.3f} training accuracy: {:.3f} validation accuracy: {:.3f} '.format(\n",
    "                    step, loss.item(), acc_training, acc_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFJ5vLUi_rCY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f405e1a5f10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['train_loss'])\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Training loss')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['train_acc'], label='Training accuracy')\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['val_acc'], label='Validation accuracy')\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-akBJwCGVgJ"
   },
   "source": [
    "## Exercise 5 - more network depth\n",
    "\n",
    "Create a network with *five* hidden layers and compare its performance to the network with one hidden layer we just built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bUMW2qppGV98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-dfdd7b4cad66>:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.activation(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 1150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 1250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 1500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1550 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 1600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 1750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 1800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 2050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 2250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 2350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 2450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 2700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 2850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 2900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 3400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 3600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 3650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 3800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4000 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 4050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 4500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 4650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 4800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 4900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 5000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 5200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 5250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 5350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 5600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 5900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 5950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6000 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 6050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 6150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 6250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 6450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 6500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 6550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 7300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 8200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 9000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 9150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 9650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 9750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 9850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 9900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 10000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 10350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 10550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 10600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 11000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 11250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 11700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 11750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 11800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 12050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 12300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 12400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 12450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 12500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 12600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 12750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 12800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 12900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 13450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 13650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 13850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 13950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 14000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 14050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14100 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 14150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 14350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 14500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 14550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 14600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 14650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 14750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 14800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 14850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 14900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 14950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 15100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 15150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 15200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 15350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 15400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 15450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 15750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 15800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 15850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 15950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 16000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 16250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 16300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 16350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 16450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 16550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 16800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 16950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 17050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 17100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 17200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 17300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 17350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 17500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 17650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 17750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 17800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 17850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 18350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 18500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 18600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 18800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 19000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 19050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 19200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 19300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 19350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 19550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 19700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 19800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 19850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 20000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 20150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 20300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 20550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 20650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 20800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 20950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 21100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 21150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 21250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 21300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 21400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 21450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 21950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 22000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 22200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 22250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 22300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 22350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 22550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 22700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 22800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 22850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 22900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 22950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 23000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23100 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 23150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 23200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 23250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 23350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 23450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 23500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 23550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 23650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 23700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 23850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 23900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 23950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 24000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 24200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 24300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 24350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 24450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 24500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 24700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 24750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 24800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 24900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 25000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 25050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 25100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 25200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 25250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 25300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 25350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 25400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25450 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 25500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 25550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 25600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 25650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 25800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 25850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 25900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 26050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 26100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 26450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 26600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 26650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 26750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 26800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 26950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 27000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 27050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 27200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 27250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 27350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 27400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 27600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 27750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 27900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 27950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 28000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 28150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 28450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 28600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 28900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 29150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 29200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 29400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 29550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 29750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 29900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 30150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 30250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 30300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30550 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 30600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 30650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 30700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 30800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 30850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 30900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 30950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 31100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 31150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 31250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 31300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 31350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 31400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 31950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 32200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 32250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 32300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 32400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 32450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 32550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 32650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 32700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 32750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 32900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 33050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 33200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 33300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 33400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 33500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 33550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 33750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 33800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 33850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 33900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 33950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 34100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 34250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 34400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 34500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 34650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 34850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 35050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 35100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 35150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 35200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 35250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 35350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 35450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 35500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 35750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 35800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 35900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 35950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 36000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 36050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 36150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 36250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 36300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 36350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 36650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 36700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 36750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 36800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 36850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 37050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 37100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 37150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 37200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 37350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 37500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 37650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 37750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 37850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 37950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 38050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 38150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 38250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 38350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 38450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 38500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 38550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 38600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 38650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 38700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 39000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 39150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 39200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 39400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 39450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 39500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 39600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 39800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 39900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 39950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 40150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 40200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 40250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 40400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 40650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 40800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 40850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 40900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 40950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 41000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 41100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 41150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 41200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 41300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 41500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 41900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 41950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 42000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 42150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 42200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 42250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 42300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 42400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 42450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 42600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 42750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 42800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 43000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 43250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 43350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 43550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 43650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 43700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 44150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 44250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 44300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 44450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 44500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 44750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 44800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 44850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 45300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 45550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 45600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 45750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 45800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 45950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 46000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 46100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 46150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 46250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 46300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 46350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 46450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 46500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 46550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 46750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 46850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 46950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 47050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 47200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 47250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 47400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 47450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 47500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 47750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 47900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 48000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 48050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 48100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 48200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 48250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 48350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 48450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 48500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 48850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 48900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 49000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 49100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 49200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 49400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 49500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 49550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 49600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 49650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 49900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 49950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 50000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 50050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 50100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 50400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 50700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 50750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 50800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 50850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 51000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 51050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 51100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 51200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 51300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 51350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 51400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 51650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 51950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 52000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 52150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 52300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 52400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 52500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 52550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 52600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 52850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 52900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 53100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 53400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 53500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 53550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 53650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 53800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 53900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 53950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 54000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 54050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 54100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 54200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 54450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 54600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 54650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 54750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 54850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 55050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 55150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 55200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 55350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 55400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 55500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 55650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 55700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 55850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 55900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 55950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 56050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 56100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 56150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 56300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 56350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 56550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 56700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 56900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 57000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 57050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 57100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 57150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 57200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 57250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 57300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 57500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 57600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 57750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 57900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 57950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 58200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 58350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 58450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 58500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 58650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 58750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 58800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 58900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 59000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 59100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 59200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 59400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 59650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 59950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 60200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 60250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 60500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 60550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 60750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 60900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 61000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 61100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 61150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 61250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 61300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 61450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 61500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 61600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 61650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 61700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 61850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 61900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 62150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 62300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 62400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 62900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 62950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 63000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 63200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 63350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 63500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 63600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 63800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 64050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 64150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 64350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 64550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 64750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 64850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 65050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 65350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 65750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 65900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 65950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 66250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 66350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 66750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 66850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 66900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 67100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 67150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 67300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 67350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 67450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 67500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 67700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 67950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 68050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 68150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 68200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 68400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 68450 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 68500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 68600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 68650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 68750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 68900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 69050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 69150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 69250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 69300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 69350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 69450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 69500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 69550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 69600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 69700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 69750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 69900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 69950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 70000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.300 \n",
      "Step 70050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 70100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 70150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 70750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 70800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 71000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 71100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 71150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 71250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 71300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 71400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 71700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 71850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 71900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 72050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 72100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 72250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 72650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 72800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 72900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 73150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 73300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 73400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 73450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 73550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 73600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 73700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 73750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 74000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 74200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 74550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 74650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 74800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 74850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 74950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 75000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 75150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 75450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 75850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 75900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 76050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 76150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 76350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 76400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 76500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 76550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 77000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 77050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 77200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 77250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 77500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 77550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 77700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 77800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 77850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 77900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 77950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 78000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 78050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 78150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 78350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 78450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 78500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 78550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 78900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 78950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 79000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 79150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 79250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 79350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 79400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 79500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 79550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 79600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 79650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 79700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 79800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 79950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 80250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 80300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 80400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 80500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 80550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 80650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 80700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 80950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 81150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 81250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 81500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 81900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 81950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 82000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 82100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 82200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 82350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 82500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 82550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 82600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 82650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 82700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 82800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 82850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 83050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 83150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 83400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 83550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 83650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 83800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 83850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 84000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 84100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 84300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 84350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 84550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 84700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 84750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 84850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 85150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 85300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 85400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 85450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 85500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 85550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 85650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 85750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 85850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 85900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 86000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 86050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 86400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 86500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 86550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 86600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 86650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 86700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 86800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 86850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 86950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 87000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 87050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 87150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 87250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 87350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 87500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 87550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 87750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 87800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 87850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 88000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 88050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 88150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 88250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 88400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 88600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 88650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 88700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 88850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 88900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 88950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 89000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 89150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 89200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 89350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 89400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 89550 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 89600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 89650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 89700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 90000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 90100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 90150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 90200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 90500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 90550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 90600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 90700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 90750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 90900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 91000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 91100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 91150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 91200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 91350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 91500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 91550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 91600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 91750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 91850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 91900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 92000 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 92050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 92100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 92350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 92550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 92600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 92650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 92750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 92800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 92850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 92900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 93050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 93100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 93150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 93400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 93500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 93900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 94200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 94600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 94800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 94900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 95050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 95150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 95300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 95400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 95650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 95750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 95850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 96000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 96100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 96300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 96350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 96400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 96650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 96800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 96850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 96900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 97000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 97100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 97200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 97350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 97400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 97450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 97550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 97600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 97750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 98050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 98100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 98200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 98250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 98400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 98450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 98650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 98750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 98900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 99000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 99100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 99300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 99450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99500 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 99550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 99600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 99800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 99950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 100200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 100250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 100300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 100450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 100650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 100750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 100800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 100900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 101000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 101100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 101150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 101250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 101400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 101450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 101500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 101600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 101750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 101950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 102200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 102250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 102300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 102550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 102650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 102700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 102750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 102950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 103000 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 103050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 103200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 103300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 103350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 103450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 103500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 103550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 103600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.300 \n",
      "Step 103700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 103800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 103850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 103900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 103950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 104100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 104150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 104300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 104400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 104450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 104500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 104550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 104600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 104650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 104900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 104950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 105000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 105050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 105100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 105150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 105200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 105300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 105350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 105400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 105450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 105650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 105700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 105900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 105950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 106050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 106100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 106150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 106300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 106350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 106500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 106600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 106750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 106800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 106850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 106900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 107050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 107100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 107150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 107350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 107400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 107500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 107550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 107800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 107850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 107950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 108050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 108100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 108250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 108350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 108450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 108550 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 108600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 108650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 108700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 108750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 109000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 109050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 109100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 109150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 109200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 109300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 109400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 109500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 109550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 109600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 109700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 110800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 111000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 111100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 111250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 111300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 111350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 111400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 111550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 111600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 111750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 111850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 112050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 112200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 112250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 112300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 112350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 112400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 112500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 112700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 113000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 113100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 113150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 113400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 113450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 113500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 113600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 113700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 113750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 113800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 114000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 114100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 114200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 114350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 114400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 114450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 114500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 114550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 114650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 114700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 114750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 114850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 114900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 115250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 115300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 115350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 115450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 115500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 115600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 115650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 115700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 115800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 115850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 115950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 116000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 116100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 116150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 116200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 116300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 116350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 116450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 116500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 116550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 116700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 116750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 116800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 116900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 117050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 117150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 117200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 117500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 117750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 117900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 117950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 118000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 118050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 118100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 118200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 118250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 118300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 118350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 118450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 118500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 118550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 118600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 119250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 119350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 119400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 119500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 119600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 119650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 119750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 119800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 119850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 119950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 120000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 120150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 120250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 120450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 120500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 120650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 120700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 120850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 120900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 121050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 121150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 121200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 121250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 121300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 121400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 121650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 121700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 121750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 121800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 121900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 121950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 122100 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 122150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 122200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 122300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 122350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 122450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 122500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 122600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 122800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 122850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 122950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 123000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 123050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 123150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 123300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 123450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 123550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 123600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 123650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 123700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 123750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 123850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 124050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 124100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 124450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 124550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 124850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 124950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 125050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 125100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 125250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 125400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 125500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 125600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 125800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 126000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 126050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 126350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 126550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 126700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 126750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 126850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 127050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 127150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 127200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 127550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 127600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 127700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 127850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 127950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 128000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 128150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128200 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 128250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 128400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 128500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 128600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 128650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 128750 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 128800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 128950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 129050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 129100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 129150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 129300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 129350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 129400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 129700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 129750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 129850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 130050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 130300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 130400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 130450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 130500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 130550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 130650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 130750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 130950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 131050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 131100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 131200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 131250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 131500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 131650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 131700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 131750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 131900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 131950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 132050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 132200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 132250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 132350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 132450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 132550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 132600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 132700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 132750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 132800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 132850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 132950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 133100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 133200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 133250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 133350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 133450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 133550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 133800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 133900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 133950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 134000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 134100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 134150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 134250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 134300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 134350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 134500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 134600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 134650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 134800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 134850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 135100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 135300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 135350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 135450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 135550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 135700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 135750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 135800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 136000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 136100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 136150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 136250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 136300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 136400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 136500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 136700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 136750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 136900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 137050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 137250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 137500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 137550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 137700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 137750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 137800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 137850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 137950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 138100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 138150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 138250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 138300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 138400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 138500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 138550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 138600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 138800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 138900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 139000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 139100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 139150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 139200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 139300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 139350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 139400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 139500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 139550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 139650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 139700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 139800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 139850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 140000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 140050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 140100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 140200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 140250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 140350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 140400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 140650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 140750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 140800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 140850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 141150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 141250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 141300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 141400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 141600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 141750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 141800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 141950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 142050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 142100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 142200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 142250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 142300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 142400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 142450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 142550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 142600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 142700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 142750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 142950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 143200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 143450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 143550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 143600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 143750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 143800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 143950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 144000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 144050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 144100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 144150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 144300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 144500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 144550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 144750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 145150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 145200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 145400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 145700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 145800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 145850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 145900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 146100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 146150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 146250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 146300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 146500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 146600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 146650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 146750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 146800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 147000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 147150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 147200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 147250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 147350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 147500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 147550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 147650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 147750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 147800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 147950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 148050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 148450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 148500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 148550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 148600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 148650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 148700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 148750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 148850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 148900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 148950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 149250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 149300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 149700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 149800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 149850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 150000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 150050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 150150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 150200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 150250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 150600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150800 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 150850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 151100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 151200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 151300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 151600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 151650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 151700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 151750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 151950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 152050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 152200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 152250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 152300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 152400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 152450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 152700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 152750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 152800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 152950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 153050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 153150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 153200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 153350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 153450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 153500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 153550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 153600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 153650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 153800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 153900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 154050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 154100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 154150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 154200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 154300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 154650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 154700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 154900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 154950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 155000 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 155050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 155150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 155200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 155300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 155350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 155400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 155600 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 155650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 155850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 155900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 156000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 156050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 156100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 156300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 156350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 156400 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 156450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 156550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 156600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 156700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 156800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 156900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 157050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 157100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 157150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 157200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 157250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 157400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 157600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 157650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 157700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 157750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 157800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 157850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 158150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 158200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 158350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 158450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 158500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 158550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 158600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 158650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 158750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 158850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 159050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 159100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 159200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 159300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 159450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 159600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 159700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 159750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 159800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 159850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 160000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 160150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 160200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 160400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 160500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 160550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 160650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 160900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 160950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 161000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 161050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 161150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 161250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 161300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 161450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 161650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 161750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 161850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 161950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 162000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 162050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 162100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 162150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 162300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 162450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 162600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 162650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 162700 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 162750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 162800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 162850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 162950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 163000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 163050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 163100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 163200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 163300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 163400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 163450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 163550 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 163600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 163650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 163850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 163950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 164000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 164200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 164300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 164400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 164650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 164700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 165150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 165200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 165250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 165900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 166000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 166100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 166150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 166250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 166300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 166350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 166450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 166600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 166700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 166750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 166800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 166900 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.000 \n",
      "Step 166950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 167050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 167150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 167200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 167250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 167300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 167500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 167650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 167800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 167900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 168200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 168600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 168700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 168750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 168800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168950 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 169000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 169050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 169150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 169200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 169250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 169300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 169350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 169400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 169450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 169550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 169750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 169900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 170000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 170100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 170150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 170300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 170350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 170450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 170650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 170700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 170800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 170850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 170900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 171050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 171250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 171300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 171350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 171500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 171550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 171600 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 171650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 171700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 171750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 171850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 171900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 171950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 172050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 172250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 172400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    }
   ],
   "source": [
    "# ======\n",
    "# Create a five-layer network based on the code in the exercise above\n",
    "# let's set some hyperparameters\n",
    "batch_size = 10\n",
    "learning_rate = 0.00001\n",
    "n_epochs = 100\n",
    "print_every = 50\n",
    "num_hidden = 100\n",
    "\n",
    "# build the neural network\n",
    "layer_1 = layer(input_size, num_hidden, activation=nn.ReLU())\n",
    "\n",
    "# Create additional hidden layers\n",
    "layer_2 = layer(num_hidden, num_hidden, activation=nn.ReLU())\n",
    "layer_3 = layer(num_hidden, num_hidden, activation=nn.ReLU())\n",
    "layer_4 = layer(num_hidden, num_hidden, activation=nn.ReLU())\n",
    "layer_5 = layer(num_hidden, num_hidden, activation=nn.ReLU())\n",
    "\n",
    "layer_6 = layer(num_hidden, num_classes, activation=nn.Softmax())\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.SGD(\n",
    "    # Add all of the network weights for the three layers\n",
    "    [layer_1.weight, layer_1.bias,\n",
    "     layer_2.weight, layer_2.bias,\n",
    "     layer_3.weight, layer_3.bias,\n",
    "     layer_4.weight, layer_4.bias,\n",
    "     layer_5.weight, layer_5.bias,\n",
    "     layer_6.weight, layer_6.bias],\n",
    "    lr=learning_rate)\n",
    "\n",
    "# train the network\n",
    "step = 0\n",
    "results = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "}\n",
    "for epoch in range(n_epochs):\n",
    "    # randomize the order in which we see the data in each epoch\n",
    "    random_order_indices = np.random.choice(train_tensor.shape[0], train_tensor.shape[0], replace=False)\n",
    "    \n",
    "    # iterate through the data in batches of size `batch_size`\n",
    "    for batch_indices in np.array_split(random_order_indices, random_order_indices.shape[0] // batch_size):\n",
    "      \n",
    "        train_data_batch = train_tensor[batch_indices]\n",
    "        train_labels_batch = train_labels[batch_indices]\n",
    "        train_onehot = to_one_hot(train_labels_batch, num_classes)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # get pass batch through layers\n",
    "        hidden_layer1 = layer_1(train_data_batch)\n",
    "        # Apply your additional hidden layers\n",
    "        hidden_layer2 = layer_2(hidden_layer1)\n",
    "        hidden_layer3 = layer_3(hidden_layer2)\n",
    "        hidden_layer4 = layer_4(hidden_layer3)\n",
    "        hidden_layer5 = layer_5(hidden_layer4)\n",
    "        output = layer_6(hidden_layer5)\n",
    "\n",
    "        # compute cross entropy\n",
    "        loss = train_onehot * torch.log(output+ 1e-6) + (1 - train_onehot) * torch.log(1 - output + 1e-6)\n",
    "        loss = -1 * loss.sum()\n",
    "\n",
    "        # backpropagate the loss\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # evaluate accuracy on both the training and validation datasets\n",
    "        if step % print_every == 0:\n",
    "            \n",
    "            # don't track gradients\n",
    "            with torch.no_grad():\n",
    "                # compute the predicted outputs\n",
    "                train_prediction = output.argmax(1).numpy()\n",
    "\n",
    "                # compute the accuracy over the batch\n",
    "                acc_training = np.mean(train_prediction == train_labels_batch.numpy())\n",
    "\n",
    "                # compute the loss on all the validation data\n",
    "                loss_np = []\n",
    "                output_np = []\n",
    "                labels_np = []\n",
    "\n",
    "                random_order_indices = np.random.choice(valid_tensor.shape[0], valid_tensor.shape[0], replace=False)\n",
    "\n",
    "                for batch_indices in np.array_split(random_order_indices, random_order_indices.shape[0] // batch_size):\n",
    "                    valid_data_batch = valid_tensor[batch_indices]\n",
    "                    valid_labels_batch = valid_labels[batch_indices]\n",
    "\n",
    "                    # pass through layers\n",
    "                    valid_hidden1 = layer_1(valid_data_batch)\n",
    "                    # Apply your additional hidden layers\n",
    "                    valid_hidden2 = layer_2(valid_hidden1)\n",
    "                    valid_hidden3 = layer_3(valid_hidden2)\n",
    "                    valid_hidden4 = layer_4(valid_hidden3)\n",
    "                    valid_hidden5 = layer_5(valid_hidden4)\n",
    "                    \n",
    "                    valid_output = layer_6(hidden_layer5)\n",
    "\n",
    "                    # compute the predicted outputs\n",
    "\n",
    "                    prediction_np = valid_output.argmax(1).numpy()\n",
    "\n",
    "                    output_np = np.concatenate(prediction_np.reshape(-1,1), axis=0)\n",
    "                    labels_np = np.concatenate(valid_labels_batch.numpy().reshape(-1,1), axis=0)\n",
    "\n",
    "\n",
    "                # compute the accuracy over the whole dataset\n",
    "                acc_validation = np.mean(output_np == labels_np)\n",
    "\n",
    "                results['train_loss'].append(loss.item())\n",
    "                results['train_acc'].append(acc_training)\n",
    "                results['val_acc'].append(acc_validation)\n",
    "                print('Step {} loss: {:.3f} training accuracy: {:.3f} validation accuracy: {:.3f} '.format(\n",
    "                    step, loss.item(), acc_training, acc_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bUMW2qppGV98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f405e0f33a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['train_loss'])\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Training loss')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['train_acc'], label='Training accuracy')\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['val_acc'], label='Validation accuracy')\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "# ======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 - optimizers\n",
    "\n",
    "PyTorch provides a number of different optimizers for us to choose from. Replace `optim.SGD` with any of `optim.RMSprop`, `optim.Adagrad` and `optim.Adam` and experiment with the number of layers and hidden units to find the best possible network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-dfdd7b4cad66>:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = self.activation(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1300 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 1350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 1900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 1950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2000 loss: 276.280 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 2650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 2750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 2950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 3550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 3600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 3950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 4000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 4850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 4950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 5500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 5650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 5900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 5950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 6700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 6850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 6950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 7350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 7750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 7950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 8400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 8550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 8600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 8900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 8950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 9250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 9550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 9850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 9900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 9950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 10050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 10350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 10950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 11500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 11650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 11800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 11950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 12350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 12900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 12950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 13050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 13200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 13300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 13600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 13900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 13950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 14300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 14650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 14700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 14950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 15950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 16050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 16250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 16650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 16950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 17150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 17200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 17300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 17600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 17700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 17950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 18100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 18500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 18950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 19000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 19150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 19950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 20150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 20500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 20600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 20950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 21100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 21200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 21350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 21500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 21800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 21850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 21900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 21950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 22450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 22900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 22950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 23050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 23100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 23150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 23250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 23950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 24250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 24900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 24950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 25300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 25350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 25500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 25550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 25700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 25800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 25950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 26100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 26550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 26950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 27000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 27300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 27400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 27500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 27600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 27700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 27850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 27950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 28250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 28500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 28550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 28950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 29700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 29950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 30150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 30350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 30700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 30750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 30950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 31000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 31550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 31650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 31750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 31800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 31850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 31900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 32000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 32300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 32600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 32800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 32850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 32950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 33050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 33100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 33500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 33650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 33950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 34200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 34850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 34950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 35100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 35350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 35950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 36350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 36900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 36950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 37050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 37250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 37400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 37450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 37650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 37800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 37850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 37950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 38050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 38350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 38550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 38800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 38900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 38950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 39000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 39650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 39800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 39950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 40250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 40600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 40900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 40950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 41150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 41200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 41350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 41500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 41750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 41900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 41950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 42100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 42300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 42450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 42550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 42650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 42750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 42800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 42900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 42950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 43050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 43350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 43900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 43950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 44600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 44650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 44850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 44950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 45550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 45600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 45950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 46100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 46450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 46650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 46700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 46950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 47250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 47850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 47900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 47950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 48150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 48350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 48800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 48950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 49000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 49250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 49300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 49450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 49600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 49650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 49800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 49900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 49950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 50150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 50300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 50800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 50950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 51650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 51700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 51900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 51950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 52200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 52300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 52350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 52550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 52750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 52800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 52950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 53150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 53400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 53600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 53750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 53950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 54400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 54450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 54650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 54700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 54950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 55000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 55150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 55450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 55650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 55900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 55950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 56250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 56350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 56550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 56600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 56900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 56950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 57050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 57250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 57550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 57600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 57650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 57750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 57800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 57950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 58000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 58100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 58450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 58650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 58900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 58950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 59100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 59200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 59350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 59400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 59450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 59600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 59750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 59900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 59950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 60300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 60550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 60800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 60850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 60900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 60950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 61250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 61350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 61500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 61800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 61850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 61900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 61950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 62250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 62850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 62950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 63250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 63450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 63550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 63650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 63750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 63950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 64400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 64850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 64950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 65900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 65950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 66150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 66300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 66800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 66850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 66900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 66950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 67000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 67550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 67850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 67950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 68000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 68250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 68350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 68400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 68500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 68950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 69000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 69050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 69200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 69350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 69550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 69750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 69800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 69900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 69950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 70450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 70500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 70700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 70950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 71050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 71100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 71400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 71550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 71750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 71950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 72000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 72150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 72200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 72300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 72400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 72500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 72700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 72900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 72950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 73300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 73450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 73500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 73950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 74350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 74400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 74600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 74950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 75300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 75500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 75800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 75900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 75950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 76050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 76900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 76950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 77000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 77050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 77100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 77300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 77350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 77900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 77950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 78050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 78700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 78950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 79050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 79250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 79600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 79650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 79950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 80500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 80750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 80800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 80950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 81500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 81550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 81600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 81650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 81900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 81950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 82250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 82350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 82400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 82750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 82850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 82900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 82950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 83100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 83350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 83400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 83450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 83550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 83900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 83950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 84300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 84350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 84750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 84800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 84850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 84900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 84950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 85700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 85800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 85850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 85900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 85950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 86300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 86350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 86450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 86500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 86600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 86750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 86850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 86900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 86950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 87100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 87150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 87300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 87450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 87950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 88150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 88200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 88450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 88650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 88700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 88950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 89000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 89150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 89750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89850 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 89900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 89950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 90100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 90250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 90350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 90500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 90750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 90800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 90950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 91350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 91400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 91650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 91850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 91950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 92000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 92250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 92550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 92700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 92900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 92950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 93000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 93550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93650 loss: 193.417 training accuracy: 0.300 validation accuracy: 0.100 \n",
      "Step 93700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 93850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 93950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 94050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 94100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 94150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 94650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 94900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 94950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 95000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 95300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 95450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 95550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 95900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 95950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 96350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 96550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 96600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 96650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 96850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 96950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 97000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 97350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 97500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 97800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 97900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 97950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 98150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 98200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 98350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 98400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 98450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 98950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 99100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 99550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 99600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 99950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 100000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 100600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 100650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 100850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 100950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 101850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 101950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 102050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 102250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 102400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 102600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102650 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 102700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 102750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 102900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 102950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 103200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 103300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 103750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 103950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 104000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 104100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 104300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 104900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 104950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 105700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 105900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 105950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 106000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 106550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 106800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 106850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 106950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 107500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 107850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 107900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 107950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 108000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 108550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 108950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 109750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 109850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 109950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110050 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 110100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 110300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 110650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 110700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 110850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 110900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 110950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 111200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 111400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 111550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 111650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 111750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 111850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 111900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 111950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 112650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 112900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 112950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 113200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 113250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 113350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 113450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 113950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 114050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 114250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 114500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 114750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 114950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 115150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 115250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 115350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 115400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 115950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 116200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 116400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 116450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 116700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 116900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 116950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 117150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 117350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 117400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 117450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 117700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 117900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 117950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 118000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 118050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 118550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 118650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 118850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 118950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 119550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 119600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 119700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 119750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 119950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 120150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 120400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 120450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 120500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 120700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 120950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 121050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 121200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 121250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 121350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 121450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 121600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 121650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 121950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 122150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 122400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 122550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 122850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 122900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 122950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 123000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 123250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 123400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 123750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 123850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 123950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124150 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 124200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 124250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 124600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 124700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 124950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 125000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 125100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 125200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125800 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.100 \n",
      "Step 125850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 125900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 125950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 126300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 126400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 126500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 126550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 126650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 126700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 126800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 126950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 127700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 127950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 128100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 128700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 128800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 128900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 128950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 129450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 129550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 129800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 129950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 130050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130400 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 130450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 130550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 130600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 130800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 130950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 131150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 131200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 131250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 131500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 131650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 131950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 132000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 132050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 132100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 132250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 132550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 132750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 132850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 132900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 132950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 133350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 133450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 133550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 133750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 133800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 133850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 133900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 133950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 134000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 134050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 134100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 134400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 134450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 134500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 134700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 134800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 134900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 134950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 135100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 135200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 135350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 135500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 135600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 135800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 135950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 136550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 136850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 136950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 137100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 137150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 137200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 137400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 137600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 137850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 137950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 138050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 138550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 138850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 138950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.200 \n",
      "Step 139250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 139500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 139650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 139900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 139950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 140100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 140200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140250 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.200 \n",
      "Step 140300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 140650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 140750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 140800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 140950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 141050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.200 \n",
      "Step 141100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 141150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 141250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 141300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 141450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 141900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 141950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 142000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 142150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 142250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 142350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 142400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 142600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 142900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 142950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 143250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 143450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 143550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 143600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 143700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 143850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 143900 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 143950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 144000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 144150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 144450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 144800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 144900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 144950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 145350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145400 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 145450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 145750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 145950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 146300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 146350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 146550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 146600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 146950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 147350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147400 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 147450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 147550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 147600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 147900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 147950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 148350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 148900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 148950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149150 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 149200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 149450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 149550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149750 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 149800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 149950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 150050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 150150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 150200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 150300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 150350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 150400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 150950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 151250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 151400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 151750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 151950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152000 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 152050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 152150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 152350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 152750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 152800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 152850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 152950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 153400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 153550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 153700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 153850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 153900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 153950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 154550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 154700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 154750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 154950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 155750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 155800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 155850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 155900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 155950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156000 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 156050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 156350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 156850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 156900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 156950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 157000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 157550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 157850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 157950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 158000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 158350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158400 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 158450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 158800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 158950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 159950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 160000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160250 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 160300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 160350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 160600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 160650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 160700 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 160750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 160900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 160950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 161150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161300 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 161350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 161550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 161600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 161650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 161700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 161900 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 161950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 162150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 162950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 163200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 163250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 163950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 164100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 164500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 164700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 164950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 165200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165500 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 165550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 165650 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 165700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 165950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 166150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 166450 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 166500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 166750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 166800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 166950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 167100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 167150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167550 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 167600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 167900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 167950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 168100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168200 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 168250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 168400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 168650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168750 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 168800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 168900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 168950 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 169000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169100 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 169150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 169350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169600 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 169650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 169750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169800 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.100 \n",
      "Step 169850 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 169900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 169950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 170000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170350 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 170400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 170900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 170950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171050 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171350 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171450 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171500 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171550 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.100 \n",
      "Step 171600 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171650 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171700 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171750 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171800 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171850 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171900 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 171950 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172000 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172050 loss: 248.679 training accuracy: 0.100 validation accuracy: 0.000 \n",
      "Step 172100 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172150 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172200 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172250 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172300 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n",
      "Step 172350 loss: 221.048 training accuracy: 0.200 validation accuracy: 0.000 \n",
      "Step 172400 loss: 276.310 training accuracy: 0.000 validation accuracy: 0.000 \n"
     ]
    }
   ],
   "source": [
    "# ======\n",
    "# Create a neural network based on the code in the exercises above\n",
    "# Modify the optimizer to find what works best\n",
    "batch_size = 10\n",
    "learning_rate = 0.00001\n",
    "n_epochs = 100\n",
    "print_every = 50\n",
    "num_hidden = 100\n",
    "\n",
    "# build the neural network\n",
    "layer_1 = layer(input_size, num_hidden, activation=nn.ReLU())\n",
    "\n",
    "# Create additional hidden layers\n",
    "layer_2 = layer(num_hidden, num_hidden, activation=nn.ReLU())\n",
    "layer_3 = layer(num_hidden, num_hidden, activation=nn.ReLU())\n",
    "layer_4 = layer(num_hidden, num_hidden, activation=nn.ReLU())\n",
    "layer_5 = layer(num_hidden, num_hidden, activation=nn.ReLU())\n",
    "\n",
    "layer_6 = layer(num_hidden, num_classes, activation=nn.Softmax())\n",
    "\n",
    "# create the optimizer\n",
    "optimizer = optim.Adam(\n",
    "    # Add all of the network weights for the three layers\n",
    "    [layer_1.weight, layer_1.bias,\n",
    "     layer_2.weight, layer_2.bias,\n",
    "     layer_3.weight, layer_3.bias,\n",
    "     layer_4.weight, layer_4.bias,\n",
    "     layer_5.weight, layer_5.bias,\n",
    "     layer_6.weight, layer_6.bias],\n",
    "    lr=learning_rate)\n",
    "\n",
    "# train the network\n",
    "step = 0\n",
    "results = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "}\n",
    "for epoch in range(n_epochs):\n",
    "    # randomize the order in which we see the data in each epoch\n",
    "    random_order_indices = np.random.choice(train_tensor.shape[0], train_tensor.shape[0], replace=False)\n",
    "    \n",
    "    # iterate through the data in batches of size `batch_size`\n",
    "    for batch_indices in np.array_split(random_order_indices, random_order_indices.shape[0] // batch_size):\n",
    "      \n",
    "        train_data_batch = train_tensor[batch_indices]\n",
    "        train_labels_batch = train_labels[batch_indices]\n",
    "        train_onehot = to_one_hot(train_labels_batch, num_classes)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # get pass batch through layers\n",
    "        hidden_layer1 = layer_1(train_data_batch)\n",
    "        # Apply your additional hidden layers\n",
    "        hidden_layer2 = layer_2(hidden_layer1)\n",
    "        hidden_layer3 = layer_3(hidden_layer2)\n",
    "        hidden_layer4 = layer_4(hidden_layer3)\n",
    "        hidden_layer5 = layer_5(hidden_layer4)\n",
    "        output = layer_6(hidden_layer5)\n",
    "\n",
    "        # compute cross entropy\n",
    "        loss = train_onehot * torch.log(output+ 1e-6) + (1 - train_onehot) * torch.log(1 - output + 1e-6)\n",
    "        loss = -1 * loss.sum()\n",
    "\n",
    "        # backpropagate the loss\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # evaluate accuracy on both the training and validation datasets\n",
    "        if step % print_every == 0:\n",
    "            \n",
    "            # don't track gradients\n",
    "            with torch.no_grad():\n",
    "                # compute the predicted outputs\n",
    "                train_prediction = output.argmax(1).numpy()\n",
    "\n",
    "                # compute the accuracy over the batch\n",
    "                acc_training = np.mean(train_prediction == train_labels_batch.numpy())\n",
    "\n",
    "                # compute the loss on all the validation data\n",
    "                loss_np = []\n",
    "                output_np = []\n",
    "                labels_np = []\n",
    "\n",
    "                random_order_indices = np.random.choice(valid_tensor.shape[0], valid_tensor.shape[0], replace=False)\n",
    "\n",
    "                for batch_indices in np.array_split(random_order_indices, random_order_indices.shape[0] // batch_size):\n",
    "                    valid_data_batch = valid_tensor[batch_indices]\n",
    "                    valid_labels_batch = valid_labels[batch_indices]\n",
    "\n",
    "                    # pass through layers\n",
    "                    valid_hidden1 = layer_1(valid_data_batch)\n",
    "                    # Apply your additional hidden layers\n",
    "                    valid_hidden2 = layer_2(valid_hidden1)\n",
    "                    valid_hidden3 = layer_3(valid_hidden2)\n",
    "                    valid_hidden4 = layer_4(valid_hidden3)\n",
    "                    valid_hidden5 = layer_5(valid_hidden4)\n",
    "                    \n",
    "                    valid_output = layer_6(hidden_layer5)\n",
    "\n",
    "                    # compute the predicted outputs\n",
    "\n",
    "                    prediction_np = valid_output.argmax(1).numpy()\n",
    "\n",
    "                    output_np = np.concatenate(prediction_np.reshape(-1,1), axis=0)\n",
    "                    labels_np = np.concatenate(valid_labels_batch.numpy().reshape(-1,1), axis=0)\n",
    "\n",
    "\n",
    "                # compute the accuracy over the whole dataset\n",
    "                acc_validation = np.mean(output_np == labels_np)\n",
    "\n",
    "                results['train_loss'].append(loss.item())\n",
    "                results['train_acc'].append(acc_training)\n",
    "                results['val_acc'].append(acc_validation)\n",
    "                print('Step {} loss: {:.3f} training accuracy: {:.3f} validation accuracy: {:.3f} '.format(\n",
    "                    step, loss.item(), acc_training, acc_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f405e1eb700>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['train_loss'])\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Training loss')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['train_acc'], label='Training accuracy')\n",
    "plt.plot(np.arange(len(results['train_loss'])) * print_every, results['val_acc'], label='Validation accuracy')\n",
    "plt.xlabel('Training step')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "# ======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQLRokIMGXkQ"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "1. How did the more complex networks you built compare to the simple network we started with?\n",
    "2. Which was more useful -- adding _depth_ to your network or adding width?\n",
    "3. Which optimizer performed best?\n",
    "4. What had the biggest effect on performance: depth, width, or optimizer?\n",
    "\n",
    "#### Re-Cap\n",
    "1. Power of PyTorch is to allow us to setup the neural networks using nn.Module\n",
    "\n",
    "2. We can use the same neural network over and over with different data without having to re-write the code."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "00_Classifier_networks_draft.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/KrishnaswamyLab/SingleCellWorkshop/blob/master/exercises/Deep_Learning/notebooks/00_Classifier_networks.ipynb",
     "timestamp": 1589251939756
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
