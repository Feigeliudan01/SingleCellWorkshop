{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSMbk-Ndx29Z"
   },
   "source": [
    "# Exploratory analysis of single cell data with SAUCIE\n",
    "\n",
    "In this notebook, we will use SAUCIE, a multitasking neural network, that can be used for visualization, clustering, batch correction and denoising of single cell data. We will apply it once again to the Shekhar et al. retinal bipolar data.\n",
    "\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 855
    },
    "colab_type": "code",
    "id": "NQM54ZUU61dE",
    "outputId": "2612b984-943d-4368-a048-7139cdb11a98"
   },
   "outputs": [],
   "source": [
    "!pip install scprep\n",
    "!pip install tensorflow==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgaZZU8r4drd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.decomposition\n",
    "import scprep\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2iJh3zV1x296"
   },
   "source": [
    "SAUCIE is not available on PyPi, but we can download it from GitHub and add it to our Python path to run it without any further installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "vcx_hovEx298",
    "outputId": "0b342996-9e89-4922-f120-dfded787a4b8"
   },
   "outputs": [],
   "source": [
    "# download SAUCIE from Github\n",
    "!git clone https://github.com/KrishnaswamyLab/SAUCIE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2sVFMKCBx2-D"
   },
   "outputs": [],
   "source": [
    "# add SAUCIE to the python path\n",
    "sys.path.append('./SAUCIE/')\n",
    "import SAUCIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JV-qIoto-zU9"
   },
   "source": [
    "## 2. Loading the retinal bipolar data\n",
    "\n",
    "We'll use the same retinal bipolar data you saw in preprocessing and visualization.\n",
    "\n",
    "Alternatively, you may load your own data by replacing the Google Drive file ids with your own file ids.\n",
    "\n",
    "Note that if you do, you will likely not have annotated celltype labels yet. Replace all references to `metadata['CELLTYPE']` with an entry from `metadata`, or your favorite gene. Parts of this notebook are only applicable if you have multiple batches, which you should encode in `metadata['sample_id']` as integers and `metadata['sample_name']` as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cFcDskDHNBT"
   },
   "outputs": [],
   "source": [
    "scprep.io.download.download_google_drive(\"1GYqmGgv-QY6mRTJhOCE1sHWszRGMFpnf\", \"data.pickle.gz\")\n",
    "scprep.io.download.download_google_drive(\"1q1N1s044FGWzYnQEoYMDJOjdWPm_Uone\", \"metadata.pickle.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "colab_type": "code",
    "id": "ujIUq8Km9jNr",
    "outputId": "0a70897e-4aba-4a64-ab22-ed4e03ff1ac8"
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_pickle(\"data.pickle.gz\")\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5rfUjXo-zVR"
   },
   "source": [
    "Technically, the retinal bipolar data comes from six separate sequencing runs with subtle batch effects between then. For simplicity, we'll treat these six runs as coming from two batches---runs 1-3 and runs 4-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "0WJjwXpxx2-p",
    "outputId": "1c5411a1-5120-446c-e291-9bbc6af3fe21"
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_pickle(\"metadata.pickle.gz\")\n",
    "# the batch ids are in the cell barcode names\n",
    "metadata['batch'] = [int(index[7]) for index in metadata.index]\n",
    "# for simplicity, we'll split the six batches into two groups -- 1-3 and 4-6\n",
    "metadata['sample_id'] = np.where(metadata['batch'] < 4, 1, 2)\n",
    "metadata['sample_name'] = np.where(metadata['batch'] < 4, 'Samples 1-3', 'Samples 4-6')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Buk9aswH-zVZ"
   },
   "source": [
    "## 3. Preparing the data\n",
    "\n",
    "Data for input to neural networks should generally be 100 or less input dimensions. If you have more than that, you should run PCA. If you have less, you should ensure that each of your data features are roughly normally distributed with mean 0 and standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "id": "p-xYURo_x2-w",
    "outputId": "e48cb55f-b8c7-4c81-bc14-2b660985e8c2"
   },
   "outputs": [],
   "source": [
    "pca_op = sklearn.decomposition.PCA(100)\n",
    "data = pca_op.fit_transform(data_raw)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "TDHUFM6f-zVf",
    "outputId": "ae646d7e-ce30-4cd7-862f-daf1d2cd02c6"
   },
   "outputs": [],
   "source": [
    "n_features = data.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "QhtkGfkLx2-2",
    "outputId": "104546b3-6b41-4ed8-a8a3-37f36e7cdb31"
   },
   "outputs": [],
   "source": [
    "scprep.plot.scatter2d(data, c=metadata['sample_name'], ticks=False, label_prefix=\"PC\", legend_title=\"Batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "olyoqmrX-zVr"
   },
   "source": [
    "## 4. Running SAUCIE for visualization\n",
    "\n",
    "SAUCIE contains a convenience class `SAUCIE.Loader` which allows us to easily send our data to the SAUCIE model without worrying about the underlying neural network mechanics. We'll build two of these -- one for training the model, which randomizes the order of the data points, and one for evaluating the model, which sends the points through in order so we can compare them to our metadata object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wkXQ956x2-_"
   },
   "outputs": [],
   "source": [
    "# in training: get random order\n",
    "loader_train = SAUCIE.Loader(data, labels=metadata['sample_id'], shuffle=True)\n",
    "# to evaluate: get same order, so we know which row is which\n",
    "loader_eval = SAUCIE.Loader(data, labels=metadata['sample_id'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31mq-1Ni-zVx"
   },
   "source": [
    "Each time we run SAUCIE, we should call `tf.reset_default_graph()` to clear any previous runs. Then all we need to do to actually run SAUCIE is to create the model `SAUCIE.SAUCIE(n_features)` and run `model.train(loader)`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "WccaR6BW-mCX",
    "outputId": "1326ab50-eaa5-434b-b69b-381f242b7345"
   },
   "outputs": [],
   "source": [
    "# clear the computational graph\n",
    "tf.reset_default_graph()\n",
    "# build the SAUCIE model\n",
    "model = SAUCIE.SAUCIE(n_features)\n",
    "# train the model!\n",
    "model.train(loader_train, steps=1000)\n",
    "\n",
    "# get the visualization layer\n",
    "embedding, _ = model.get_embedding(loader_eval)\n",
    "\n",
    "# plot the results\n",
    "scprep.plot.scatter2d(embedding, c=metadata['sample_name'], ticks=False, label_prefix=\"SAUCIE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XLHJRj3x-zV6"
   },
   "source": [
    "### Exercise - examine the visualization\n",
    "\n",
    "Try coloring the SAUCIE visualization by features in the `metadata` data frame, or by gene expression from `data_raw`. Compare this to what you saw when visualizing the same dataset with PCA, PHATE, t-SNE or UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jjw4D1F2-zV7"
   },
   "outputs": [],
   "source": [
    "# =======\n",
    "# plot `embedding` colored by the feature or meta-feature of your choice\n",
    "scprep.plot.scatter2d(\n",
    "# ======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L5aYpIHv-zV_"
   },
   "outputs": [],
   "source": [
    "# ======\n",
    "# run the visualization of your choice\n",
    "# you may need to install PHATE or UMAP (`!pip install phate` or `!pip install umap-learn`)\n",
    "embedding_op = \n",
    "alt_embedding = embedding_op.fit_transform(data)\n",
    "# plot `alt_embedding` colored by the sample labels and the feature or meta-feature of your choice\n",
    "scprep.plot.scatter2d(\n",
    "# ======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0V2td19_-zWF"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "1. What do you notice about the SAUCIE visualization?\n",
    "2. How does the visualization compare to UMAP and PHATE?\n",
    "3. When do you think it would be useful to use SAUCIE instead of any other visualization technique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67IWWsZ2-zWF"
   },
   "source": [
    "## 5. Running SAUCIE for batch correction\n",
    "\n",
    "#### Characterizing the batch effect\n",
    "\n",
    "We noticed in the visualization above that there is a small but noticeable difference between the batches. Let's take a look at the differences between batches to understand the batch effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "id": "3GpawRG0-zWG",
    "outputId": "5801122a-2659-4591-b72d-765d80eb3dae"
   },
   "outputs": [],
   "source": [
    "# Calculate the differential expression by calculating the t-statistic between samples\n",
    "de_results = scprep.stats.differential_expression(data_raw.loc[metadata['sample_name'] == 'Samples 1-3'],\n",
    "                                                  data_raw.loc[metadata['sample_name'] == 'Samples 4-6'],\n",
    "                                                  measure='ttest')\n",
    "de_results.iloc[0:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aOTHJ-27-zWL",
    "outputId": "4a5fd4cc-5b1b-4be4-9396-3027345bf6dd"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 5, figsize=(20, 16))\n",
    "for gene, ax in zip(de_results.index, axes.flatten()):\n",
    "    scprep.plot.histogram([\n",
    "        data_raw.loc[metadata['sample_name'] == 'Samples 1-3', gene],\n",
    "        data_raw.loc[metadata['sample_name'] == 'Samples 4-6', gene],\n",
    "    ], color=['red', 'blue'], ax=ax, title=gene, log='y')\n",
    "\n",
    "scprep.plot.tools.generate_legend({'Samples 1-3':'red', 'Samples 4-6':'blue'}, \n",
    "                                  ax=axes[0,-1], fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEqjlKni-zWP"
   },
   "source": [
    "There seem to be two different types of genes here: one set in which Samples 1-3 have nearly zero expression ( _Xist, Platr17, Smim10l1, Tsix,_ etc ) and another where Samples have systematically higher expression ( _BC033916, 2700089E24Rik, Rsrp1,_ etc ). It's worth noting that many of these second group are poorly characterized in the literature. We should also be careful when we see a gene like _Xist_ in a list of differentially expressed genes, since this gene is strongly sex-linked.\n",
    "\n",
    "Let's assume that we want to correct this batch effect. For more discussion of why you might _not_ want to correct it, see our materials on batch correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpmNAHGi-zWP"
   },
   "source": [
    "#### Correcting the batch effect\n",
    "\n",
    "In order to run batch correction with SAUCIE, we can run SAUCIE in the same way as before, but using the keyword argument `lambda_b` (the MMD coefficient, which is set to 0 by default). The larger the coefficient, the more batch correction SAUCIE will apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "S1ibzbuO-oCM",
    "outputId": "58db3da2-5dfb-4d18-a410-05c5891c279e"
   },
   "outputs": [],
   "source": [
    "# compile the tf computations for saucie\n",
    "tf.reset_default_graph()\n",
    "model = SAUCIE.SAUCIE(n_features, lambda_b=1)\n",
    "\n",
    "# train the data\n",
    "model.train(loader_train, steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21sf_-SQ-zWe"
   },
   "source": [
    "#### Examining the corrected data\n",
    "\n",
    "Now we can obtain the reconstructed data from SAUCIE, and see how well we have corrected the batch effect by looking at those same differentially expressed genes from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BnQ4lfKT-zWe",
    "outputId": "817a16e2-f10a-4460-8251-26d1f9ce05f3"
   },
   "outputs": [],
   "source": [
    "# get the output of SAUCIE\n",
    "data_reconstructed, _ = model.get_reconstruction(loader_eval)\n",
    "\n",
    "# invert PCA to get the reconstructed data in the ambient gene space\n",
    "data_raw_reconstructed = pca_op.inverse_transform(data_reconstructed)\n",
    "data_raw_reconstructed = pd.DataFrame(data_raw_reconstructed, index=data_raw.index, columns=data_raw.columns)\n",
    "\n",
    "# plot the same genes that were differentially expressed in the original data\n",
    "fig, axes = plt.subplots(4, 5, figsize=(20, 16))\n",
    "for gene, ax in zip(de_results.index, axes.flatten()):\n",
    "    scprep.plot.histogram([\n",
    "        data_raw_reconstructed.loc[metadata['sample_name'] == 'Samples 1-3', gene],\n",
    "        data_raw_reconstructed.loc[metadata['sample_name'] == 'Samples 4-6', gene],\n",
    "    ], color=['red', 'blue'], ax=ax, title=gene, log='y')\n",
    "\n",
    "scprep.plot.tools.generate_legend({'Samples 1-3':'red', 'Samples 4-6':'blue'}, \n",
    "                                  ax=axes[0,-1], fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yt84MGre-zWj"
   },
   "source": [
    "Note that the differences we saw earlier are now gone.\n",
    "\n",
    "We can also examine the batch effect in the visualization space. Here we look at the visualization from SAUCIE as it was correcting the batch effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "wRYwN3Il-zWk",
    "outputId": "68ff004e-6710-47db-a94e-ad4b7d7bd26f"
   },
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "batch_correction_embedding, _ = model.get_embedding(loader_eval)\n",
    "\n",
    "scprep.plot.scatter2d(batch_correction_embedding, c=metadata['sample_name'], ticks=False, label_prefix=\"SAUCIE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rTfn2Bl-zWp"
   },
   "source": [
    "### Exercise - rerunning SAUCIE on batch corrected data\n",
    "\n",
    "You'll notice that the embedding is far less granular than the one we saw at the beginning -- this is due to the additional constraint on the network enforced by the batch correction regularization. We can improve this somewhat by running SAUCIE again to visualize the reconstructed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======\n",
    "# create loaders for batch-corrected data\n",
    "loader_train = SAUCIE.Loader(\n",
    "    data = , \n",
    "    labels = , \n",
    "    shuffle=True\n",
    ")\n",
    "loader_eval = SAUCIE.Loader(\n",
    "    data = , \n",
    "    labels = , \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# compile tf computations for saucie\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# build and run the model\n",
    "model = \n",
    "model.train(load = , \n",
    "            steps=1000)\n",
    "# =======\n",
    "\n",
    "# look at the embedding layer\n",
    "reconstructed_embedding, _ = model.get_embedding(loader_eval)\n",
    "\n",
    "# plot the output\n",
    "scprep.plot.scatter2d(reconstructed_embedding, \n",
    "                      c=metadata['sample_name'],\n",
    "                      ticks=False, label_prefix=\"SAUCIE\", figsize=(4,4))\n",
    "scprep.plot.scatter2d(reconstructed_embedding, \n",
    "                      c=metadata['CELLTYPE'],\n",
    "                      ticks=False, label_prefix=\"SAUCIE\", figsize=(10,4), legend_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "1. What do you notice about the gene expression pre- and post-batch correction?\n",
    "2. What do you notice about the SAUCIE visualizations from the batch correcting model, and from the secondary model that we ran on batch corrected data?\n",
    "3. When might you use SAUCIE for batch correction instead of other methods like MNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WokRRqjk-zWt"
   },
   "source": [
    "## 5. Running SAUCIE for clustering\n",
    "\n",
    "In order to run clustering with SAUCIE, we can run SAUCIE in the same way as before, but using the keyword argument `lambda_c` (the ID regularization coefficient, which is set to 0 by default) and `lambda_d` (the intra-cluster distance coefficient, which is set to 0 by default). The larger we set `lambda_c`, the stronger the binary assignments will be; the larger we set `lambda_d`, the more SAUCIE will expect clusters to be distinct from each other.\n",
    "\n",
    "For the clustering to work well, we should scale the data to range between -10 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37FiZ8S4-sEy"
   },
   "outputs": [],
   "source": [
    "# rescale the data for better clustering\n",
    "data_scaled = data / data.max() * 10\n",
    "loader_train = SAUCIE.Loader(data_scaled, labels=metadata['sample_id'], shuffle=True)\n",
    "loader_eval = SAUCIE.Loader(data_scaled, labels=metadata['sample_id'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "kmk_B4-F-zW5",
    "outputId": "ea415145-d7e6-4220-9c06-582dc1ae1d30"
   },
   "outputs": [],
   "source": [
    "# compile the tf computations for the clustering model\n",
    "tf.reset_default_graph()\n",
    "model = SAUCIE.SAUCIE(n_features, lambda_c=.1, lambda_d=.5)\n",
    "\n",
    "# train the clustering model\n",
    "model.train(loader_train, steps=5000)\n",
    "\n",
    "# get the clusters out\n",
    "_, clusters = model.get_clusters(loader_eval, binmin=10)\n",
    "cluster_embedding, _ = model.get_embedding(loader_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "0KgjhWL_-uFQ",
    "outputId": "654a4fe9-0b4e-4c8a-aa62-78243218a525"
   },
   "outputs": [],
   "source": [
    "scprep.plot.scatter2d(cluster_embedding, c=clusters, ticks=False, label_prefix=\"SAUCIE\", \n",
    "                      discrete=True, figsize=(10, 4), legend_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dA_D7Nxi-zXG"
   },
   "source": [
    "### Exercise - understanding SAUCIE clustering\n",
    "\n",
    "In groups, explore the effect of `lambda_c` and `lambda_d` on SAUCIE's clustering.\n",
    "\n",
    "1. Pick one of these two coefficients to hold constant while you vary the other\n",
    "2. Pick one value larger than what we used above and one value smaller.\n",
    "3. Visualize the cluster assignments on both the SAUCIE visualization and another visualization of your choice (e.g. PHATE, UMAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0Ic93JY-zXI"
   },
   "outputs": [],
   "source": [
    "# =======\n",
    "# pick new values for lambda_c and lambda_d\n",
    "lambda_c = \n",
    "lambda_d = \n",
    "# =======\n",
    "\n",
    "# compile the tf computations for the clustering model\n",
    "tf.reset_default_graph()\n",
    "model = SAUCIE.SAUCIE(n_features, lambda_c=lambda_c, lambda_d=lambda_d)\n",
    "\n",
    "# train the clustering model\n",
    "model.train(loader_train, steps=5000)\n",
    "\n",
    "# get the clusters out\n",
    "_, clusters = model.get_clusters(loader_eval, binmin=10)\n",
    "cluster_embedding, _ = model.get_embedding(loader_eval)\n",
    "\n",
    "# ======\n",
    "# run the visualization of your choice\n",
    "# you may need to install PHATE or UMAP (`!pip install phate` or `!pip install umap-learn`)\n",
    "embedding_op = \n",
    "alt_embedding = embedding_op.fit_transform(data)\n",
    "# ======\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "scprep.plot.scatter2d(embedding, c=clusters, ticks=False, label_prefix=\"SAUCIE\", \n",
    "                      ax=ax1, discrete=True, legend=False, title=\"Default SAUCIE Embedding\")\n",
    "scprep.plot.scatter2d(cluster_embedding, c=clusters, ticks=False, label_prefix=\"SAUCIE\", \n",
    "                      ax=ax2, discrete=True, legend=False, title=\"Clustered SAUCIE Embedding\")\n",
    "scprep.plot.scatter2d(alt_embedding, c=clusters, ticks=False, label_prefix=\"Alt. Embedding \", \n",
    "                      ax=ax3, discrete=True, legend=False, title=\"Alternative Embedding\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yl2shm-n-zXO"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "1. How does `lambda_c` affect the clustering output?\n",
    "2. How does `lambda_b` affect the clustering output?\n",
    "3. How does SAUCIE's clustering compare to the other clustering algorithms we have learned about?\n",
    "4. Do `lambda_c` and `lambda_d` affect the SAUCIE visualization? How might you mitigate this?\n",
    "5. When might you choose to use SAUCIE for clustering?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_Exploratory_analysis_of_single_cell_data_with_SAUCIE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
