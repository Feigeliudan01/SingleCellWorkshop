{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying cell types with neural networks\n",
    "\n",
    "In this notebook, we will build a neural network that classifies cell types in the retinal bipolar dataset for Shekhar et al., 2016. These cells have been manually annotated, and here we will show that a neural network can recapitulate these cell type labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user scprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import scprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the retinal bipolar data\n",
    "\n",
    "We'll use the same retinal bipolar data you saw in preprocessing and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scprep.io.download.download_google_drive(\"1kxsMav1ly_S6pQ1vKeAtlFFW3QVvilz0\", \"shekhar_data.pkl\")\n",
    "scprep.io.download.download_google_drive(\"1J4K8bo8Pys-8xayO5vtMK3t5wJ0_TG2Y\", \"shekhar_clusters.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"shekhar_data.pkl\")\n",
    "clusters = pd.read_pickle(\"shekhar_clusters.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting data to `numpy` format\n",
    "\n",
    "Tensorflow expects data to be stored as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scprep.reduce.pca(data, n_components=100, method='dense').to_numpy()\n",
    "labels, cluster_names = pd.factorize(clusters['CELLTYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(labels))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into training and validation sets\n",
    "\n",
    "We'll allocate 80\\% of our data for training and 20\\% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15018, 100), (3755, 100))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first let's split our data into training and validation sets\n",
    "train_test_split = int(.8 * data.shape[0])\n",
    "\n",
    "data_training = data[:train_test_split, :]\n",
    "labels_training = labels[:train_test_split]\n",
    "data_validation = data[train_test_split:, :]\n",
    "labels_validation = labels[train_test_split:]\n",
    "data_training.shape, data_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Computational graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow works with an abstract computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_3:0\", shape=(10,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# let's make an object in this graph corresponding to our first 10 points\n",
    "data_tf = tf.constant(data_training[:10, :], dtype=tf.float32)\n",
    "\n",
    "# and now their corresponding labels\n",
    "labels_tf = tf.constant(labels_training[:10], dtype=tf.int32)\n",
    "\n",
    "# look at the output\n",
    "print(labels_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 2 1 4 0 3 5]\n"
     ]
    }
   ],
   "source": [
    "# compare this to the numpy data we started with\n",
    "print(labels_training[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BC5A', 'BC1B', 'BC6', 'Rod BC', 'BC6', 'BC1B', 'BC3B', 'BC5A',\n",
       "       'Rod BC', 'Muller Glia'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now go back to the original cluster names\n",
    "cluster_names[labels_training[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data is a np variable, with actual numbers\n",
    "data_tf is a tf variable, and is just a set of instructions, i.e. \"grab numbers from this variable and make them a constant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow's `Session`\n",
    "\n",
    "tf variables are just *instructions* for how to do computation, not the actual computations themselves\n",
    "to perform computations as instructed, we need to start a session and ask for the output by \"running\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 2., 1., 4., 0., 3., 5.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(labels_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(sess.run(data_tf), data_training[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.55465302e+02, 5.86087031e+04, 4.70691553e+03, 5.71816406e+04,\n",
       "        2.26201950e+02, 1.89646558e+03, 2.08491040e+03, 9.73422229e-01,\n",
       "        2.76444971e+03, 2.08067505e+02, 1.80798450e+03, 2.04972794e+02,\n",
       "        2.91574658e+03, 5.56084277e+03, 1.89451157e+02, 4.93480377e+02,\n",
       "        8.17330933e+02, 1.20037830e+03, 5.04254181e+02, 3.29946198e+02,\n",
       "        3.34681976e+02, 1.81121780e+02, 1.18960498e+03, 1.11654945e+02,\n",
       "        5.72496729e+03, 1.48646570e+03, 1.88747818e+02, 8.97228165e+01,\n",
       "        1.19735825e+02, 1.76366806e+02, 7.00738342e+02, 3.63830902e+02,\n",
       "        1.83918190e+01, 7.48567009e+00, 1.55218701e+03, 3.49349976e+03,\n",
       "        3.63029724e+02, 7.77578857e+02, 1.76109778e+03, 6.54872192e+02,\n",
       "        4.90719109e+01, 1.01245728e+02, 1.73189758e+02, 2.09980408e+02,\n",
       "        4.55323877e+03, 2.87891455e+03, 9.27585602e+01, 1.58389636e+03,\n",
       "        5.67447021e+02, 2.02089600e+03, 3.45625758e+00, 3.18488483e+01,\n",
       "        1.56000809e+02, 1.67953014e+01, 1.14625403e+03, 2.17807593e+03,\n",
       "        6.00447937e+02, 6.25815491e+02, 9.90090408e+01, 9.55407619e-01,\n",
       "        7.53956665e+02, 4.30344092e+03, 1.51874634e+03, 1.83333289e+03,\n",
       "        9.50500305e+02, 1.07673615e+02, 3.25117310e+03, 2.94993378e+02,\n",
       "        4.45190576e+03, 1.02443260e+02, 9.00416183e+01, 1.59007660e+02,\n",
       "        8.90652561e+00, 1.90033855e+01, 3.44336456e+02, 1.60139435e+02,\n",
       "        5.88484375e+02, 9.20702148e+03, 1.65518372e+03, 9.78427429e+01,\n",
       "        1.56884403e+01, 2.30898476e+01, 1.23107307e+02, 1.21573959e+02,\n",
       "        4.77829004e+03, 1.15048608e+03, 2.10777985e+02, 1.65981360e+03,\n",
       "        3.83619531e+03, 2.55964380e+03, 3.42954369e+01, 1.59887985e+02,\n",
       "        6.39727966e+02, 1.69173088e+01, 2.49631119e+02, 2.19013580e+02,\n",
       "        1.28413843e+03, 1.66657544e+03, 8.93671570e+02, 1.42126053e+02],\n",
       "       [1.89995331e+02, 3.88662773e+04, 1.47093127e+03, 2.52823535e+04,\n",
       "        6.94031128e+02, 1.43531738e+04, 1.00647793e+04, 1.27932239e+03,\n",
       "        1.05551777e+04, 1.96395667e+03, 2.60175098e+03, 2.91062109e+03,\n",
       "        1.19358362e+03, 2.99269043e+02, 7.14104128e+00, 8.47384109e+01,\n",
       "        9.92139844e+03, 2.19360156e+03, 3.67368774e+03, 1.61423682e+03,\n",
       "        3.00448090e+02, 2.55611481e+02, 8.09193970e+02, 4.13106792e-02,\n",
       "        2.52516943e+03, 6.14945190e+02, 1.52528131e+00, 1.43675213e+01,\n",
       "        4.53621979e+01, 5.47158670e+00, 6.29856787e+03, 1.50747278e+03,\n",
       "        1.52511917e+02, 1.28439362e+02, 7.36533154e+03, 1.41315613e+03,\n",
       "        8.28292175e+02, 2.06772247e+02, 2.07348804e+03, 5.02810547e+03,\n",
       "        4.83645142e+02, 1.76055798e+03, 7.86635559e+02, 2.06218286e+03,\n",
       "        2.37974243e+03, 9.58860046e+02, 6.20963745e+02, 6.01623352e+02,\n",
       "        8.44202881e+01, 1.33722595e+03, 2.10610461e+00, 2.26738867e+03,\n",
       "        2.79442114e+03, 5.62733040e+01, 2.25399033e+02, 4.12245941e+02,\n",
       "        1.08902820e+03, 6.72161627e+00, 4.28773315e+02, 1.42877281e+00,\n",
       "        1.22622650e+02, 3.14805237e+02, 1.38888940e+03, 2.51227100e+03,\n",
       "        8.10255798e+02, 1.51906274e+03, 1.86940112e+03, 6.01786743e+02,\n",
       "        2.37798233e+02, 1.95641870e+03, 1.79239865e-02, 1.06120642e+03,\n",
       "        3.92306399e+00, 1.35431458e+03, 1.02902962e+02, 8.34679871e+02,\n",
       "        2.46680786e+02, 3.66111565e+01, 2.73824829e+02, 2.07295334e+02,\n",
       "        1.34426895e+02, 6.67524529e+00, 3.21680249e+03, 2.25396320e-01,\n",
       "        5.27550537e+02, 9.62638306e+02, 4.85391602e+02, 1.50501782e+03,\n",
       "        3.35619736e+01, 5.25324280e+02, 4.63083801e+01, 6.11908691e+02,\n",
       "        3.82055939e+02, 7.90592194e+01, 5.81870239e+02, 3.78393188e+02,\n",
       "        1.41211273e+02, 8.53719940e+01, 3.68442749e+02, 5.04422998e+03],\n",
       "       [3.23411072e+02, 1.06263584e+04, 7.36250156e+04, 2.69196911e+01,\n",
       "        3.86617266e+04, 3.12187051e+04, 2.17696509e+03, 5.01235742e+03,\n",
       "        2.12516699e+03, 1.34250806e+03, 6.41648877e+03, 1.79800625e+04,\n",
       "        1.57361975e+03, 1.65754913e+02, 2.76573486e+02, 1.19627832e+03,\n",
       "        6.16996908e+00, 3.53593521e+01, 4.29072656e+03, 4.58897070e+03,\n",
       "        5.12546936e+02, 2.68750977e+03, 3.02204492e+03, 1.69614148e+03,\n",
       "        2.13292618e+02, 2.35289383e+02, 2.92407593e+02, 1.10849902e+03,\n",
       "        3.35515625e+03, 3.43624458e+01, 4.34166351e+02, 6.56107178e+02,\n",
       "        1.15356812e+03, 7.12610657e+02, 6.16975844e-01, 1.93683020e+03,\n",
       "        6.58794189e+02, 1.31032837e+02, 8.02478333e+02, 6.79239380e+02,\n",
       "        1.12906238e+03, 3.48691504e+03, 1.42517502e+02, 7.11286743e+02,\n",
       "        3.44598503e+01, 4.80392532e+01, 1.77065332e+03, 1.69704871e+03,\n",
       "        3.87419167e+01, 6.71299011e+02, 1.42995438e+02, 2.45138623e+03,\n",
       "        3.33324805e+03, 1.31734631e+03, 1.87544678e+02, 1.02188806e+03,\n",
       "        4.26480273e+03, 1.47198779e+03, 6.58809387e+02, 6.59708313e+02,\n",
       "        5.85739929e+02, 2.32261963e+03, 9.38411743e+02, 1.43721970e+02,\n",
       "        1.33475439e+03, 1.22307892e+02, 5.45072651e+00, 7.83129395e+02,\n",
       "        1.90874985e+02, 3.44462824e+00, 2.04563293e+02, 3.74277271e+03,\n",
       "        1.74642810e+03, 1.81444427e+02, 6.87723022e+02, 5.21215248e+01,\n",
       "        7.83927612e+02, 1.74576343e+03, 1.22770593e+03, 2.38985840e+03,\n",
       "        5.12074661e+01, 5.04524231e+02, 5.72297821e+01, 2.49893188e+03,\n",
       "        9.27786926e+02, 8.01414669e-01, 1.62969894e+01, 1.67414841e+02,\n",
       "        1.21781616e+02, 1.39777970e+00, 1.12526843e+03, 8.08913269e+01,\n",
       "        2.88681030e-01, 4.57336378e+00, 2.11131024e+00, 6.76294861e+01,\n",
       "        6.88213440e+02, 3.34230194e+02, 3.31587046e-01, 2.36691711e+02],\n",
       "       [5.30658359e+04, 2.85599590e+04, 1.70979932e+03, 1.09606750e+03,\n",
       "        1.10824854e+03, 5.52343689e+02, 2.76008862e+03, 1.48005139e+03,\n",
       "        1.06066724e+03, 2.09043652e+03, 1.50691956e+03, 1.99751892e+03,\n",
       "        1.14414563e+03, 1.05402718e+02, 6.21228943e+01, 2.42964432e+02,\n",
       "        4.82577881e+03, 8.74348402e-01, 3.38398657e+03, 1.74174377e+03,\n",
       "        1.18704968e+03, 1.51294816e+00, 2.13679346e+03, 6.75308594e+02,\n",
       "        1.28397632e+03, 9.26579834e+02, 1.12402319e+03, 1.89270276e+03,\n",
       "        9.98738586e+02, 4.59030426e+02, 2.17708473e+01, 3.71414136e+03,\n",
       "        4.62558502e+02, 3.35014038e+01, 1.03797266e+03, 4.63008057e+02,\n",
       "        4.66631775e+02, 5.85725293e+03, 1.32611303e+01, 2.61464783e+02,\n",
       "        9.18229797e+02, 2.31365747e+03, 9.10458984e+02, 1.86734734e+01,\n",
       "        2.33394092e+03, 1.39038839e+01, 1.86055200e+03, 7.11401224e+00,\n",
       "        2.61878571e+02, 1.03954254e+02, 1.01219305e+03, 3.23881531e+01,\n",
       "        1.71280518e+01, 7.52216919e+02, 2.15244324e+02, 2.66272736e+02,\n",
       "        2.18192163e+03, 1.91196613e+01, 2.92050977e+03, 1.32635963e+00,\n",
       "        1.43662036e+03, 9.89825378e+02, 5.82703186e+02, 1.11214587e+03,\n",
       "        2.91174072e+02, 1.21407068e+03, 1.24363147e+03, 1.15216057e+02,\n",
       "        6.90926086e+02, 1.37340491e+03, 2.01552991e+03, 2.79826782e+02,\n",
       "        1.27061539e+02, 8.75359650e+01, 4.71967812e+01, 4.44169502e+01,\n",
       "        2.30928857e+03, 6.30979150e+03, 3.05125806e+03, 4.13018945e+03,\n",
       "        5.86648376e+02, 1.85721924e+02, 7.75513611e+02, 5.40692482e+01,\n",
       "        1.64166689e+00, 3.02847876e+03, 1.50900513e+02, 2.39598870e+00,\n",
       "        1.45010828e+03, 7.46437759e+01, 7.76666870e+02, 1.47519592e+03,\n",
       "        7.13797569e+00, 3.37074646e+02, 5.37367773e+03, 3.65714996e+02,\n",
       "        2.57802002e+02, 1.81653976e+02, 1.90070892e+02, 3.30560962e+03],\n",
       "       [2.15398535e+04, 7.70273514e+01, 1.05673643e+04, 1.19035974e+03,\n",
       "        1.10716272e+03, 2.05451992e+04, 3.35212067e+02, 1.40294905e+01,\n",
       "        3.05967188e+03, 6.73562744e+02, 4.31430634e+02, 7.08117310e+02,\n",
       "        7.02773560e+02, 1.49760239e+02, 5.13622925e+02, 8.63870972e+02,\n",
       "        2.14585596e+03, 2.91566382e+03, 7.07332568e+03, 2.30768408e+03,\n",
       "        1.68885727e+01, 1.59046341e+02, 7.13792542e+02, 2.28250305e+02,\n",
       "        6.10327209e+02, 1.37361499e+03, 1.58607349e+03, 3.48667633e+02,\n",
       "        5.88521919e+01, 1.32242584e+02, 2.81194214e+03, 3.14059296e+01,\n",
       "        1.05581519e+03, 3.70182800e+02, 2.53360352e+02, 4.45745667e+02,\n",
       "        1.63501877e+02, 2.66998828e+03, 3.17438599e+02, 6.67077100e+03,\n",
       "        2.76538428e+03, 4.12481041e+01, 1.49597925e+03, 5.23137695e+02,\n",
       "        1.06298474e+03, 2.35202393e+03, 2.68485938e+03, 1.37142590e+03,\n",
       "        3.43410889e+02, 1.36719958e+03, 9.00899963e+02, 2.28222092e+02,\n",
       "        1.47594711e+02, 6.68886602e-01, 1.03545422e+03, 2.62113647e+03,\n",
       "        2.02226257e+03, 2.25835718e+03, 1.12421516e+02, 2.81017529e+03,\n",
       "        1.09463081e+02, 1.24362965e+01, 5.36971817e+01, 1.63962646e+03,\n",
       "        5.95440857e+02, 1.16253426e+02, 1.57857141e+03, 2.20448265e+01,\n",
       "        2.50949814e+02, 2.22823145e+03, 1.36229105e+01, 1.94802444e+02,\n",
       "        1.61093506e+02, 1.46367998e+01, 6.73025274e+00, 5.88353943e+02,\n",
       "        6.46776581e+01, 1.59117249e+03, 1.12335645e+03, 2.32517219e+00,\n",
       "        1.83273962e+03, 1.63487732e+03, 5.73085754e+02, 2.05235815e+03,\n",
       "        6.96970901e+01, 3.05222144e+03, 1.57900864e+02, 7.68748108e+02,\n",
       "        2.17469391e+02, 2.92601379e+02, 9.57432079e+00, 4.53997650e+02,\n",
       "        1.87049809e+01, 3.27314362e+02, 1.49670312e+03, 1.36162451e+03,\n",
       "        9.12861145e+02, 4.99528900e+02, 6.85323563e+01, 2.48991333e+02],\n",
       "       [4.33848000e+01, 3.76063164e+04, 3.16032861e+03, 1.23252959e+04,\n",
       "        7.27958447e+03, 1.12129473e+04, 1.54533765e+03, 6.26135596e+03,\n",
       "        3.85831274e+03, 4.13604248e+03, 6.19904150e+03, 7.85179590e+03,\n",
       "        1.22900305e+03, 3.71737122e+02, 1.12162207e+04, 3.07935257e+01,\n",
       "        2.44276596e+02, 9.22100258e+00, 9.21149963e+02, 4.96540099e-01,\n",
       "        5.21505176e+03, 4.60294189e+03, 2.79595966e+01, 1.60932446e+03,\n",
       "        1.25213647e+03, 2.21770309e+02, 1.79559766e+03, 5.79089294e+02,\n",
       "        1.82353735e+03, 1.24937592e+02, 6.41613235e+01, 2.46770947e+03,\n",
       "        3.38697235e+02, 5.12714424e+01, 7.14849268e+03, 1.66238672e+03,\n",
       "        4.37207565e+01, 2.32933914e+02, 4.95114600e+03, 5.90879456e+02,\n",
       "        4.53956388e-02, 2.10722070e+03, 2.30810962e+03, 7.62087488e+00,\n",
       "        1.78806213e+03, 5.73493103e+02, 4.89126434e+02, 5.19712280e+02,\n",
       "        1.07738354e+03, 7.61316376e+01, 1.21623238e+02, 1.54526459e+02,\n",
       "        2.07423486e+03, 1.39340088e+02, 1.63262500e+03, 4.29784203e+00,\n",
       "        2.69096606e+03, 1.17890259e+03, 8.59732056e+02, 3.54622095e+03,\n",
       "        6.57750061e+02, 1.71729736e+02, 1.96464587e+03, 1.40003479e+03,\n",
       "        1.67059131e+03, 1.51509741e+03, 1.58872208e+02, 3.92831482e+02,\n",
       "        4.16939331e+02, 1.30489624e+03, 4.72921875e+02, 2.87328377e+01,\n",
       "        1.10704700e+03, 3.42589172e+02, 8.40706543e+02, 6.49428101e+01,\n",
       "        1.80776367e+01, 3.06829834e+01, 6.06141357e+02, 1.08988232e+03,\n",
       "        1.29316359e+01, 1.55616626e+03, 1.55375916e+02, 2.95452301e+02,\n",
       "        4.23935890e+01, 6.14166374e+01, 2.80006237e+01, 2.44036353e+03,\n",
       "        1.08909790e+03, 1.09619177e+03, 1.15162756e+03, 6.46725159e+02,\n",
       "        1.33936719e+03, 6.82897888e+02, 2.66128223e+03, 1.19267647e+02,\n",
       "        9.08275635e+02, 6.31827332e+02, 3.50303735e+03, 8.73654785e+02],\n",
       "       [5.43233740e+03, 4.03900898e+04, 1.11321611e+04, 8.96245544e+02,\n",
       "        1.72795703e+04, 2.29342212e+03, 1.71881152e+04, 3.43641553e+03,\n",
       "        7.89420288e+02, 1.57116760e+02, 5.04397247e+02, 5.56432227e+04,\n",
       "        2.11144141e+03, 6.51617578e+03, 4.49740771e+03, 1.12538464e+03,\n",
       "        1.83312610e+03, 4.09511383e+02, 1.95178490e+01, 4.97595042e-01,\n",
       "        1.65890030e+02, 2.39669043e+03, 8.53713928e+02, 7.28366394e+02,\n",
       "        4.28584015e+02, 2.65575378e+02, 7.31680969e+02, 2.86412476e+02,\n",
       "        1.01977704e+03, 2.43999731e+03, 7.93619263e+02, 5.16538379e+03,\n",
       "        1.08640289e+02, 1.81507095e+02, 2.92819214e+02, 8.57257767e+01,\n",
       "        1.61913223e+01, 5.28428345e+02, 1.70047571e+03, 2.17660205e+03,\n",
       "        1.67878387e+02, 4.80669678e+03, 2.34010376e+02, 2.69942212e+03,\n",
       "        3.51587250e+02, 2.88030396e+02, 4.90112000e+02, 5.24691406e+03,\n",
       "        1.93023706e+03, 9.17552673e+02, 2.29458130e+03, 4.00493546e+01,\n",
       "        1.69206641e+03, 4.00133553e+01, 2.31065247e+02, 5.56198547e+02,\n",
       "        6.30984974e+00, 1.76491650e+03, 9.91617432e+02, 1.09975708e+03,\n",
       "        5.95160095e+02, 6.05837463e+02, 5.09201622e+01, 4.27927277e+02,\n",
       "        2.12119080e+02, 1.87454675e+03, 3.12204723e+01, 2.61174243e+03,\n",
       "        8.04532288e+02, 1.84156952e+01, 4.49932281e+02, 7.92340164e+01,\n",
       "        1.05226593e+02, 4.46517395e+02, 8.60991638e+02, 4.11409187e+01,\n",
       "        2.78120312e+03, 6.34828552e+02, 2.88294554e-01, 8.52503014e+00,\n",
       "        2.55025406e+02, 3.56674385e+01, 5.92146973e+02, 2.07066309e+03,\n",
       "        1.99888229e+02, 2.92869690e+02, 1.22284338e+03, 1.01852043e+02,\n",
       "        2.81707977e+02, 2.40207593e+03, 2.62462006e+01, 6.19525795e+01,\n",
       "        1.86918110e-01, 5.60933594e+02, 1.54842300e+02, 1.25859619e+03,\n",
       "        6.16945763e+01, 6.83247223e+01, 2.27541718e+02, 8.21676731e+00],\n",
       "       [7.91487305e+02, 1.66161172e+04, 9.94807983e+02, 4.02055117e+04,\n",
       "        5.12742188e+03, 1.66416809e+02, 1.13494373e+03, 2.27656592e+03,\n",
       "        1.10478894e+03, 1.45575537e+03, 7.13758926e+01, 1.14463058e+02,\n",
       "        2.43258496e+03, 8.83190247e+02, 1.45372559e+02, 2.44652783e+03,\n",
       "        1.49889816e+02, 6.40162903e+02, 1.26172217e+03, 9.56975281e+02,\n",
       "        9.65819275e+02, 5.10130432e+02, 6.58656006e+01, 2.43138474e+02,\n",
       "        5.77352966e+02, 4.14926453e+02, 5.25926697e+02, 2.26361377e+03,\n",
       "        4.47703949e+02, 2.44419116e+03, 1.43423889e+02, 1.41959412e+03,\n",
       "        1.62785022e+03, 1.23977246e+03, 2.86614716e+02, 2.89415951e+01,\n",
       "        1.84162817e+03, 8.79922562e+01, 1.40561096e+02, 1.02802515e+03,\n",
       "        1.14623352e+03, 3.41138000e+01, 7.89480103e+02, 2.61571460e+03,\n",
       "        2.92045166e+02, 8.52452087e+00, 2.90916367e+01, 2.83550146e+03,\n",
       "        1.02292671e+01, 1.93840277e+00, 5.53880959e+01, 5.50807037e+01,\n",
       "        1.67372803e+03, 3.05837128e+02, 1.72327722e+03, 1.48497351e+03,\n",
       "        1.18700830e+03, 3.09631592e+02, 4.98787933e+02, 5.31981735e+01,\n",
       "        1.71977005e+02, 6.51222763e+01, 1.13783228e+03, 1.42826953e+03,\n",
       "        1.85718933e+02, 5.11921310e+01, 8.90005035e+01, 4.15918793e+02,\n",
       "        8.72096741e+02, 1.04944252e+02, 2.03819812e+03, 5.07512054e+02,\n",
       "        2.06265747e+03, 1.26495903e+02, 4.56804688e+03, 1.91151892e+03,\n",
       "        2.53729639e+03, 3.80303673e-02, 4.14937305e+03, 4.28195709e+02,\n",
       "        1.56144788e+03, 3.88400757e+02, 1.96080875e+01, 2.49310455e+02,\n",
       "        3.60336037e+01, 2.41928604e+02, 2.31732251e+03, 1.03220190e+03,\n",
       "        1.61432141e+03, 1.77140979e+03, 2.56715488e+00, 1.51228613e+03,\n",
       "        2.79386987e+03, 1.86782776e+03, 1.97762054e+02, 2.68135742e+02,\n",
       "        6.12810859e-03, 5.98597755e+01, 9.90445614e+00, 7.84085999e+01],\n",
       "       [3.49415664e+04, 1.66568105e+04, 5.08702911e+02, 5.79651172e+03,\n",
       "        5.67821026e+00, 1.80825830e+03, 3.06789746e+03, 1.49087537e+03,\n",
       "        2.26524634e+03, 6.35710327e+02, 1.16935327e+03, 4.16429688e+02,\n",
       "        7.22234985e+02, 8.91340820e+02, 6.47823828e+03, 2.59720142e+03,\n",
       "        2.54365039e+03, 1.84658997e+02, 8.59380531e+00, 7.86348083e+02,\n",
       "        1.83021820e+02, 5.41548096e+03, 2.10635544e+02, 6.83912659e+02,\n",
       "        9.37107520e+03, 8.96581360e+02, 3.73366165e+01, 3.94775200e+01,\n",
       "        2.45373706e+03, 3.91266174e+01, 3.67857117e+02, 2.52683687e+00,\n",
       "        3.52311426e+03, 9.27731954e-03, 2.70741974e+02, 3.18821606e+03,\n",
       "        1.09519604e+03, 5.59908104e+01, 2.75369824e+03, 1.74273849e+00,\n",
       "        1.40718823e+03, 8.20621704e+02, 4.46738464e+02, 1.02621045e+03,\n",
       "        1.79958466e+02, 9.99426575e+01, 1.08905872e+03, 3.42959412e+02,\n",
       "        3.08705884e+03, 9.61529602e+02, 2.77021362e+02, 3.21838745e+02,\n",
       "        7.05872437e+02, 2.75819325e+00, 1.06033180e+02, 1.06362228e+01,\n",
       "        5.89943733e+01, 2.99497620e+02, 2.98602238e+01, 4.57765918e+03,\n",
       "        1.27838486e+02, 1.27829871e+03, 6.14685242e+02, 4.11423187e+02,\n",
       "        1.71699905e+01, 1.13213391e+03, 1.93348328e+02, 1.81702633e+01,\n",
       "        1.34507980e+02, 2.92118988e+01, 1.13501550e+03, 4.40383339e+01,\n",
       "        9.19960022e+02, 2.96963477e+03, 3.59410248e+02, 3.00844189e+03,\n",
       "        2.13885101e+02, 2.84497772e+02, 2.59954810e+03, 1.74893539e+02,\n",
       "        7.93320862e+02, 6.02896767e+01, 3.22441559e+02, 1.03062146e+03,\n",
       "        1.17219043e+03, 8.21401215e+00, 1.24920559e+00, 7.56874939e+02,\n",
       "        5.32119691e-01, 1.29865707e+02, 4.94969139e+01, 1.03027258e+01,\n",
       "        1.21697803e+03, 7.09539368e+02, 6.49538574e+01, 1.19473314e+01,\n",
       "        2.68631256e+02, 2.14326562e+03, 1.67477161e+03, 1.69106445e+03],\n",
       "       [4.24886906e+05, 2.92754570e+04, 1.01803418e+04, 1.35418750e+03,\n",
       "        1.83796338e+03, 2.83943311e+03, 2.55679834e+03, 5.98569336e+02,\n",
       "        5.99473511e+02, 3.11342392e+01, 2.57243652e+03, 1.01482495e+03,\n",
       "        7.36521454e+01, 5.34318970e+02, 8.06897412e+03, 1.85553375e+02,\n",
       "        1.62622534e+03, 3.51437469e+02, 2.10206348e+03, 6.16833252e+02,\n",
       "        2.90168934e+01, 4.64732094e+01, 4.28259491e+02, 1.57535803e+03,\n",
       "        9.18147034e+02, 1.65417004e+03, 6.68227844e+01, 8.36229614e+02,\n",
       "        5.96567749e+02, 9.40792942e+00, 3.88095044e+03, 9.96167302e-01,\n",
       "        1.11439844e+03, 1.97442700e+03, 2.13760319e+01, 6.85393143e+00,\n",
       "        1.29890613e+03, 6.41264465e+02, 4.71892529e+03, 1.04995903e+02,\n",
       "        5.45381104e+02, 5.44209137e+01, 1.13794813e+01, 7.55823730e+02,\n",
       "        1.36207016e+02, 2.16310150e+02, 4.34474897e+00, 5.17549072e+02,\n",
       "        7.83143494e+02, 8.44544601e+01, 5.77689590e+01, 1.10682648e+02,\n",
       "        1.06855934e+02, 1.79513440e+03, 1.14032623e+02, 2.17802200e+02,\n",
       "        1.27183044e+03, 7.54244156e+01, 7.58023119e+00, 1.13496695e+01,\n",
       "        8.76704468e+02, 2.32882401e+02, 1.96934583e+03, 1.18410083e+03,\n",
       "        1.81075516e+02, 2.55716080e+02, 1.23246521e+03, 2.70893829e+02,\n",
       "        1.20629807e+02, 9.70569305e+01, 1.10377708e+02, 1.03204514e+02,\n",
       "        2.14868011e+02, 1.05537146e+03, 1.12832893e+02, 2.36369702e+03,\n",
       "        3.70457611e+01, 3.89395050e+02, 8.34037720e+02, 2.25719019e+03,\n",
       "        4.23239380e+02, 3.87915778e+00, 1.40160370e+00, 1.95761673e+02,\n",
       "        4.61055786e+02, 5.38985300e+00, 6.71992254e+00, 5.46676254e+00,\n",
       "        3.53848083e+02, 1.95417557e+02, 2.88456818e+02, 1.66229660e+02,\n",
       "        1.41819537e+00, 2.90116138e+03, 1.85151993e+02, 2.21912265e-01,\n",
       "        5.81443359e+02, 2.42363953e+02, 2.00445267e+02, 4.99432564e+01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now give instructions for computations on this data and then ask for the output\n",
    "w = 10 * data_tf + 3\n",
    "x = w / 2\n",
    "y = x + w\n",
    "z = y**2\n",
    "\n",
    "sess.run(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note now output is a np variable that corresponds to the value of z. we do not have a np variable \n",
    "corresponding to w, x, or y. if all we want is the output z, we don't need them!\n",
    "\n",
    "## Exercise 1 - Print the last 5 rows of the data matrix with their values doubled (using tensorflow operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-60-c76805c08f8b>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-60-c76805c08f8b>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    data_last5 =\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# =================\n",
    "# Get the last five rows of `data_training`\n",
    "data_last5 = \n",
    "# Create a tensorflow constant storing `data_last5`\n",
    "tf_last5 = \n",
    "# Multiply by two\n",
    "tf_last5_double =\n",
    "# Use `sess` to compute the result\n",
    "data_last5_double =\n",
    "# Print the result\n",
    "data_last5_double\n",
    "# ================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a one-layer neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# this function applies the simple feedforward operation\n",
    "def layer(x, n_dim, name, activation=None):\n",
    "    # create the weight matrix\n",
    "    W = tf.get_variable(dtype=tf.float32, shape=[x.get_shape()[-1], n_dim], name='W{}'.format(name))\n",
    "    # create the bias vector\n",
    "    b = tf.get_variable(dtype=tf.float32, shape=[n_dim], name='b{}'.format(name))\n",
    "    # X2 = X1 * W + b\n",
    "    output = tf.matmul(x, W) + b\n",
    "    if activation:\n",
    "        # nonlinear activation function\n",
    "        output = activation(output)\n",
    "    return output\n",
    "\n",
    "# create a hidden (middle) layer\n",
    "hidden_layer_tf = layer(data_tf, n_dim=100, name='hidden', activation=tf.nn.relu)\n",
    "\n",
    "# create the output layer used to classify\n",
    "output_tf = layer(hidden_layer_tf, n_dim=num_classes, name='output', activation=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a loss/score to tell our network how good or bad these results are\n",
    "# let's use cross-entropy like we talked about\n",
    "labels_one_hot = tf.one_hot(labels_tf, num_classes)\n",
    "\n",
    "loss_tf = labels_one_hot * tf.log(output_tf + 1e-6) + (1 - labels_one_hot) * tf.log(1 - output_tf + 1e-6)\n",
    "loss_tf = -1 * tf.reduce_sum(loss_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the optimizer and tell it to minimize the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need an optimizer that we'll give this loss, and it'll take responsibility\n",
    "# for updating the network to make this score go down\n",
    "learning_rate = .00001\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "# this will be the tf object we call for when we want to take a single step to train our network\n",
    "train_op = opt.minimize(loss_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last thing: we need to set our network weights to random values to start\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and that's it! We've built a one-layer neural network!\n",
    "\n",
    "#### Evaluating network performance\n",
    "\n",
    "Let's see how our network does at classifying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_np, labels_np = sess.run([output_tf, labels_tf])\n",
    "\n",
    "output_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 17 17  4 12  4  9 26 12  7]\n"
     ]
    }
   ],
   "source": [
    "# network outputs\n",
    "np.argmax(output_np, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 2 1 4 0 3 5]\n"
     ]
    }
   ],
   "source": [
    "# true output labels\n",
    "labels_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 0 / 10\n"
     ]
    }
   ],
   "source": [
    "# count the number we got right\n",
    "print('Correct: {} / {}'.format((np.argmax(output_np, axis=1) == labels_np).sum(), output_np.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the network\n",
    "\n",
    "Here's the important part: we can optimize the weights of the network based on the desired outputs and iterate until we get good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step 0 correct: 0 / 10\n",
      "Training step 100 correct: 2 / 10\n",
      "Training step 200 correct: 5 / 10\n",
      "Training step 300 correct: 5 / 10\n",
      "Training step 400 correct: 9 / 10\n",
      "Training step 500 correct: 10 / 10\n",
      "Training step 600 correct: 10 / 10\n",
      "Training step 700 correct: 10 / 10\n",
      "Training step 800 correct: 10 / 10\n",
      "Training step 900 correct: 10 / 10\n"
     ]
    }
   ],
   "source": [
    "for step in range(1000):\n",
    "    sess.run(train_op)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        output_np, labels_np = sess.run([output_tf, labels_tf])\n",
    "        print('Training step {} correct: {} / {}'.format(step, (np.argmax(output_np, axis=1) == labels_np).sum(), output_np.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so our network can classify these ten points pretty well. But how can we do this for thousands or millions of points?\n",
    "\n",
    "### Start again with placeholders so we can use all of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of tensorflow is that we are able to define computations as we did above, but with 'placeholders' instead of actual data. We just have to define the shape and type of the variable, and then we don't have to give it actual data until we call `sess.run`.\n",
    "\n",
    "This is powerful because we can call the same computation over and over again with different data without having to rewrite the tensorflow code.\n",
    "\n",
    "So now let's start over and do it with `tf.placeholder`! Conveniently, we don't have to specify the number of rows in our dataset and can instead just use `None` to indicate this may vary from batch to batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # a helpful function for clearing the tf code in your existing session\n",
    "batch_size = 10\n",
    "data_tf = tf.placeholder(shape=[None, data.shape[1]], dtype=tf.float32, name='data_tf')\n",
    "labels_tf = tf.placeholder(shape=[None], dtype=tf.int32, name='labels_tf')\n",
    "\n",
    "\n",
    "hidden_layer_tf = layer(data_tf, n_dim=10, name='hidden', activation=tf.nn.relu)\n",
    "\n",
    "output_tf = layer(hidden_layer_tf, n_dim=num_classes, name='output', activation=tf.nn.softmax)\n",
    "\n",
    "labels_one_hot = tf.one_hot(labels_tf, num_classes)\n",
    "\n",
    "loss_tf = labels_one_hot * tf.log(output_tf + 1e-6) + (1 - labels_one_hot) * tf.log(1 - output_tf + 1e-6)\n",
    "loss_tf = - tf.reduce_sum(loss_tf)\n",
    "\n",
    "learning_rate = .001\n",
    "# we'll use the AdamOptimizer as it is much more powerful\n",
    "opt = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train_op = opt.minimize(loss_tf)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's train our network with new data each step\n",
    "step = 0\n",
    "for epoch in range(100):\n",
    "    random_order = np.random.choice(data_training.shape[0], data_training.shape[0], replace=False)\n",
    "    data_randomized = data_training[random_order]\n",
    "    labels_randomized = labels_training[random_order]\n",
    "    \n",
    "    for data_batch, labels_batch in zip(np.array_split(data_randomized, data_randomized.shape[0] // batch_size), np.array_split(labels_randomized, labels_randomized.shape[0] // batch_size)):\n",
    "        step += 1\n",
    "\n",
    "        sess.run(train_op, {data_tf: data_batch, labels_tf: labels_batch})\n",
    "\n",
    "        # evaluate accuracy on both the training and validation datasets every once in awhile\n",
    "        if step % 10 == 0:\n",
    "            loss_np = sess.run(loss_tf, {data_tf: data_batch, labels_tf: labels_batch})\n",
    "            output_np = []\n",
    "            labels_np = []\n",
    "            for data_batch, labels_batch in zip(np.array_split(data_training, data_training.shape[0] // ), np.array_split(labels_training, labels_training.shape[0] // batch_size)):\n",
    "                output_np_ = sess.run(output_tf, {data_tf: data_batch})\n",
    "                output_np.append(output_np_)\n",
    "                labels_np.append(labels_batch)\n",
    "            output_np = np.concatenate(output_np, axis=0)\n",
    "            labels_np = np.concatenate(labels_np, axis=0)\n",
    "            acc_training = (np.argmax(output_np, axis=1) == labels_np).sum() / output_np.shape[0]\n",
    "\n",
    "            output_np = []\n",
    "            labels_np = []\n",
    "            for data_batch, labels_batch in zip(np.array_split(data_validation, data_validation.shape[0] // batch_size), np.array_split(labels_validation, labels_validation.shape[0] // batch_size)):\n",
    "                output_np_ = sess.run(output_tf, {data_tf: data_batch})\n",
    "                output_np.append(output_np_)\n",
    "                labels_np.append(labels_batch)\n",
    "            output_np = np.concatenate(output_np, axis=0)\n",
    "            labels_np = np.concatenate(labels_np, axis=0)\n",
    "            acc_validation = (np.argmax(output_np, axis=1) == labels_np).sum() / output_np.shape[0] \n",
    "            print('Step {} loss: {:.3f} training accuracy: {:.3f} validation accuracy: {:.3f} '.format(step, loss_np, acc_training, acc_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "How did our network do? Is the classification accuracy high? How many iterations did it take for the training accuracy to stop increasing? How many iterations did it take for the training loss to stop decreasing?\n",
    "\n",
    "#### _Breakpoint_  - once you get here, please help those around you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - network width\n",
    "\n",
    "Create a network with a wider hidden layer and compare its performance to the network with 10 hidden neurons we just built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================\n",
    "# Copy the code from above and change n_dim in the hidden layer from 10 to something larger\n",
    "\n",
    "# ==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Breakpoint_  - once you get here, please help those around you!\n",
    "\n",
    "## Exercise 4\n",
    "\n",
    "Create a network with *two* hidden layers and compare its performance to the network with one hidden layer we just built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================\n",
    "# Copy the code from above and add another hidden layer whose input is the output of the first layer\n",
    "# The second hidden layer should be used as input to the output layer\n",
    "\n",
    "# ==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _Breakpoint_  - once you get here, please help those around you!\n",
    "\n",
    "## Exercise 5\n",
    "\n",
    "Create a network with *five* hidden layers and compare its performance to the network with one hidden layer we just built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================\n",
    "# Copy the code from above and add another three hidden layers\n",
    "# Chain the output from each layer to the input at the next\n",
    "\n",
    "# ==================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
